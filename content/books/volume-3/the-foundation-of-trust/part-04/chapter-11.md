---
title: 第十一章 算法的全知：从芝麻信用到社会评分
date: 2025-10-19T00:00:00+08:00
draft: false
hidden: false
tags: ["书稿"]
keywords: ["信任的基底：从血缘到算法", "第十一章 算法的全知：从芝麻信用到社会评分"]
slug: "chapter-11"
---

如果说区块链代表了一种试图通过"去中心化"来重构信任的、带有某种无政府主义色彩的技术理想；那么，在现实世界中，一股同样强大、甚至在影响范围上更为深远的信任革命，正在沿着一条截然相反的、极致"中心化"的路径，高歌猛进。

这场革命的主导者，不再是匿名的密码朋克，而是我们这个时代最强大的权力实体——科技巨头（Big Tech）与现代国家。他们所使用的武器，不是密码学和共识机制，而是一种更为古老、但在数字时代被赋予了前所未有力量的东西——信息。

这场革命的核心逻辑是：只要我们能够收集到关于一个人的、足够全面的数据（Data），我们就可以通过一个足够复杂的算法模型（Algorithm Model），来计算出一个关于他/她的、极其精准的"可信度"分数（Credit/Trust Score）。这个分数，将成为其在数字社会中通行无阻或寸步难行的"万能通行证"。

这就是"算法评估"（Algorithmic Evaluation）的时代。它正在将信任，从一种模糊的、定性的、基于人际关系的"感觉"，彻底改造为一种清晰的、定量的、基于数据计算的"指标"。从中国的"芝麻信用"，到西方金融业日益普及的自动化风控，再到某些国家正在试点的"社会信用体系"，我们正目睹着一个由算法所统治的、全景敞视式的"评估社会"的降临。

在这个新的社会形态中，那个曾经被认为是属于上帝的、无所不知的"全知视角"，正在以一种世俗化的、技术化的形式，被重新实现。而这一次，扮演"上帝"角色的，是那些掌握着海量数据和先进算法的、新的"数字利维坦"。

## 数据的收集：万物皆成评估参数

算法评估这台宏伟机器的运转，其燃料，是数据。没有持续不断的、海量的数据输入，最先进的算法模型，也只是一具空洞的骨架。因此，构建一个算法评估体系的第一步，也是最基础、最关键的一步，就是建立一个无所不包的、全天候的"数据收集"基础设施。

在数字时代之前，对一个人的"信用"评估，其数据来源是极其有限和低效的。一个银行的信贷员，在评估一个贷款申请人时，他所能依据的，可能仅仅是一份简单的收入证明、一些不动产的凭证，以及一些来自社区的、零散的"口碑"信息。评估，是在一种"数据稀疏"的状态下进行的。

而今天，随着智能手机成为我们身体的"延伸"，随着物联网（IoT）设备遍布我们生活的每一个角落，我们正进入一个"万物皆可数据化"（Datafication of Everything）的时代。我们每一个微不足道的行为、每一次心不在焉的选择、每一句脱口而出的言语，都在被默默地、持续不断地，转化为可被收集、存储、分析的"评估参数"。

人类，正在变成一个行走的、24 小时不间断生产数据的"数据源"。

第一维度：经济与金融数据——"你拥有什么？"

这是最传统、也是最核心的评估数据维度。它衡量的是一个人的"经济实力"与"财务信誉"。

传统金融数据：你的银行账户流水、信用卡还款记录、历史贷款情况、有无违约记录、名下资产（房产、汽车、股票）等。这些数据，构成了传统征信体系（如美国的 FICO 分，中国的央行征信）的基石。

数字支付数据：在中国，由支付宝和微信支付所主导的移动支付革命，将这种数据收集的广度和深度，提升到了一个前所未有的层面。你每天的每一笔消费——从早上一杯咖啡的支付、中午一顿外卖的订单，到晚上一张电影票的购买——都被精准地记录下来。你的消费水平、消费偏好、生活稳定性（例如，是否按时缴纳水电煤气费），都成为了评估你"履约能力"和"信用水平"的重要参数。

第二维度：行为与偏好数据——"你是谁？你喜欢什么？"

这是互联网平台经济的核心数据维度。它旨在绘制一幅关于你的、无比精细的"用户画像"（User Profile）。

搜索与浏览数据：你在搜索引擎上输入的每一个关键词，你在新闻网站上点击的每一篇文章，你在电商平台上浏览的每一个商品，都在揭示你的兴趣、需求、知识层次甚至潜在的意识形态。

社交网络数据：你在社交媒体上与谁互动，关注了哪些大 V，加入了哪些群组，发布了什么内容的帖子，点赞了哪些朋友的动态。你的"社交图谱"，被认为是评估你"人脉质量"和"社会影响力"的关键指标。芝麻信用就曾明确表示，你支付宝好友的信用分数，也会在一定程度上，影响你自己的分数。这是一种现代版的、数字化的"近朱者赤，近墨者黑"的评估逻辑。

地理位置与出行数据：你的手机基站定位、GPS 轨迹、打车记录、共享单车使用记录，共同构成了一幅关于你"时空行为"的地图。你住在哪个小区，在哪栋写字楼上班，经常去哪些商场消费，周末喜欢去哪里娱乐。这些数据，可以被用来推断你的职业、收入水平和社会阶层。

第三维度：生物识别与生理数据——"你的身体在说什么？"

这是最新兴、也最具争议性的数据维度。它试图穿透你外在的行为，直接去读取你身体内部的、更"诚实"的信号。

生物识别数据：你的人脸图像、指纹、虹膜、声纹，越来越多地被用作身份验证和支付的手段。这些独一无二的、与你肉体紧密绑定的数据，正在成为你在数字世界中的"终极身份证"。

健康与运动数据：你的智能手表或手环，正在实时地记录你的心率、睡眠质量、每日步数。一些健康保险公司，已经开始尝试，根据这些数据，来动态地调整你的保费。一个生活方式更"健康"的人，被评估为是一个风险更低的、更"值得信任"的投保人。

情绪识别数据（Affective Computing）：通过分析你的摄像头捕捉到的面部微表情、麦克风收集到的语音语调，甚至是你敲击键盘的力度和节奏，一些先进的算法，声称能够"识别"出你当下的情绪状态（高兴、愤怒、紧张、撒谎）。这种技术，虽然尚在早期，但其在未来的招聘面试、信贷审批甚至刑事审讯中的应用前景，已经引发了巨大的伦理忧虑。

第四维度：公共与政务数据——"国家眼中的你是什么样？"

除了来自商业机构的数据，来自政府和公共部门的数据，也正在被越来越多地，整合进这个全景式的评估体系之中。

司法与行政记录：你是否有过犯罪记录、是否被列为"失信被执行人"（即"老赖"）、是否有过交通违章 是否按时纳税。这些"负面清单"数据，是评估一个人"守法意识"和"社会责任感"的最直接依据。

学历与职业资格记录：你的教育背景、毕业院校、获得的专业技术职称等，被用来评估你的"人力资本"价值。

社会行为记录：在某些社会信用体系的试点中，一些公共领域的行为，如是否参与志愿服务、是否进行垃圾分类、甚至是否"见义勇为"，也被尝试性地，纳入加分或减分的评估范畴。

经济、行为、生理、政务……这四个维度的数据，如同四条奔流不息的江河，正在从我们生活的每一个缝隙中，涌出，并最终汇入由科技巨头和国家所掌控的、深不见底的"数据湖"（Data Lake）之中。

在这个过程中，"隐私"（Privacy），这个曾经被认为是现代个体自由基石的古典概念，正在被迅速地，重新定义，甚至被消解。我们的生活，被转化为一本"公开的账簿"，一本由无数个微小的、量化的"参数"所构成的、可供算法随时查阅和评估的"数字档案"。

"万物皆成评估参数"，这句看似夸张的口号，正在成为我们这个时代，一个冰冷而严峻的现实。它为算法的全知，提供了取之不尽、用之不竭的"原材料"。而接下来，这台机器，将用一个我们看不见、也无法理解的"黑箱"，来对这些原材料，进行神秘的"炼金术"加工。

## 模型的黑箱：不可见、不可辩的自动化评估

当海量的数据被收集起来之后，算法评估的第二阶段，也是最核心、最神秘的阶段，便开始了。在这个阶段，原始的数据，将被喂入一个极其复杂的"算法模型"（Algorithmic Model）之中，进行处理、分析、关联、预测，并最终，输出一个关于评估对象的、简洁明了的"结论"（例如，一个信用分数、一个风险等级、或是一个"同意/拒绝"的决策）。

这个"算法模型"，就是现代评估权的"权力中枢"。然而，与前现代长老那可以被当面质询的权威，或现代法庭那必须公开其判决理由的权威不同，算法模型的评估过程，在绝大多数情况下，对于被评估者而言，是一个完全不可见（Invisible）、不可辩（Incontestable）的"黑箱"（Black Box）。

从"统计回归"到"深度学习"：日益增长的复杂性与不可解释性

早期的算法模型，相对简单。例如，一个基于"逻辑回归"（Logistic Regression）的信贷审批模型，其内部的评估逻辑，在很大程度上，还是可以被人类所理解和解释的。信贷分析师，可以清晰地告诉你："因为你的收入低于某个阈值，并且你的负债率高于某个阈值，所以，根据我们的模型，你的违约概率被判定为过高，因此你的贷款申请被拒绝了。" 在这里，评估的"因果关系"，虽然是统计性的，但仍然是可追溯的。

然而，随着"机器学习"（Machine Learning），特别是"深度学习"（Deep Learning）技术的崛起，算法模型的复杂性和能力，发生了指数级的跃迁。

一个现代的、基于深度学习的风险评估模型，其内部，可能包含了数亿个相互连接的"神经元"，分布在数百个"隐藏层"之中。当你的个人数据，被作为"输入"，喂入这个"神经网络"的第一层时，它会经历一个极其复杂的、非线性的、人类大脑完全无法追踪的"特征提取"与"权重调整"的过程。数据，在这些层层叠叠的神经元之间，以一种我们无法理解的方式，进行着"涌现"式的计算。最终，在最后一层，模型"吐出"一个关于你违约概率的、精确到小数点后五位的预测值。

这个模型的预测能力，可能远超于任何人类专家。它能够从那些看似毫不相干的数据维度之间，发现一些人类分析师永远无法察觉的、极其微弱的、但统计上却显著的"相关性"（Correlation）。

例如，模型可能会"发现"：

那些手机电池电量经常低于 20%才充电的用户，其还款的拖欠率，要略高于那些总是保持电量充足的用户。

那些在深夜频繁点高热量外卖的用户，其发生健康问题的保险理赔率，更高。

那些输入密码速度过快或过慢的用户，其是欺诈用户的可能性，更大。

当模型的开发者，被问及"为什么会存在这种相关性"时，他们的回答，常常是："我们也不知道。模型就是这样告诉我们的。It just works."（它就是管用。）

在这里，我们遭遇了现代评估权一个最深刻、也最令人不安的悖论：评估的"准确性"，是以牺牲其"可解释性"（Explainability）为代价的。模型，越是复杂，越是"智能"，其内部的运作逻辑，就越是趋近于一个纯粹的"黑箱"。

评估的"自动化"与权力的"不可辩驳性"

当评估权，被封装进这样一个"黑箱"之中，并以"自动化"（Automation）的方式，大规模地，应用于社会生活的方方面面时，一种全新的、不对称的权力关系，便诞生了。

评估的"不可见性"：作为被评估者，你完全不知道，是你的哪些数据，被纳入了评估的范围；你也不知道，这些数据，在模型中，各自被赋予了多大的"权重"；你更不知道，模型所依据的，是哪些你甚至都意识不到的"微弱相关性"。整个评估的过程，对你而言，是完全"隐身"的。

评估的"不可辩驳性"：当你，因为一个算法给出的负面评估（例如，你的贷款被拒、你的保险申请被拒、你无法通过某一轮的机器人面试筛选），而试图去申辩或寻求一个理由时，你将陷入一种前所未有的"申诉困境"。

你去找客服，客服人员很可能，也无法访问和理解那个复杂的算法模型。他们只能给你一个标准化的、循环论证式的答复："根据我们系统的综合评估，您不符合我们的要求。"

你要求公司公开其算法模型，公司会以"商业机密"为由，断然拒绝。

即使公司同意让你看到一部分评估逻辑，那些基于复杂相关性的判断，也常常是"反常识"的，是你无法用日常逻辑去反驳的。你如何能去证明，"你的充电习惯"，与你的"还款意愿"，之间"不应该"存在关联？

在这种权力结构下，被评估者，被彻底地"去能"（Disempowered）了。他/她，从一个可以与评估者进行对话、协商、甚至讨价还价的"主体"，退化为了一个只能被动地，接受那个来自"黑箱"的、如同神谕般不可置疑的"裁决"的"客体"。

算法偏见：偏见的"洗白"与歧视的"自动化"

更具讽刺意味的是，这个被宣称为是"客观"、"中立"、"超越人类偏见"的算法评估系统，在实践中，却常常会系统性地，复制、放大、甚至"洗白"人类社会中早已存在的、深刻的偏见（Bias）与歧视（Discrimination）。

这是因为，机器学习模型，并非是在真空中进行学习的。它们，是通过"喂食"海量的、来自真实世界的"历史数据"，来进行"训练"的。而这些历史数据本身，就如同化石一般，深深地，烙印着人类社会过去所有的不平等与歧视。

一个用来筛选求职简历的 AI 模型，如果它所学习的"训练数据"，是某家公司过去 20 年的招聘记录，而在这 20 年里，这家公司，因为其根深蒂固的性别歧视文化，而主要招聘男性工程师。那么，这个 AI 模型，就会从数据中，"学习"到这样一条"成功模式"："男性"这个特征，与"被录用"这个结果之间，存在着强烈的正相关性。于是，在未来的筛选中，它就会自动地，对女性求职者的简历，给出更低的分数。即使，在它的代码中，并没有任何一行，明确地写着"歧视女性"。它只是在"客观地"，反映和延续历史的偏见而已。

一个用来预测累犯风险的刑事司法算法（如美国的 COMPAS 系统），如果其训练数据，主要来自于一个在历史上，存在着严重种族偏见的司法系统（例如，黑人社区，受到了比白人社区，更严密的警力监控，因此黑人的被逮捕率，天然地就更高）。那么，这个算法，就会"学习"到，"肤色"或"居住社区"这些特征，是预测未来犯罪的"强相关"指标。其结果，就是黑人被告，会被系统性地，赋予比白人被告，更高的"再犯风险"分数，从而导致他们被判处更长的刑期。

算法，在这里，扮演了一个极其危险的"偏见洗白机"的角色。它将那些赤裸裸的、在政治上不正确的社会歧视（如种族歧视、性别歧视），"转码"为一种看似客观、中立、甚至科学的、基于统计相关性的"技术性风险评估"。

它使得歧视，得以在一种"自动化"的、大规模的、难以被追责的方式下，得以延续和固化。我们，正在创造一个系统，在这个系统里，我们甚至不需要一个怀有种族主义思想的法官，就能够得到一个种族主义的判决。因为，歧视，已经被编码进了那个不可见的、不可辩的"黑箱"的核心深处。

## 信任的量化：当"可信度"成为一个精准的分数

算法评估这台机器的最终产物，其最显著、也最具社会冲击力的特征，就是它将那个原本是多维度的、情境化的、难以捉摸的"可信度"（Trustworthiness），压缩成了一个单一的、一维的、看似无比精准的"分数"（Score）。

从芝麻信用的 350-950 分，到美国 FICO 信用的 300-850 分，再到各种新兴的、应用于不同场景的声誉评分、风险评分、潜力评分……我们正在进入一个"万物皆可评分"（Scoring of Everything）的社会。

"分数"，是算法评估权力的终极"权杖"。它以一种前所未有的、简洁明了的方式，完成了对个体社会价值的"量化"（Quantification）。这种量化，带来了深刻的社会后果。

第一，分数的"可比性"与"可排序性"：社会分层的"新标尺"

分数，最大的魔力，在于其"可比性"。

在前现代社会，我们很难去精确地比较，一个"德高望重"的长老，和一个"骁勇善战"的武士，谁的"社会价值"更高。他们的价值，体现在不同的、不可通约的维度上。

然而，在一个评分社会里，这种比较，变得异常简单和残酷。一个芝麻信用 750 分的人，就是比一个 650 分的人，"更可信"；一个 FICO 分数 800 分的客户，就是比一个 600 分的客户，"更优质"。

分数，为社会，提供了一把全新的、看似客观的、普遍适用的"度量衡"。它将所有原本是异质的、多元的个体，都投射到了一个单一的、线性的"积分榜"之上。在这个积分榜上，每一个人，都可以被清晰地"排序"（Ranking）。

这种可排序性，正在成为一种新的、强大的社会分层（Social Stratification）机制。

你的信用分数，直接决定了，你能够以多低的利率，获得贷款；你是否能够享受"免押金"租车、住酒店的便利；甚至，在一些婚恋网站上，它会成为系统为你匹配对象的、一个重要的权重参数。

你在某个网约车平台上的"司机分"，决定了，你能够以多大的概率，接到那些距离更近、金额更高的"优质订单"。

一个求职者，在通过了 AI 简历筛选和机器人面试后，所得到的那个内部"潜力分"，将决定他/她，能否进入下一轮、由人类面试官所主持的"终审"。

一个以"分数"为基础的社会，是一个"数字化的种姓制度"。你的分数，如同一个无形的、但又无处不在的"烙印"，决定了你能够进入哪些社会场景，能够获得哪些机会，能够享受何种层次的服务。它正在我们之间，划下一道道新的、看不见的、但却坚不可摧的"数字鸿沟"。

第二，分数的"规训"力量：自我行为的"算法迎合"

当分数，开始与我们生活中的各种"奖赏"与"惩罚"机制，紧密地挂钩时，它便产生了一种强大的、深入骨髓的"规训"（Discipline）力量。

为了获得一个更高的分数，为了在那个无形的"积分榜"上，向上攀爬，我们，开始有意识地、甚至无意识地，去调整自己的行为，以"迎合"（Cater to）那个我们并不能完全理解的、隐藏在黑箱之中的"算法偏好"。

这是一种全新的、福柯式的"自我监控"与"自我规训"。

一个芝麻信用的用户，可能会为了"提升"自己的分数，而刻意地，多使用几次支付宝的"爱心捐赠"功能，或者将自己的存款，从银行，转移到支付宝的"余额宝"里。即使，他/她，并不真正地相信那个慈善项目，或者，余额宝的利息，并不比银行更高。

一个网约车司机，为了维持自己的高分，可能会强迫自己，即使在身体极度疲惫、或者路况极其糟糕的情况下，也去接受那些他本能地想要拒绝的订单。他会时刻保持"微笑服务"，因为他知道，任何一个来自乘客的差评，都可能让他过去一周的努力，付诸东流。

我们，开始像训练一只"巴甫洛夫的狗"一样，去训练我们自己。我们学着，去做出那些能够得到算法"奖励"（加分、好评、优先推荐）的行为，去避免那些可能导致算法"惩罚"（减分、差评、流量限制）的行为。

在这个过程中，我们，正在逐渐地，丧失我们行为的"内在动机"与"自主性"。我们行动的理由，不再是"因为我真心想这么做"，或者"因为我认为这样做是正确的"，而是"因为这样做，对我的分数有好处"。

那个隐藏在黑箱中的算法，就如同边沁所设计的"全景敞视监狱"中央的那座"瞭望塔"。我们虽然看不见塔中的"监视者"（算法），但我们默认它"永远在那里凝视着我们"。于是，我们，便成为了我们自己，最警惕、最有效率的"狱卒"。

第三，信任的"异化"：从人际关系到人机关系

最终，一个被分数所统治的社会，其所带来的最深刻的危机，是信任本身的"异化"（Alienation）。

信任，在其最本真的意义上，是一种"人际关系"。它发生在两个具体的、有血有肉的、不完美的"人"之间。它是一种需要时间去培养、需要情感去维系的、充满了风险与谅解的"艺术"。

而算法评分，则试图将这种复杂的人际艺术，简化为一种简单的"人机关系"。

我信任你，不再是因为我了解你的为人，欣赏你的品格，或者与你有着共同的经历和回忆。我信任你，仅仅是因为"算法告诉我，你的分数很高"。

我评估一个合作对象的标准，不再是去与他/她进行深入的、面对面的沟通，去观察他/她的言行举止，去感受那种难以言喻的"化学反应"。我的评估，被简化为，在合作开始前，互相"扫一下"对方的"信用二维码"。

当信任，可以被一个冷冰冰的、外部化的分数，所完全"代理"时，我们，也就逐渐地，丧失了那种去进行真正的、困难的、但却无比宝贵的"人际信任"的能力与意愿。

我们将生活在一个极其"高效"、极其"便利"、风险被极度"最小化"的社会里。在这个社会里，我们与陌生人之间的每一次互动，都被算法那看不见的手，所预先"匹配"和"过滤"了。我们只会遇到那些与我们分数相近的、"安全"的、"可信"的人。

然而，那也将是一个人与人之间，关系变得极其稀薄、情感变得极其廉价、道德判断被外包给机器的、一个"扁平化"的社会。在那里，我们将不再需要去冒险，不再需要去宽恕，不再需要去进行那些建立深度信任所必需的、艰难的"情感劳动"。

我们，将用信任的"便利性"，去交换信任的"深刻性"。我们将用一个看似全知全能的"算法上帝"，去取代我们自己那不完美的、但却无比真实的"人性"。而这笔交易，最终的代价，可能是我们作为一个"道德主体"的、自由而完整的"灵魂"本身。而这或许是所有技术乌托邦，在许下那"终极解决方案"的承诺时，都秘而不宣的、魔鬼的"隐藏条款"。
