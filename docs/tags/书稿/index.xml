<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>书稿 on 祝融说。</title><link>https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/</link><description>Recent content in 书稿 on 祝融说。</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 07 Dec 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/index.xml" rel="self" type="application/rss+xml"/><item><title>第10章 GPU集群的存储设计与实现</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-10/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-10/</guid><description>&lt;p&gt;在前面的章节中，我们已经为GPU集群构建了强大的计算核心（GPU服务器）、高速的内部“神经网络”（计算网络）以及灵活的虚拟“城市规划”（网络虚拟化）。现在，我们来到了构建这个“AI都市”的最后一块，也是同样至关重要的一块基石——存储。&lt;/p&gt;
&lt;p&gt;存储系统是整个GPU集群的“粮仓”和“资料库”。它承载着从操作系统、应用程序、到海量的训练数据集、中间检查点、再到最终生成的模型等所有数据。如果存储系统性能不佳，数据供给跟不上，那么再强大的GPU和再快的网络也只能“望眼欲穿”，整个集群的效率将一落千丈。正如一句行业名言所说：“在高性能计算中，你花在计算上的每一分钱，都得在I/O上花同样的钱来支撑。”&lt;/p&gt;</description></item><item><title>第11章 机器学习应用开发与运行平台的设计与实现</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-11/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-11/</guid><description>&lt;p&gt;在本书的前两个部分，我们已经投入了巨大的精力，完成了从微观到宏观的、全栈式的基础设施建设。我们拥有了顶级的GPU服务器、高速无阻塞的物理网络、灵活安全的虚拟网络、以及分层异构的高性能存储系统。我们还掌握了如何通过虚拟化和容器化技术，将底层的物理资源池化、调度和隔离。至此，我们已经建成了一座基础设施完备、交通发达、能源充足的“AI都市”。&lt;/p&gt;</description></item><item><title>第12章 基于云平台的GPU集群的管理与运营</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-12/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-12/</guid><description>&lt;p&gt;经过前面十一章的艰苦努力，我们已经成功地设计并构建起了一个功能完备、技术先进的大模型算力基础设施。我们拥有了由顶级GPU服务器组成的计算集群，由高速无损网络构成的通信动脉，由分层异构存储组成的强大数据底座，以及一个云原生的、基于微服务的应用开发与运行平台。我们已经建成了这座宏伟的“AI都市”。&lt;/p&gt;</description></item><item><title>第13章 服务机器学习的GPU计算平台落地案例</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-04/chapter-13/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-04/chapter-13/</guid><description>&lt;p&gt;在本书的前三个部分，我们已经系统性地、由浅入深地完成了构建一个大规模GPU计算平台所需的全栈知识体系的学习。我们如同一个学徒，从认识最基础的“砖瓦”（GPU芯片），到学会建造“房屋”（GPU服务器），再到规划整个“城市”的交通（网络）、仓储（存储）、市政（应用平台）与管理（运维运营）。我们已经掌握了所有的理论知识、设计原则和关键技术。&lt;/p&gt;</description></item><item><title>第1章：AI与大模型时代对基础架构的需求</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-01/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-01/</guid><description>&lt;p&gt;随着信息技术的飞速发展，我们正处在一个由数据驱动、智能赋能的全新时代。人工智能（Artificial Intelligence, AI）不再是科幻小说中的遥远构想，而是已经渗透到社会生产、日常生活的方方面面，成为推动第四次工业革命的核心引擎。近年来，以GPT系列、LLaMA等为代表的大规模预训练模型（Large Language Models, LLMs）取得了突破性进展，其强大的自然语言理解、生成、推理能力，以及在多模态领域的延伸，预示着通用人工智能（AGI）的曙光，也由此开启了波澜壮阔的“大模型时代”。&lt;/p&gt;</description></item><item><title>第2章 软件程序与专用硬件的结合</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-02/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-02/</guid><description>&lt;p&gt;在第一章中，我们已经深刻理解了AI及大模型算法对计算硬件的特殊需求，并明确了以GPU为代表的专用硬件为何能成为这个时代的主力计算引擎。我们拥有了强大无比的“发动机”（GPU），但仅仅拥有发动机并不能造出一辆能自由驰骋的汽车。我们还需要传动系统、方向盘、仪表盘，以及最重要的——一位懂得如何驾驶的司机。&lt;/p&gt;</description></item><item><title>第3章 GPU硬件架构剖析</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-03/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-03/</guid><description>&lt;p&gt;在前两章中，我们已经从AI算法的需求和软件堆栈的实现两个维度，理解了为何GPU成为了大模型时代的算力基石。我们知道了GPU擅长大规模并行计算，也了解了CUDA、PyTorch等软件是如何将这种能力释放出来的。然而，对于一个致力于构建顶级算力中心的架构师或工程师而言，仅仅停留在软件抽象层面是远远不够的。如同要造一辆高性能赛车，你必须深入了解其发动机的每一个缸体、每一个活塞、每一条管路。&lt;/p&gt;</description></item><item><title>第4章 GPU服务器的设计与实现</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-04/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-04/</guid><description>&lt;p&gt;在前三章中，我们已经建立了一个自顶向下的完整认知：我们理解了AI大模型对算力的极致渴求，熟悉了驾驭算力的软件栈，也深入剖析了算力之源——GPU芯片的内部微观架构。现在，我们拥有了最强大的发动机（GPU），也知道了如何驾驶它（软件栈）。接下来的任务，就是围绕这颗发动机，设计并制造出一台性能均衡、稳定可靠、能够发挥其极限潜能的超级跑车——GPU服务器。&lt;/p&gt;</description></item><item><title>第5章 机器学习所依托的I/O框架体系</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-05/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-05/</guid><description>&lt;p&gt;在前面的章节中，我们已经深入探索了AI算法、软件框架、GPU微观架构以及GPU服务器的宏观设计。我们拥有了最强大的计算单元（GPU）和承载它们的精密载具（DGX服务器）。然而，一个现代的大规模AI训练集群，远非一堆孤立的服务器。它是一个由成百上千个计算节点、高速网络和海量存储共同组成的、庞大而复杂的分布式系统。&lt;/p&gt;</description></item><item><title>第6章 GPU集群的网络设计与实现</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-06/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-06/</guid><description>&lt;p&gt;在本书的第一部分，我们已经完成了对构建大模型算力中心所需的核心“积木”的深入探索。我们理解了GPU的微观架构，剖析了GPU服务器的系统设计，也掌握了连接这一切的Magnum IO软件I/O框架。我们现在拥有了强大的、经过优化的单体计算节点。&lt;/p&gt;
&lt;p&gt;从本章开始，我们将进入本书的第二部分，将我们的视野从单个节点提升到整个集群的宏观层面。我们的任务，是将成百上千个这样的“超级积木”高效、稳定、可靠地组合起来，构建一个真正意义上的AI超级计算机。这个过程，如同从建造一栋栋独立的别墅，升级到规划和建设一个拥有高速公路、水电管网、商业和住宅区的现代化大都市。&lt;/p&gt;</description></item><item><title>第7章 GPU板卡级算力调度技术</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-07/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-07/</guid><description>&lt;p&gt;在第六章中，我们成功地为GPU集群构建了强大的多平面网络，将成百上千个GPU节点连接成一个统一的整体。现在，我们拥有了一个巨大的、原始的GPU算力池。然而，如何高效、公平、灵活地将这个算力池中的资源分配给众多的用户和任务，成为了我们面临的下一个核心挑战。&lt;/p&gt;</description></item><item><title>第8章 GPU虚拟化调度方案</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-08/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-08/</guid><description>&lt;p&gt;在第七章中，我们已经探讨了“板卡级”的算力调度技术，核心是解决如何将一张物理GPU卡共享给多个虚拟机或容器的问题。我们学习了GPU直通、vGPU、MIG以及基于容器的设备插件等多种技术。这些技术可以被看作是GPU虚拟化的“第一层境界”，它们大多依赖于硬件厂商提供的原生支持，在隔离性、性能和实现方式上各有侧重，但共同的目标是将物理GPU转化为可被上层调度系统识别和分配的、粒度或粗或细的“GPU资源块”。&lt;/p&gt;</description></item><item><title>第9章 GPU集群的网络虚拟化设计与实现</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-09/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-09/</guid><description>&lt;p&gt;在第六章，我们专注于构建GPU集群的物理网络，如同规划了一座拥有高速公路（计算网络）、主干道（存储网络）和市政道路（业务网络）的现代化城市。这个物理网络是所有数据流动的坚实基础。然而，在一个多用户、多任务、多租户的真实云环境中，仅仅拥有一个共享的物理网络是远远不够的。&lt;/p&gt;</description></item><item><title>后记：通往智能的基石，以及未来的地平线</title><link>https://zhurongshuo.com/practices/season-1/a-frightened-bird-at-the-sound-of-a-bow/epilogue/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-1/a-frightened-bird-at-the-sound-of-a-bow/epilogue/</guid><description/></item><item><title>后记：通往智能的基石，以及未来的地平线</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/epilogue/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/epilogue/</guid><description>&lt;p&gt;掩卷沉思，当您读到这里，我们共同的旅程已近终点。这不仅仅是一本书的结束，更希望是您开启一段新征程的起点。我们一起，如同一位耐心的探险家，穿越了AI基础设施这片广袤而深邃的大陆。从第一章仰望大模型时代的璀璨星空，到第十三章亲手构建一座服务于自动驾驶的“算力之城”，我们走过了一条从理想到现实、从抽象到具象的完整路径。&lt;/p&gt;</description></item><item><title>智算中心建设指南：大模型算力的基础架构</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/</guid><description/></item><item><title>第10章：常见故障排查与SRE实践</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-04/chapter-10/</link><pubDate>Sat, 29 Nov 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-04/chapter-10/</guid><description>&lt;p&gt;在第九章中，我们为智算中心安装了强大的“天眼”系统——一个覆盖全链路的可观测性平台。我们现在能够看到硬件的每一次心跳，追踪业务的每一次请求。然而，监控本身并不能解决问题，它只是吹响了战斗的号角。当告警声响起，真正的考验才刚刚开始。&lt;/p&gt;
&lt;p&gt;一个价值数亿元的千卡集群，每宕机一分钟，都意味着数千甚至数万元的算力成本被白白烧掉。作为智算中心的守护者，我们的核心价值不仅在于保障系统“不出事”，更在于出事后能以最快的速度恢复服务（MTTR - Mean Time To Recovery）。这要求我们不仅要熟悉工具，更要具备像急诊医生一样的临床诊断思维：快速分类、定位病灶、对症下药、事后复盘。&lt;/p&gt;</description></item><item><title>第11章：两级智算运营体系设计</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-05/chapter-11/</link><pubDate>Sat, 29 Nov 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-05/chapter-11/</guid><description>&lt;p&gt;在前面的篇章中，我们投入了巨大的精力，构建了一座功能强大的智算“巨舰”。我们精通了它的引擎（GPU/NPU），熟悉了它的航道（网络与存储），掌握了它的驾驶术（调度与并行），甚至还演练了各种紧急情况下的损管流程。现在，是时候为这艘巨舰任命一位“舰长”，并为它制定一套远航的“作战条令”了。&lt;/p&gt;</description></item><item><title>第12章：LLMOps与AI Infra的未来</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-05/chapter-12/</link><pubDate>Sat, 29 Nov 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-05/chapter-12/</guid><description>&lt;p&gt;当我们合上这本书的前十一章时，我们已经共同完成了一段非凡的旅程。我们从最基础的硅芯片出发，穿越了网络、存储、容器、调度的丛林，攀登了训练、推理、监控的险峰，甚至还为我们庞大的智算帝国设计了协同运作的法律（运营体系）和货币（计费模型）。我们已经不仅仅是“会用AI”的人，而是“能支撑起AI”的人。&lt;/p&gt;</description></item><item><title>第1章：智算中心（AIDC）的新范式</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-01/chapter-01/</link><pubDate>Sat, 29 Nov 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-01/chapter-01/</guid><description>&lt;p&gt;欢迎来到智能计算的时代。&lt;/p&gt;
&lt;p&gt;2022年末，随着ChatGPT的横空出世，一场由大型语言模型（LLM）驱动的技术革命席卷全球。它不仅颠覆了我们与信息交互的方式，更深刻地重塑了计算产业的底层逻辑。支撑这场革命的，不再是我们熟悉的、以通用计算为核心的传统数据中心（IDC），而是一种全新的、为海量智能计算量身打造的新型基础设施——智算中心（Artificial Intelligence Data Center, AIDC）。&lt;/p&gt;</description></item></channel></rss>