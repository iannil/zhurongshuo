<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=google-site-verification content="8_xpI-TS3tNV8UPug-Q6Ef3BhKTcy0WOG7dEdAcm2zk"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="祝融"><link rel=dns-prefetch href=//cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=preconnect href=https://www.googletagmanager.com crossorigin><link rel=canonical href=https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-06/><title>祝融说。 第6章 GPU集群的网络设计与实现</title><meta property="og:title" content="第6章 GPU集群的网络设计与实现"><meta property="og:url" content="https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-06/"><meta property="og:site_name" content="祝融说。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:published_time" content="2025-12-07T00:00:00+08:00"><meta property="article:modified_time" content="2025-12-07T00:00:00+08:00"><meta property="article:tag" content="书稿"><meta name=description content="在本书的第一部分，我们已经完成了对构建大模型算力中心所需的核心“积木”的深入探索。我们理解了GPU的微观架构，剖析了GPU服务器的系统设计，也掌握了连接这一切的Magnum IO软件I/O框架。我们现在拥有了强大的、经过优化的单体计算节点。
从本章开始，我们将进入本书的第二部分，将我们的视野从单个节点提升到整个集群的宏观层面。我们的任务，是将成百上千个这样的“超级积木”高效、稳定、可靠地组合起来，构建一个真正意义上的AI超级计算机。这个过程，如同从建造一栋栋独立的别墅，升级到规划和建设一个拥有高速公路、水电管网、商业和住宅区的现代化大都市。
"><meta property="og:description" content="在本书的第一部分，我们已经完成了对构建大模型算力中心所需的核心“积木”的深入探索。我们理解了GPU的微观架构，剖析了GPU服务器的系统设计，也掌握了连接这一切的Magnum IO软件I/O框架。我们现在拥有了强大的、经过优化的单体计算节点。
从本章开始，我们将进入本书的第二部分，将我们的视野从单个节点提升到整个集群的宏观层面。我们的任务，是将成百上千个这样的“超级积木”高效、稳定、可靠地组合起来，构建一个真正意义上的AI超级计算机。这个过程，如同从建造一栋栋独立的别墅，升级到规划和建设一个拥有高速公路、水电管网、商业和住宅区的现代化大都市。
"><meta property="og:image" content="https://zhurongshuo.com/images/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="第6章 GPU集群的网络设计与实现"><meta name=twitter:description content="在本书的第一部分，我们已经完成了对构建大模型算力中心所需的核心“积木”的深入探索。我们理解了GPU的微观架构，剖析了GPU服务器的系统设计，也掌握了连接这一切的Magnum IO软件I/O框架。我们现在拥有了强大的、经过优化的单体计算节点。
从本章开始，我们将进入本书的第二部分，将我们的视野从单个节点提升到整个集群的宏观层面。我们的任务，是将成百上千个这样的“超级积木”高效、稳定、可靠地组合起来，构建一个真正意义上的AI超级计算机。这个过程，如同从建造一栋栋独立的别墅，升级到规划和建设一个拥有高速公路、水电管网、商业和住宅区的现代化大都市。
"><meta name=twitter:image content="https://zhurongshuo.com/images/favicon.ico"><meta name=keywords content="智算中心建设指南：大模型算力的基础架构,第6章 GPU集群的网络设计与实现"><link rel="shortcut icon" href=https://zhurongshuo.com/images/favicon.ico><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/animate-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/zozo.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/remixicon-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/highlight.css><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"第6章 GPU集群的网络设计与实现","description":"在本书的第一部分，我们已经完成了对构建大模型算力中心所需的核心“积木”的深入探索。我们理解了GPU的微观架构，剖析了GPU服务器的系统设计，也掌握了连接这一切的Magnum IO软件I\/O框架。我们现在拥有了强大的、经过优化的单体计算节点。\n从本章开始，我们将进入本书的第二部分，将我们的视野从单个节点提升到整个集群的宏观层面。我们的任务，是将成百上千个这样的“超级积木”高效、稳定、可靠地组合起来，构建一个真正意义上的AI超级计算机。这个过程，如同从建造一栋栋独立的别墅，升级到规划和建设一个拥有高速公路、水电管网、商业和住宅区的现代化大都市。\n","datePublished":"2025-12-07T00:00:00\u002b08:00","dateModified":"2025-12-07T00:00:00\u002b08:00","author":{"@type":"Person","name":"祝融"},"publisher":{"@type":"Organization","name":"祝融说。","logo":{"@type":"ImageObject","url":"https:\/\/zhurongshuo.com\/images\/favicon.ico"}},"image":"https:\/\/zhurongshuo.com\/images\/favicon.ico","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zhurongshuo.com\/practices\/season-4\/intelligent-computing-center-construction-guide\/part-02\/chapter-06\/"},"keywords":"书稿"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"首页","item":"https:\/\/zhurongshuo.com\/"},{"@type":"ListItem","position":2,"name":"practices","item":"https:\/\/zhurongshuo.com\/practices/"},{"@type":"ListItem","position":3,"name":"第6章 GPU集群的网络设计与实现","item":"https:\/\/zhurongshuo.com\/practices\/season-4\/intelligent-computing-center-construction-guide\/part-02\/chapter-06\/"}]}</script></head><body><div class="main animate__animated animate__fadeInDown"><div class="nav_container animated fadeInDown"><div class=site_nav id=site_nav><ul><li><a href=https://zhurongshuo.com/>首页</a></li><li><a href=https://zhurongshuo.com/start/>开始</a></li><li><a href=https://zhurongshuo.com/advanced/>进阶rc</a></li><li><a href=https://zhurongshuo.com/posts/>归档</a></li><li><a href=https://zhurongshuo.com/tags/>标签</a></li><li><a href=https://zhurongshuo.com/about/>关于</a></li></ul></div><div class=menu_icon><a id=menu_icon><i class=ri-menu-line></i></a></div></div><div class="header animated fadeInDown"><div class=site_title_container><div class=site_title><h1><a href=https://zhurongshuo.com/><span class=web-font>祝融说。</span></a></h1></div><div class=description><p class=sub_title>法不净空，觉无性也。</p><div class=my_socials><a href=https://zhurongshuo.com/books/ title=book-open><i class=ri-book-open-line></i></a>
<a href=https://zhurongshuo.com/practices/ title=trophy><i class=ri-trophy-line></i></a>
<a href=https://zhurongshuo.com/gallery/ title=gallery><i class=ri-gallery-line></i></a>
<a href=https://zhurongshuo.com/about/ title=game><i class=ri-game-line></i></a>
<a href type=application/rss+xml title=rss target=_blank><i class=ri-rss-fill></i></a></div></div></div></div><div class=content><div class=post_page><div class="post animate__animated animate__fadeInDown"><div class="post_title post_detail_title"><h2><a href=https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-06/>第6章 GPU集群的网络设计与实现</a></h2><span class=date>2025.12.07</span></div><div class="post_content markdown"><p>在本书的第一部分，我们已经完成了对构建大模型算力中心所需的核心“积木”的深入探索。我们理解了GPU的微观架构，剖析了GPU服务器的系统设计，也掌握了连接这一切的Magnum IO软件I/O框架。我们现在拥有了强大的、经过优化的单体计算节点。</p><p>从本章开始，我们将进入本书的第二部分，将我们的视野从单个节点提升到整个集群的宏观层面。我们的任务，是将成百上千个这样的“超级积木”高效、稳定、可靠地组合起来，构建一个真正意义上的AI超级计算机。这个过程，如同从建造一栋栋独立的别墅，升级到规划和建设一个拥有高速公路、水电管网、商业和住宅区的现代化大都市。</p><p>网络，无疑是这个“AI都市”中最重要的基础设施。它如同城市的交通动脉，承载着数据、梯度、模型参数、控制信令等各种“车流”在不同的功能区域之间穿梭。网络的设计优劣，直接决定了整个集群的扩展效率、稳定性和整体性能。一个设计糟糕的网络，会使得昂贵的GPU集群因为通信瓶颈而性能大打折扣，如同将无数辆法拉利跑车投入到一个没有红绿灯、处处是断头路的城市，其结果必然是无尽的拥堵和混乱。</p><p>本章——《GPU集群的网络设计与实现》——将作为第二部分的开篇，专注于构建这个至关重要的“交通网络”。我们将从一个网络架构师的视角，系统性地探讨如何为一个大规模GPU集群设计和实现一个多平面、高可用、无瓶颈的网络架构。</p><p>我们将遵循“分而治之”的设计原则，将复杂的集群网络划分为四个逻辑上独立、物理上可能融合的网络平面：</p><ol><li>计算网络（Compute Fabric）：这是为分布式训练中GPU之间的梯度同步和模型参数交换而生的“高速公路”，对低延迟、高带宽和无损传输有极致要求。我们将以RoCE（RDMA over Converged Ethernet）为例，详细阐述其设计与实现。</li><li>存储网络（Storage Fabric）：负责连接计算节点与后端的分布式存储系统，为海量训练数据的加载提供持续、高带宽的数据流。</li><li>业务网络（Business/Application Network）：为除了AI训练之外的其他应用（如API服务、用户访问、数据分析等）提供通用、可靠的网络连接。</li><li>带外管理/监控网络（Out-of-Band Management/Monitoring Network）：这是集群的“生命维持系统”，独立于所有数据网络，负责所有硬件设备的远程管理、监控和故障排查。</li></ol><p>此外，我们还将讨论网络边界（Network Boundary）的设计，即集群如何与外部世界（如公网、企业内网）安全、高效地连接。</p><p>通过本章的学习，你将掌握一套完整的GPU集群网络设计方法论，理解多平面网络架构的必要性，并能深入到每个平面的具体技术选型（如Clos架构、ECMP、PFC/ECN等）和实现细节中。这将为你构建一个稳定、高效、可扩展的大模型算力奠定坚实的网络基础。</p><h2 id=61-gpu集群中roce计算网络的设计与实现>6.1 GPU集群中RoCE计算网络的设计与实现</h2><p>计算网络是GPU集群中性能要求最高、设计最关键的网络平面。它的唯一使命，就是为大规模分布式训练中GPU之间的密集通信提供一个超低延迟、超高带宽、无阻塞的通信底座。正如我们在第五章所讨论的，实现这一目标的技术核心是RDMA，而RoCE（RDMA over Converged Ethernet）因其对以太网生态的兼容性，成为了许多企业构建AI集群的热门选择。</p><p>然而，在以太网上实现高性能、大规模的RDMA，是一项极具挑战性的系统工程。本节将详细阐述构建一个成功的RoCE计算网络所需的设计原则、核心技术和实现步骤。</p><h3 id=611-设计原则为无损和低延迟而生>6.1.1 设计原则：为无损和低延迟而生</h3><p>一个RoCE计算网络的设计，必须遵循以下几个核心原则：</p><ol><li>无损（Lossless）：这是首要原则。传统以太网的丢包行为对RDMA是致命的。我们必须通过技术手段，将底层网络改造为“无损网络”，确保数据包不会因为拥塞而被交换机丢弃。</li><li>低延迟（Low Latency）：分布式训练的性能对通信延迟极度敏感。网络设计的每一个环节，从拓扑结构、交换机选型到布线，都必须以最小化端到端的延迟为目标。</li><li>高带宽（High Bandwidth）：网络必须能够提供与GPU节点网卡速率（如200Gbps或400Gbps）相匹配的、无阻塞的带宽。</li><li>可扩展性（Scalability）：网络架构必须能够支持未来集群规模的平滑扩展，从几十个节点扩展到上千个节点，而无需对核心架构进行颠覆性改造。</li><li>高可用性（High Availability）：网络中的任何单点故障（如交换机、链路）都不应该导致整个计算网络的中断。</li></ol><h3 id=612-核心技术之一clos网络架构>6.1.2 核心技术之一：Clos网络架构</h3><p>要满足高带宽、可扩展性和无阻塞的要求，现代数据中心网络普遍采用Clos架构（也称为Spine-Leaf架构或Fat-Tree架构）。</p><p>架构组成：Clos架构由两层交换机组成：</p><p>叶交换机（Leaf Switches）：位于网络底层，直接连接服务器节点（GPU服务器）。每个服务器通常会以冗余的方式连接到两个不同的叶交换机。</p><p>脊交换机（Spine Switches）：位于网络上层，不连接任何服务器。它的唯一作用是连接所有的叶交换机。在一个严格的Clos架构中，每一个叶交换机都必须连接到每一个脊交换机。</p><p>数据路径：</p><p>服务器之间的通信，永远只经过“一上一下”两跳：<code>服务器A -> 叶交换机A -> 脊交换机 -> 叶交换机B -> 服务器B</code>。任意两个服务器之间的路径长度都是固定的（三跳：服务器->叶->脊->叶->服务器），这保证了通信延迟的可预测性。
叶交换机之间不直接相连，所有跨叶交换机的流量都必须经过脊交换机。</p><p>Clos架构的优势：</p><p>无阻塞带宽：通过精心计算和配置上行链路（Leaf-Spine）与下行链路（Leaf-Server）的带宽比（Over-subscription Ratio），可以实现一个理论上无阻塞的网络。例如，如果一个叶交换机有24个连接服务器的下行端口和24个连接脊交换机的上行端口，且所有端口速率相同，那么其超订比就是1:1，即无阻塞。</p><p>负载均衡与多路径：从一个叶交换机到另一个叶交换机，存在多条通过不同脊交换机的等价路径。网络可以利用等价多路径路由（ECMP, Equal-Cost Multi-Path）技术，将流量哈希到这些路径上，实现负载均衡和带宽聚合。</p><p>高可扩展性：</p><p>要增加服务器容量，只需增加新的叶交换机，并将其连接到所有脊交换机即可。</p><p>当叶交换机数量增多，导致脊交换机的端口不足时，可以增加新的脊交换机。</p><p>对于超大规模集群，还可以构建一个三层Clos架构（Leaf-Spine-SuperSpine），进一步提升扩展能力。</p><p>高可用性：任何一台脊交换机或叶交换机故障，流量都可以通过ECMP自动切换到其他健康路径上，不会造成服务中断。</p><h3 id=613-核心技术之二实现无损以太网>6.1.3 核心技术之二：实现无损以太网</h3><p>在Clos架构这个骨架之上，我们需要填充“血肉”，即实现无损传输的技术细节。这主要依赖于PFC和ECN的协同工作。</p><h4 id=pfc-priority-based-flow-control-ieee-8021qbb基于优先级的流量控制>PFC (Priority-based Flow Control, IEEE 802.1Qbb)：基于优先级的流量控制</h4><p>工作原理：PFC将传统的以太网<code>PAUSE</code>帧机制（会暂停链路上所有流量）进行了细化。它允许我们将流量划分为最多8个不同的优先级（Priority Class, PC），并为每个优先级独立地应用流量控制。</p><p>在RoCE中的应用：我们通常会为RoCE流量分配一个专门的、高优先级的PC（例如PC 3）。当一个交换机的出端口上，用于PC 3的缓冲区即将被填满时，交换机会向其上游设备（另一个交换机或服务器网卡）发送一个针对PC 3的PFC <code>PAUSE</code>帧。上游设备收到后，会暂停发送所有属于PC 3的流量，但其他优先级的流量（如管理流量、TCP流量）则不受影响。</p><p>作用：PFC是防止因瞬时拥塞导致RoCE数据包被丢弃的第一道防线。</p><h4 id=ecn-explicit-congestion-notification-rfc-3168显式拥塞通知>ECN (Explicit Congestion Notification, RFC 3168)：显式拥塞通知</h4><p>PFC的风险：PFC虽然能防止丢包，但它也可能引入新的问题。如果拥塞持续存在，PFC <code>PAUSE</code>帧会不断向上游传播，可能导致大面积的网络“暂停”，甚至引发PFC风暴或死锁。PFC只解决了“堵”的问题，没有解决“疏”的问题。</p><p>ECN的工作原理：ECN提供了一种主动的拥塞管理机制。交换机被配置一个缓冲区阈值（ECN marking threshold）。当某个队列的缓冲区占用超过这个阈值时，交换机不会立即暂停流量，而是在流经该队列的IP包头中设置一个“拥塞经历（Congestion Experienced, CE）”标记。</p><p>数据包到达最终的目的地网卡后，网卡会检测到这个CE标记，并通过一个特殊的拥塞通知包（Congestion Notification Packet, CNP）将拥塞信号反馈给原始的发送方。</p><p>发送方收到CNP后，会主动、临时地降低其发送速率，从而缓解网络拥塞。</p><p>DCQCN (Data Center Quantized Congestion Notification)：这是目前RoCE网络中广泛使用的、结合了ECN和PFC的先进拥塞控制算法。它精确地定义了如何根据收到的CNP来调整发送速率，以及如何与PFC协同工作。</p><h4 id=pfc与ecn的协同>PFC与ECN的协同</h4><p>ECN是主动的、端到端的拥塞控制机制，它试图在拥塞发生的早期就通过降速来“疏导”流量，是解决拥塞的主要手段。</p><p>PFC是被动的、逐跳的拥塞避免机制，它是在ECN来不及反应或拥塞极其严重时的最后一道保险，通过暂停来“堵住”流量，防止丢包。
一个健康的RoCE网络，应该绝大部分时间都依靠ECN来工作，PFC的触发应该是小概率事件。</p><h3 id=614-roce计算网络的实现步骤>6.1.4 RoCE计算网络的实现步骤</h3><h4 id=物理设计>物理设计</h4><ul><li>拓扑：设计一个满足未来扩展需求的、超订比尽可能低的（理想为1:1）Spine-Leaf Clos架构。</li><li>设备选型：选择支持PFC和ECN、拥有大且动态的缓冲区、低延迟、高端口速率（200G/400G）的数据中心交换机（如NVIDIA Spectrum系列、Arista、Cisco Nexus等）。选择与GPU服务器配套的高性能RoCE网卡（如NVIDIA ConnectX系列）。</li><li>布线：使用高质量的光纤和光模块，精确计算长度，确保信号质量。所有布线应整洁、有序，并做好标识。</li></ul><h4 id=逻辑配置>逻辑配置</h4><ul><li>交换机配置：这是最复杂的部分。<ul><li>启用PFC，并为RoCE流量（通常通过DSCP值来识别）分配一个专门的、无损的优先级。</li><li>启用ECN，并为无损队列配置合适的ECN标记阈值。</li></ul></li><li>配置DCQCN或其他拥塞控制算法。<ul><li>配置VLAN、IP地址、BGP（通常用于在Spine和Leaf之间通告路由）等基础网络参数。</li><li>配置ECMP，确保流量能够被均匀地哈希到所有可用路径上。</li></ul></li><li>服务器配置：<ul><li>在操作系统中安装和配置网卡驱动及RDMA相关软件包。</li><li>配置服务器网卡，使其发出的RoCE流量带有正确的DSCP值，以便被交换机识别并放入无损队列。</li><li>配置服务器端的拥塞控制，使其能够响应ECN信号。</li></ul></li></ul><h4 id=测试与验证>测试与验证</h4><p>基础连通性测试：使用<code>ping</code>, <code>ib_write_bw</code>, <code>ib_write_lat</code>等工具测试节点之间的基本连通性、带宽和延迟。</p><p>拥塞测试：使用专门的工具（如<code>nd_stress</code>）模拟多种拥塞场景（如Incast拥塞），验证PFC和ECN是否按预期工作，网络是否真的无损。</p><p>应用层测试：运行小规模的<code>All-Reduce</code>基准测试（如<code>nccl-tests</code>），检查在实际应用负载下的网络性能。</p><h4 id=监控与调优>监控与调优</h4><p>部署网络监控系统，持续收集交换机和网卡的各项指标，特别是PFC <code>PAUSE</code>帧的计数、ECN标记计数、缓冲区占用率等。</p><p>通过分析这些指标，可以判断网络是否存在潜在的拥塞点或配置问题，并进行持续的调优。</p><p>构建一个成功的RoCE计算网络，需要网络、系统、AI应用团队的紧密合作，是一个集设计、实现、测试、监控于一体的闭环工程。</p><h2 id=62-gpu集群中存储与业务网络的设计与实现>6.2 GPU集群中存储与业务网络的设计与实现</h2><p>虽然计算网络是性能皇冠上的明珠，但存储网络和业务网络同样是维持集群健康、高效运转不可或缺的部分。将它们与计算网络进行逻辑上甚至物理上的分离，是一种优秀的设计实践。</p><h3 id=621-为何要分离网络平面>6.2.1 为何要分离网络平面？</h3><h4 id=需求差异巨大>需求差异巨大</h4><p>计算网络：追求极致的低延迟和无损传输，流量模型主要是GPU之间的大块、突发性RDMA流量。</p><p>存储网络：追求高吞吐量和稳定性，流量模型主要是计算节点与存储节点之间持续、大块的数据读写。</p><p>业务网络：追求通用性和可靠性，流量模型复杂多变，包含大量的小包、TCP连接。</p><h4 id=避免干扰>避免干扰</h4><p>如果将所有流量都混合在同一个网络中，可能会发生“劣币驱逐良币”的现象。例如，一个突发的TCP流量风暴，可能会抢占交换机缓冲区，影响到对延迟极度敏感的RoCE流量，导致分布式训练性能抖动。</p><h4 id=简化管理与安全>简化管理与安全</h4><p>分离的网络平面使得每个网络的配置和优化可以独立进行。例如，我们只需要在计算网络中配置复杂的无损以太网技术，而存储和业务网络则可以使用更简单的标准以太网配置。同时，这也便于通过防火墙和访问控制列表（ACL）在不同网络平面之间实现安全隔离。</p><h3 id=622-存储网络的设计与实现>6.2.2 存储网络的设计与实现</h3><p>存储网络的目标是为GPU节点提供到后端分布式存储系统的高速、可靠连接。</p><p>流量特征：主要是计算节点（客户端）到存储节点（服务器）之间的大块、持续性读写流量。对带宽的要求很高，但对延迟的敏感度低于计算网络。</p><p>技术选型：</p><ul><li>网络协议：存储网络通常也运行在以太网上。根据后端存储系统的不同，上层协议可能是标准的TCP/IP（用于连接NFS或基于S3的对象存储），也可能是RDMA（用于连接支持NVMe-oF over RoCE/InfiniBand的高性能存储）。</li><li>拓扑架构：同样可以采用Spine-Leaf Clos架构。一个典型的设计是，计算节点作为Leaf下的服务器，而分布式存储系统的存储节点也作为另一组Leaf下的服务器，接入到同一个Spine-Leaf网络中。</li><li>带宽与收敛比：存储网络的带宽设计需要仔细规划。需要估算所有计算节点在满负荷进行数据加载时，可能产生的总存储I/O带宽需求，并确保网络的聚合带宽能够满足这个需求。存储网络的超订比可以比计算网络稍高一些（例如1:3或1:4），因为通常不是所有计算节点都会在同一时刻达到峰值存储I/O。</li></ul><p>实现要点：</p><ul><li>大帧（Jumbo Frames）：在存储网络中启用MTU为9000字节的大帧，可以显著提升大块数据传输的效率。因为同样传输1MB的数据，使用大帧所需的数据包数量和包头开销都远少于标准的1500字节MTU。</li><li>链路聚合（LAG/LACP）：可以将计算节点或存储节点到叶交换机的多条物理链路捆绑成一个逻辑链路，以增加带宽和提供链路冗余。</li><li>流量整形与QoS：如果存储网络与业务网络在物理上共享（例如使用VLAN进行逻辑隔离），则需要配置QoS策略，确保高优先级的存储流量不会被低优先级的业务流量影响。</li></ul><h3 id=623-业务网络的设计与实现>6.2.3 业务网络的设计与实现</h3><p>业务网络是一个通用的数据平面，承载着除了计算和存储之外的所有其他业务流量。</p><p>流量类型：</p><ul><li>模型服务（Inference）：如果集群也用于提供在线推理服务，那么来自用户的API请求和模型的响应就在业务网络上传输。</li><li>用户访问：用户通过SSH登录到计算节点进行开发和调试，流量走业务网络。</li><li>数据分析与可视化：Jupyter Notebook、TensorBoard等服务的Web访问流量。</li><li>应用间通信：集群中各种微服务之间的通信。</li><li>连接外部数据源：从互联网或企业内网下载数据、代码、Docker镜像等。</li></ul><p>设计原则：业务网络设计的首要原则是可靠性、通用性和安全性。</p><p>拓扑：同样可以采用Spine-Leaf架构，与存储网络共享物理基础设施是一种常见的、节约成本的做法。</p><p>带宽：业务网络的带宽需求通常远低于计算和存储网络。10Gbps或25Gbps的接口通常就足够了。</p><p>可靠性：必须考虑高可用性，所有网络设备（交换机、链路）都应有冗余。</p><p>安全性：业务网络是集群与外部世界连接的主要通道，因此是安全防护的重点。需要在此网络上部署防火墙、ACL等安全策略。</p><h2 id=63-gpu集群中带外管理监控网络的设计与实现>6.3 GPU集群中带外管理监控网络的设计与实现</h2><p>带外管理（Out-of-Band, OOB）网络是整个集群的“生命线”，其重要性再怎么强调也不为过。它是一个完全独立于所有数据网络（计算、存储、业务）的、专用的管理通道。</p><h3 id=631-独立性的至关重要性>6.3.1 独立性的至关重要性</h3><p>想象一下，如果一个计算节点的业务网卡驱动崩溃，或者交换机的配置错误导致整个数据网络瘫痪，你将如何登录到这台服务器去排查问题？如果管理通道也依赖于这个瘫痪的数据网络，那么你将对这台服务器彻底“失联”，唯一的办法就是派人到机房现场去插显示器和键盘。</p><p>OOB网络的价值就在于，无论数据网络发生了多么严重的故障，只要服务器插着电、连着OOB网线，管理员就始终拥有一条通向设备“大脑”——BMC（基板管理控制器）——的可靠路径。</p><h3 id=632-oob网络的设计与实现>6.3.2 OOB网络的设计与实现</h3><p>拓扑与设备：</p><ul><li>OOB网络通常是一个非常简单的、低成本的星型或树形拓扑。</li><li>使用专门的、便宜的1GbE或10GbE的管理交换机。为了高可用，通常也会部署一对冗余的管理交换机。</li><li>集群中的每一个设备（包括GPU服务器的BMC端口、所有计算/存储/业务交换机的管理端口、PDU、存储控制器等）都必须连接到OOB网络。</li></ul><p>功能：</p><p>OOB网络承载了所有基础设施的管理和监控流量：</p><ul><li>远程管理：<ul><li>通过IPMI或Redfish协议对服务器进行开关机、固件升级、硬件配置等操作。</li><li>通过KVM over IP进行远程桌面访问。</li><li>自动化部署：使用PXE（Preboot Execution Environment）通过OOB网络进行操作系统的自动化安装。</li></ul></li><li>监控数据采集：<ul><li>Prometheus、Zabbix等监控系统通过OOB网络，从服务器的BMC、交换机等设备上采集硬件状态信息（温度、功耗、风扇转速、硬件故障日志等）。</li><li>这是实现集群健康状态全局可视化的基础。</li></ul></li><li>配置管理：Ansible、SaltStack等自动化运维工具通过OOB网络，向所有设备推送配置变更。</li><li>安全性：<ul><li>OOB网络拥有对所有基础设施的最高控制权限，因此必须是整个数据中心安全级别最高、隔离最严格的网络。</li><li>它必须与所有数据网络在物理上完全隔离。</li><li>访问OOB网络的权限必须受到严格控制，通常需要通过一个安全的堡垒机（Jump Host）进行跳转。</li></ul></li></ul><p>一个设计良好、稳定可靠的OOB网络，是实现大规模集群自动化、智能化运维（AIOps）的前提和基础。</p><h2 id=64-gpu集群中网络边界的设计与实现>6.4 GPU集群中网络边界的设计与实现</h2><p>网络边界是GPU集群与外部世界连接的关口。如何设计这个边界，决定了集群的安全性、可访问性和与外部服务的集成能力。</p><h3 id=641-边界的功能与挑战>6.4.1 边界的功能与挑战</h3><p>网络边界需要承载多种类型的内外流量：</p><p>出向流量（Egress）：</p><ul><li>集群内的应用需要访问互联网，下载软件包、Docker镜像、预训练模型等。</li><li>训练任务可能需要将日志、指标等数据推送到外部的监控或存储系统。</li></ul><p>入向流量（Ingress）：</p><ul><li>用户和管理员需要从企业内网或公网访问集群。</li><li>如果集群提供API服务，外部用户需要能够访问这些服务。</li></ul><p>挑战：</p><ul><li>安全：如何在提供必要连接的同时，保护集群免受来自外部的攻击？</li><li>性能：如何为合法的内外流量提供足够的带宽，使其不会成为瓶颈？</li><li>管理：如何对进出集群的流量进行审计和控制？</li></ul><h3 id=642-边界设计的典型架构>6.4.2 边界设计的典型架构</h3><p>一个常见的边界设计架构是采用一个多层的、纵深防御的模型。</p><h4 id=边界路由器edge-routers>边界路由器（Edge Routers）</h4><p>这是集群与外部网络（如运营商网络、企业骨干网）连接的第一跳。</p><p>通常会部署一对冗余的、高性能的边界路由器，它们通过BGP协议与外部世界交换路由信息。</p><h4 id=防火墙firewalls>防火墙（Firewalls）</h4><p>位于边界路由器之后，是安全防护的核心。</p><p>所有进出集群的流量都必须经过防火墙的策略检查。可以部署下一代防火墙（NGFW），提供状态检测、入侵防御（IPS）、应用识别等高级功能。</p><p>为了性能，通常会部署一个高吞吐量的防火墙集群。</p><h4 id=负载均衡器load-balancers>负载均衡器（Load Balancers）</h4><p>对于需要对外提供服务的应用（如API推理服务），负载均衡器是必不可少的。</p><p>它接收来自外部的请求，并根据一定的策略（如轮询、最少连接数）将请求分发到后端的多台服务器上，实现服务的水平扩展和高可用。</p><p>可以部署硬件负载均衡器（如F5, A10）或软件负载均衡器（如HAProxy, Nginx）。</p><h4 id=dmzdemilitarized-zone隔离区>DMZ（Demilitarized Zone，隔离区）</h4><p>为了进一步增强安全性，可以将那些需要直接暴露给外部访问的服务器（如Web服务器、API网关、堡垒机）放置在一个称为DMZ的特殊网络区域。</p><p>DMZ区域与集群内部的核心网络（如计算网络、存储网络）以及外部的互联网之间，都有防火墙进行严格隔离。即使DMZ中的服务器被攻破，攻击者也难以直接渗透到核心网络。</p><h4 id=nat网关network-address-translation-gateway>NAT网关（Network Address Translation Gateway）</h4><p>集群内部的服务器通常使用私有IP地址。当它们需要访问互联网时，其流量需要经过NAT网关，将其私有IP地址转换为一个或多个公有IP地址。</p><p>NAT网关可以集中管理和审计集群的出向流量。</p><h3 id=643-将各网络平面连接到边界>6.4.3 将各网络平面连接到边界</h3><p>业务网络是连接到边界的主要网络。用户的SSH访问、应用的API服务等，都通过业务网络，经过防火墙和负载均衡器与外部通信。</p><p>存储网络和计算网络通常不应该直接暴露给外部，它们应该被严格地隔离在集群内部。</p><p>OOB管理网络绝对不能直接连接到外部互联网。对OOB网络的远程访问，必须通过一个位于DMZ的、经过多重安全加固的堡垒机进行跳转。</p><h2 id=65-本章小结>6.5 本章小结</h2><p>在本章中，我们完成了从单个GPU服务器到构建一个完整GPU集群的关键一步——网络设计与实现。我们深刻认识到，网络是连接数千个计算、存储和管理单元的“神经系统”，其设计的成败直接关系到整个AI集群的性能、稳定性和可扩展性。</p><p>我们采用了多平面网络这一核心设计思想，将复杂的集群网络分解为四个目标明确、功能独立的逻辑平面，并深入探讨了每个平面的设计精髓：</p><ol><li>在计算网络中，我们以RoCE为例，系统地学习了如何构建一个为RDMA而生的无损、低延迟网络。我们掌握了其两大核心技术：Clos（Spine-Leaf）架构提供了无阻塞、可扩展的物理骨架；而PFC与ECN的协同工作则是在以太网上实现无损传输的关键“魔法”，前者是最后的保险，后者是主动的拥塞疏导。</li><li>在存储网络与业务网络的设计中，我们强调了将它们与计算网络分离的重要性，以避免性能干扰并简化管理。我们了解了存储网络对高吞吐量的追求，以及业务网络对通用性、可靠性和安全性的侧重。</li><li>在带外管理监控网络中，我们认识到其物理上的完全独立性是实现集群高可用运维和故障快速响应的生命线。它是连接所有设备BMC的“最后一道保险”，是实现自动化部署、监控和配置管理的基础。</li><li>最后，在网络边界的设计上，我们学习了如何通过防火墙、负载均衡器、DMZ等组件，构建一个纵深防御的安全体系，在保证集群与外部必要连接的同时，最大限度地抵御安全风险。</li></ol><p>通过本章的学习，我们不再将集群网络看作一堆交换机和线缆的简单堆砌，而是能够以一个系统架构师的视角，进行全局规划、分层设计和技术权衡。我们获得了一套行之有效的方法论，无论是选择InfiniBand还是RoCE，无论是规划两层Clos还是三层Clos，我们都能从性能、成本、可扩展性、可维护性等多个维度，为特定规模和需求的GPU集群，设计出最合适的网络解决方案。</p><p>这套坚实的网络基础，将为我们接下来在第二部分探讨的更上层的集群资源管理与虚拟化技术，提供一个稳定、高效的运行平台。</p></div><div class=post_footer><div class=meta><div class=info><span class="field tags"><i class=ri-stack-line></i>
<a href=https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/>书稿</a></span></div></div></div></div><div class=doc_comments></div></div></div></div><a id=back_to_top href=# class=back_to_top><i class=ri-arrow-up-s-line></i></a><footer class=footer><div class=powered_by><a href=https://varkai.com>Designed by VarKai, </a><a href=http://www.gohugo.io/>Proudly published with Hugo,</a></div><div class=footer_slogan><span>法不净空，觉无性也。</span></div><div class=powered_by style=margin-top:10px;font-size:14px><a href=https://zhurongshuo.com/>Copyright © 2010-2025 祝融说 zhurongshuo.com All Rights Reserved.</a></div></footer><script defer src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><link href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.css rel=stylesheet integrity="sha256-7qiTu3a8qjjWtcX9w+f2ulVUZSUdCZFEK62eRlmLmCE=" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script defer src=https://zhurongshuo.com/js/zozo.js></script><script type=text/javascript async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script>window.GA_MEASUREMENT_ID="G-KKJ5ZEG1NB",window.GA_CONFIG={enableReadingTime:!0,enableScrollDepth:!0,enableOutboundLinks:!0,enableDownloads:!0,lazyLoadTimeout:3e3}</script><script defer src=https://zhurongshuo.com/js/ga-optimizer.js></script></body></html>