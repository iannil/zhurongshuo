<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=google-site-verification content="8_xpI-TS3tNV8UPug-Q6Ef3BhKTcy0WOG7dEdAcm2zk"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="祝融"><link rel=dns-prefetch href=//cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=preconnect href=https://www.googletagmanager.com crossorigin><link rel=canonical href=https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-12/><title>祝融说。 第12章 基于云平台的GPU集群的管理与运营</title><meta property="og:title" content="第12章 基于云平台的GPU集群的管理与运营"><meta property="og:url" content="https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-12/"><meta property="og:site_name" content="祝融说。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:published_time" content="2025-12-07T00:00:00+08:00"><meta property="article:modified_time" content="2025-12-07T00:00:00+08:00"><meta property="article:tag" content="书稿"><meta name=description content="经过前面十一章的艰苦努力，我们已经成功地设计并构建起了一个功能完备、技术先进的大模型算力基础设施。我们拥有了由顶级GPU服务器组成的计算集群，由高速无损网络构成的通信动脉，由分层异构存储组成的强大数据底座，以及一个云原生的、基于微服务的应用开发与运行平台。我们已经建成了这座宏伟的“AI都市”。
"><meta property="og:description" content="经过前面十一章的艰苦努力，我们已经成功地设计并构建起了一个功能完备、技术先进的大模型算力基础设施。我们拥有了由顶级GPU服务器组成的计算集群，由高速无损网络构成的通信动脉，由分层异构存储组成的强大数据底座，以及一个云原生的、基于微服务的应用开发与运行平台。我们已经建成了这座宏伟的“AI都市”。
"><meta property="og:image" content="https://zhurongshuo.com/images/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="第12章 基于云平台的GPU集群的管理与运营"><meta name=twitter:description content="经过前面十一章的艰苦努力，我们已经成功地设计并构建起了一个功能完备、技术先进的大模型算力基础设施。我们拥有了由顶级GPU服务器组成的计算集群，由高速无损网络构成的通信动脉，由分层异构存储组成的强大数据底座，以及一个云原生的、基于微服务的应用开发与运行平台。我们已经建成了这座宏伟的“AI都市”。
"><meta name=twitter:image content="https://zhurongshuo.com/images/favicon.ico"><meta name=keywords content="智算中心建设指南：大模型算力的基础架构,第12章 基于云平台的GPU集群的管理与运营"><link rel="shortcut icon" href=https://zhurongshuo.com/images/favicon.ico><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/animate-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/zozo.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/remixicon-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/highlight.css><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"第12章 基于云平台的GPU集群的管理与运营","description":"经过前面十一章的艰苦努力，我们已经成功地设计并构建起了一个功能完备、技术先进的大模型算力基础设施。我们拥有了由顶级GPU服务器组成的计算集群，由高速无损网络构成的通信动脉，由分层异构存储组成的强大数据底座，以及一个云原生的、基于微服务的应用开发与运行平台。我们已经建成了这座宏伟的“AI都市”。\n","datePublished":"2025-12-07T00:00:00\u002b08:00","dateModified":"2025-12-07T00:00:00\u002b08:00","author":{"@type":"Person","name":"祝融"},"publisher":{"@type":"Organization","name":"祝融说。","logo":{"@type":"ImageObject","url":"https:\/\/zhurongshuo.com\/images\/favicon.ico"}},"image":"https:\/\/zhurongshuo.com\/images\/favicon.ico","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zhurongshuo.com\/practices\/season-4\/intelligent-computing-center-construction-guide\/part-03\/chapter-12\/"},"keywords":"书稿"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"首页","item":"https:\/\/zhurongshuo.com\/"},{"@type":"ListItem","position":2,"name":"practices","item":"https:\/\/zhurongshuo.com\/practices/"},{"@type":"ListItem","position":3,"name":"第12章 基于云平台的GPU集群的管理与运营","item":"https:\/\/zhurongshuo.com\/practices\/season-4\/intelligent-computing-center-construction-guide\/part-03\/chapter-12\/"}]}</script></head><body><div class="main animate__animated animate__fadeInDown"><div class="nav_container animated fadeInDown"><div class=site_nav id=site_nav><ul><li><a href=https://zhurongshuo.com/>首页</a></li><li><a href=https://zhurongshuo.com/start/>开始</a></li><li><a href=https://zhurongshuo.com/advanced/>进阶rc</a></li><li><a href=https://zhurongshuo.com/posts/>归档</a></li><li><a href=https://zhurongshuo.com/tags/>标签</a></li><li><a href=https://zhurongshuo.com/about/>关于</a></li></ul></div><div class=menu_icon><a id=menu_icon><i class=ri-menu-line></i></a></div></div><div class="header animated fadeInDown"><div class=site_title_container><div class=site_title><h1><a href=https://zhurongshuo.com/><span class=web-font>祝融说。</span></a></h1></div><div class=description><p class=sub_title>法不净空，觉无性也。</p><div class=my_socials><a href=https://zhurongshuo.com/books/ title=book-open><i class=ri-book-open-line></i></a>
<a href=https://zhurongshuo.com/practices/ title=trophy><i class=ri-trophy-line></i></a>
<a href=https://zhurongshuo.com/gallery/ title=gallery><i class=ri-gallery-line></i></a>
<a href=https://zhurongshuo.com/about/ title=game><i class=ri-game-line></i></a>
<a href type=application/rss+xml title=rss target=_blank><i class=ri-rss-fill></i></a></div></div></div></div><div class=content><div class=post_page><div class="post animate__animated animate__fadeInDown"><div class="post_title post_detail_title"><h2><a href=https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-12/>第12章 基于云平台的GPU集群的管理与运营</a></h2><span class=date>2025.12.07</span></div><div class="post_content markdown"><p>经过前面十一章的艰苦努力，我们已经成功地设计并构建起了一个功能完备、技术先进的大模型算力基础设施。我们拥有了由顶级GPU服务器组成的计算集群，由高速无损网络构成的通信动脉，由分层异构存储组成的强大数据底座，以及一个云原生的、基于微服务的应用开发与运行平台。我们已经建成了这座宏伟的“AI都市”。</p><p>然而，城市的建成只是一个开始，如何科学、高效、精细化地管理和运营这座城市，确保其7x24小时安全、稳定、经济地运行，并持续地为“市民”（用户）创造价值，是一个更为长期和艰巨的挑战。这就需要我们建立一套强大的城市管理系统。</p><p>本章，我们将进入AI基础设施建设的最高层次——管理与运营。我们将从一个云平台产品经理和高级运维专家的视角，探讨如何为一个大规模GPU集群构建一个全面的、自动化的管理与运营平台。这个平台不再是单一的技术组件，而是一个由运维、运营、审计三大核心子平台构成的、一体化的治理体系。它将帮助我们从“建设者”的角色，最终蜕变为一个运筹帷幄的“市长”。</p><p>我们将依次深入这三大平台的设计与实现：</p><ol><li>云运维平台（Cloud Operations Platform）：这是保障集群稳定运行的“市政工程与应急中心”。我们将探讨如何实现对海量硬件基础设施的自动化管理，如何构建一个覆盖所有层级的、全景式的监控与告警系统，以及如何建立一个权威的、作为所有运维活动基石的配置管理数据库（CMDB）。</li><li>云运营平台（Cloud Business Operations Platform）：这是实现资源价值变现的“商业与财政中心”。我们将学习如何对GPU等宝贵的资源进行精确的计量计费，如何通过多租户管理和资源配额实现公平、高效的资源分配，以及如何为用户提供一个自助服务的门户，提升用户体验和运营效率。</li><li>云审计平台（Cloud Auditing Platform）：这是确保集群合规与安全的“监察与安全中心”。我们将探讨如何记录和审计所有用户和管理员的操作行为，以满足安全合规的要求，并能够在出现问题时进行追溯。</li></ol><p>通过本章的学习，你将掌握一套完整的、企业级的云平台治理方法论。你将理解一个成功的AI云平台，不仅仅是技术的堆砌，更是流程、规范、自动化与精细化运营的有机结合。这将是你从一个纯粹的技术专家，迈向一个能够全面掌管大规模基础设施、平衡技术与商业、实现价值闭环的资深架构师或技术管理者的最后一公里。</p><h2 id=121-云运维平台>12.1 云运维平台</h2><p>云运维平台是整个集群管理体系的基石。它的核心使命是保障基础设施的稳定性、可用性和健康度，并提升运维工作的效率和自动化水平。在一个拥有数千台服务器、数万张网卡、数十万条线缆的大规模GPU集群中，依赖传统的人工“登录跳板机-执行命令”的运维模式是不可想象的。我们必须构建一个强大的、自动化的运维平台，它主要由以下三个核心组件构成。</p><h3 id=1211-硬件基础设施管理>12.1.1 硬件基础设施管理</h3><p>这是运维平台最底层的能力，负责对物理硬件的整个生命周期进行自动化管理。</p><p>面临的挑战：</p><p>规模巨大：如何同时管理成百上千台服务器的上下架、安装、配置和维修？</p><p>异构性：集群中包含GPU服务器、存储服务器、管理服务器等多种不同型号的硬件。</p><p>状态复杂：每台设备都有固件（BIOS, BMC, 网卡固件等）需要管理和升级。</p><p>核心功能与实现技术：</p><h4 id=资产发现与录入>资产发现与录入</h4><p>自动化发现：当一台新的服务器被接入到带外管理网络后，平台应能通过LLDP、DHCP等协议自动发现这台新设备，并获取其MAC地址、序列号等基本信息。</p><p>与CMDB集成：发现的设备信息应能自动或半自动地录入到CMDB中，完成资产的初始化。</p><h4 id=自动化操作系统安装os-provisioning>自动化操作系统安装（OS Provisioning）</h4><p>PXE（Preboot Execution Environment）：这是实现裸金属服务器自动化安装的核心技术。</p><p>工作流程：</p><ol><li>管理员在平台上为一台新服务器指定一个安装模板（例如，“DGX OS for H100”）。</li><li>平台将该服务器的BMC配置为从网络启动。</li><li>服务器启动后，其网卡会发出一个PXE启动请求。</li><li>网络中的DHCP服务器响应该请求，并告诉它TFTP服务器的地址以及一个启动引导程序（如iPXE）的文件名。</li><li>服务器从TFTP服务器下载并执行引导程序。</li><li>引导程序会根据从平台获取的指令，从HTTP或NFS服务器上下载操作系统的内核、initrd镜像和Kickstart/Preseed等自动化安装配置文件，然后启动无人值守的自动化安装过程。</li></ol><p>通过这套流程，我们可以在几分钟内，为一个机架的服务器并行地、自动化地装好操作系统。</p><h4 id=配置管理自动化configuration-management>配置管理自动化（Configuration Management）</h4><p>工具：Ansible, SaltStack, Puppet, Chef是业界主流的配置管理工具。其中，Ansible因其无客户端（Agentless）、基于SSH、使用简单的YAML语言等特点，在自动化运维领域非常流行。</p><p>工作模式（以Ansible为例）：</p><ol><li>管理员编写Playbook。Playbook是一个YAML文件，它以一种声明式的方式，描述了一台服务器应该处于的“最终状态”（例如，应该安装哪些软件包、配置文件应该是什么内容、哪些服务应该被启动）。</li><li>Ansible引擎读取Playbook，通过SSH连接到目标服务器（或服务器组），并执行一系列的操作，使服务器的状态与Playbook中描述的一致。</li><li>Ansible具有幂等性（Idempotence），即一个Playbook可以被反复执行，但只有当服务器的当前状态与目标状态不一致时，才会真正执行变更操作。</li></ol><p>应用：我们可以用Ansible来自动化地完成系统初始化（如配置主机名、网络、NTP）、安装GPU驱动、部署监控Agent、分发SSH密钥等所有配置任务。</p><h4 id=固件管理与带外操作>固件管理与带外操作</h4><p>平台应能通过带外管理网络，调用服务器BMC的Redfish或IPMI API，实现对服务器的远程开关机、重启、查看硬件日志、挂载虚拟介质等操作。</p><p>平台还应能实现固件的批量查询和升级。例如，扫描集群中所有服务器的BIOS或BMC固件版本，对于版本过低的服务器，自动地、分批地进行升级。</p><p>开源与商业方案：</p><p>开源组合：可以基于iPXE + Kickstart/Ansible + Cobbler/MAAS等开源工具，自研一套硬件自动化管理平台。</p><p>商业方案：如Red Hat Satellite, SUSE Manager等提供了成熟的解决方案。</p><h3 id=1212-系统监控与告警平台>12.1.2 系统监控与告警平台</h3><p>如果说硬件管理是“装机”，那么监控告警就是“体检”和“急救”。一个全景式的监控平台，是保障集群稳定运行、快速发现和定位问题的“眼睛”和“耳朵”。</p><p>监控设计的核心原则：分层与关联</p><p>一个好的监控系统，必须能够覆盖从底层物理硬件到上层AI应用的所有层次，并且能够将这些层次的数据关联起来，形成一个完整的故障诊断链。</p><p>物理层：服务器硬件（温度、功耗、风扇）、交换机（端口状态、流量）、PDU等。</p><p>系统层：操作系统指标（CPU使用率、内存、磁盘I/O、网络流量）。</p><p>GPU层：GPU卡的核心指标（GPU利用率、显存使用率、温度、功耗、NVLink流量、MIG实例状态）。</p><p>平台层：Kubernetes集群状态（节点状态、Pod数量、API Server延迟）、中间件状态（Kafka Lag、Redis命中率、DB连接数）。</p><p>应用层：AI任务指标（训练Loss、吞吐量samples/sec、推理延迟P99）。</p><p>云原生监控的事实标准：Prometheus + Grafana</p><p>Prometheus：一个强大的、开源的时序数据库（Time Series Database, TSDB）和监控系统。</p><p>拉模型（Pull Model）：Prometheus定期地、主动地从被监控的目标（称为Target）上暴露的HTTP端点（通常是<code>/metrics</code>）拉取指标数据。</p><p>Exporter：为了让各种不支持Prometheus原生格式的系统能够被监控，社区开发了大量的Exporter。Exporter是一个小型的转换程序，它从目标系统采集数据，然后将其转换为Prometheus能够理解的格式，并通过HTTP端点暴露出来。例如：</p><ul><li><code>node-exporter</code>：采集操作系统的核心指标。</li><li><code>dcgm-exporter</code>：NVIDIA官方提供的、用于采集GPU详细指标的Exporter，基于DCGM（Data Center GPU Manager）库。</li><li><code>kube-state-metrics</code>：采集Kubernetes集群的各种对象状态。</li></ul><p>强大的查询语言PromQL：Prometheus提供了极其强大的查询语言PromQL，可以对采集到的时序数据进行灵活的查询、聚合和计算。</p><p>告警管理器（Alertmanager）：Prometheus根据预先定义的告警规则（Alerting Rules）计算出告警状态，然后将告警事件发送给Alertmanager。Alertmanager负责对告警进行去重、分组、静默，并通过邮件、Slack、钉钉、电话等多种方式发送通知。</p><p>Grafana：一个开源的、功能极其丰富的可视化平台。</p><p>数据源：Grafana可以接入多种数据源，其中最主要的就是Prometheus。</p><p>仪表盘（Dashboard）：用户可以在Grafana中，通过简单的点击和拖拽，创建各种炫酷的仪表盘。仪表盘由多个面板（Panel）组成，每个面板都可以执行一条PromQL查询，并将结果以图表、仪表、表格等多种形式展示出来。</p><p>我们可以为GPU集群的每一个层面（硬件、系统、GPU、应用）都创建专门的监控大盘，实现全局状态的可视化。</p><p>日志与追踪的补充：</p><p>集中式日志（EFK/Loki）：我们在第十一章讨论过，它提供了对应用和系统日志的全文检索能力，是排查问题的另一大利器。</p><p>分布式追踪（Jaeger/Zipkin）：对于微服务架构，分布式追踪可以跟踪一个请求在多个服务之间的完整调用链，帮助我们快速定位性能瓶颈和错误发生的环节。</p><p>通过将Metrics（Prometheus）、Logging（Loki/EFK）、Tracing（Jaeger）这“可观测性三大支柱”整合起来，我们可以构建一个强大的、立体的监控告警体系，使得任何风吹草动都无所遁形。</p><h3 id=1213-配置管理数据库cmdb>12.1.3 配置管理数据库（CMDB）</h3><p>CMDB是整个运维平台的“中枢神经”和“权威数据源”。它不仅仅是一张记录资产信息的Excel表格，而是一个活的、动态的、描述和管理IT基础设施所有组件（Configuration Item, CI）及其相互关系的数据库。</p><p>CMDB中需要管理什么？</p><ul><li>硬件CI：数据中心、机房、机柜、服务器（型号、序列号、CPU、内存、GPU卡）、交换机、PDU等。</li><li>软件CI：操作系统（版本）、IP地址、主机名、部署的应用、数据库实例、中间件等。</li><li>关系（Relationship）：CI之间的关系是CMDB的精髓。例如：<ul><li>GPU服务器 <code>gpu-server-01</code> 位于 <code>Rack-A01</code> 机柜。</li><li><code>gpu-server-01</code> 安装了 <code>DGX OS 5.0</code>。</li><li><code>gpu-server-01</code> 连接到 交换机 <code>leaf-01</code> 的 <code>eth0</code> 端口。</li><li>应用 <code>recommend-service</code> 部署在 <code>gpu-server-01</code> 上。</li></ul></li></ul><p>CMDB的作用：</p><ol><li>运维的唯一真相来源：自动化脚本（如Ansible Playbook）可以从CMDB中动态地获取要操作的目标服务器列表及其变量。监控系统可以从CMDB获取设备的元数据，从而为告警信息添加更丰富的上下文（例如，告警的不仅是IP <code>10.1.1.1</code>，而是“位于A01机柜的推荐系统gpu服务器01”）。</li><li>变更管理与影响分析：当需要对一个组件进行变更时（如升级交换机固件），可以通过查询CMDB，快速地分析出这个变更可能会影响到哪些服务器和哪些应用，从而制定周密的变更计划。</li><li>故障定位：当一个应用告警时，可以沿着CMDB中的关系链，快速地回溯到其所依赖的服务器、网络、存储等基础设施，缩小故障排查范围。</li><li>成本与容量管理：CMDB是进行成本核算和容量规划的基础数据来源。</li></ol><p>构建CMDB：</p><p>构建一个成功的CMDB是一个复杂的工程。关键在于保证数据的准确性和实时性。</p><p>自动发现是关键：CMDB的数据应该尽可能地通过自动化脚本，从各种管理系统（如硬件管理平台、Kubernetes、vCenter）中自动地发现和同步，而不是依赖人工录入。</p><p>开源方案：Ralph, Collins, iTop等。</p><p>商业方案：ServiceNow, BMC等提供了强大的ITSM/CMDB解决方案。</p><p>一个整合了硬件自动化管理、全景监控告警和权威CMDB的云运维平台，将使我们能够从容地、高效地管理一个超大规模的GPU集群，实现从“救火队”到“预防性维护专家”的转变。</p><h2 id=122-云运营平台>12.2 云运营平台</h2><p>如果说运维平台关注的是“机器”和“稳定”，那么运营平台关注的就是“人”和“价值”。它的核心目标是，将底层的、原始的计算、存储、网络资源，包装成用户易于理解和使用的“云服务”，并对这些服务的使用情况进行计量、计费和管理，最终实现资源的公平分配和价值变现。</p><h3 id=1221-多租户与资源配额管理>12.2.1 多租户与资源配额管理</h3><p>在一个共享的GPU集群中，必须对不同的用户、团队或项目进行隔离和资源限制，以防止资源的滥用和不公平的抢占。</p><p>租户（Tenant）：运营平台中的一个基本隔离单元，可以对应一个部门、一个项目组或一个外部客户。</p><p>资源配额（Resource Quota）：</p><ul><li>平台需要为每个租户设置其可以使用的各种资源的总量上限。这就像是为每个家庭分配每月的水电额度。</li><li>在Kubernetes中实现：Kubernetes原生提供了<code>ResourceQuota</code>和<code>LimitRange</code>等对象。</li><li><code>ResourceQuota</code>可以对一个命名空间（Namespace）（通常一个租户对应一个或多个命名空间）中的资源总量进行限制，例如：<ul><li><code>requests.cpu: "100"</code>（该命名空间所有Pod的CPU请求总和不能超过100核）</li><li><code>limits.nvidia.com/gpu: "32"</code>（GPU使用上限为32张）</li><li><code>count/pods: "1000"</code>（Pod数量上限）</li><li><code>LimitRange</code>可以为命名空间中的每个Pod或容器设置默认的、最小的、最大的资源请求和限制。</li></ul></li><li>通过精细的配额管理，可以确保资源在不同租户之间得到合理的分配，避免个别“土豪”用户耗尽整个集群的资源。</li></ul><h3 id=1222-计量计费系统>12.2.2 计量计费系统</h3><p>计量计费是云平台实现商业闭环的核心。它需要能够精确地度量每个租户对每种资源的使用量，并根据预定的价格策略，计算出相应的费用。</p><p>计量的挑战：</p><p>资源类型多样：需要计量的不仅是GPU卡时，还包括CPU核时、内存GB时、存储GB月、网络流量GB等。</p><p>GPU计量的复杂性：</p><p>对于独占使用的GPU，可以按“卡*小时”来计量。</p><p>对于通过MIG或cGPU等技术共享的GPU，如何公平地计量其算力和显存的使用量？是按分配的份额计量，还是按实际的使用量计量？这需要与底层的虚拟化方案紧密结合。</p><p>例如，cGPU方案的管理守护进程，就需要定期地上报每个容器的实际算力和显存使用情况。</p><p>计量数据的采集与处理：</p><ol><li>数据源：</li></ol><p>从Prometheus中获取CPU、内存、网络等指标的累计使用量。</p><p>从GPU的Exporter（如dcgm-exporter）或虚拟化管理守护进程中，获取GPU的使用数据。</p><p>从存储系统的管理接口获取存储容量使用数据。</p><ol start=2><li>数据处理流水线：</li></ol><p>一个后台的数据处理系统（如基于Spark或Flink）会定期地（如每小时）拉取这些原始的计量数据。</p><p>对数据进行清洗、聚合（例如，将分钟级的采样数据聚合成小时级的使用量）、关联（将资源使用量与租户ID关联起来）。</p><p>将处理好的、规范化的账单数据（Billing Data）存入一个专用的数据库中。</p><p>计费与账单生成：</p><p>定价策略：运营平台需要允许管理员为每一种资源（如<code>gpu-a100-hour</code>, <code>cpu-core-hour</code>）定义单价。对于不同的租户，还可以应用不同的折扣。</p><p>账单生成：一个计费引擎会定期地（如每天或每月）扫描账单数据库，根据定价策略，计算出每个租户的费用，生成详细的账单。</p><h3 id=1223-用户服务门户self-service-portal>12.2.3 用户服务门户（Self-Service Portal）</h3><p>为了提升用户体验和运营效率，平台需要为最终用户提供一个Web界面的自助服务门户。用户不再需要通过提交工单或联系管理员来申请资源。</p><p>核心功能：</p><p>仪表盘：用户登录后，可以看到自己所属租户的资源配额使用情况、当前费用、历史账单等。</p><p>服务目录与申请：</p><p>平台将标准化的服务（如“一个配备了2张A100、1TB存储的JupyterLab开发环境”、“一个10节点的PyTorch分布式训练集群”）以“商品”的形式陈列在服务目录中。</p><p>用户可以像在电商网站购物一样，选择所需的服务，填写参数（如镜像版本、代码地址），然后“一键下单”。</p><p>生命周期管理：用户可以在门户上查看、启动、停止、销毁自己申请的服务实例。</p><p>审批流：对于一些昂贵的资源申请，可以集成一个审批工作流。用户的申请需要经过其主管或预算负责人审批后，平台才会真正创建资源。</p><p>后端实现：</p><p>这个门户的后端，通常是一个与Kubernetes、CMDB、计量计费系统等所有后台系统都进行了API集成的微服务应用。</p><p>当用户下单时，它会将用户的请求转换成一系列对后台系统的API调用（例如，在K8s中创建一个Namespace、一个Deployment和一个Service）。</p><p>一个友好的、自动化的服务门户，是提升平台用户满意度和黏性，同时极大解放运营人力、实现规模化运营的关键。</p><h2 id=123-云审计平台>12.3 云审计平台</h2><p>随着集群规模的扩大和用户数量的增多，特别是当平台需要满足金融、医疗等行业的合规要求时，对所有操作行为进行记录和审计，变得至关重要。</p><p>审计的目标：</p><ol><li>安全合规：满足SOX、HIPAA、GDPR等法规对操作可追溯性的要求。</li><li>事后追溯：当发生安全事件或重大故障时，能够通过审计日志，快速地追溯到是谁（Who）、在什么时间（When）、从哪里（Where）、做了什么（What），以及结果如何（Result）。</li><li>风险发现：通过对审计日志的分析，可以发现异常的行为模式（例如，某用户在深夜频繁尝试访问未授权的资源），并触发告警。</li></ol><p>需要审计的对象：</p><p>对平台的访问：所有用户登录门户、调用平台API的行为。</p><p>对Kubernetes的API调用：所有通过<code>kubectl</code>或API对K8s资源（Pod, Service, Secret等）的创建、删除、修改操作。Kubernetes的API Server原生支持强大的审计日志功能。</p><p>对服务器的访问：所有通过SSH登录到服务器上执行的命令。</p><p>对云服务的关键操作：例如，修改防火墙策略、删除一个重要的存储卷等。</p><p>审计平台的架构：</p><ol><li>日志采集：配置所有关键组件（如平台API网关、Kubernetes API Server、堡垒机、云服务控制器）将它们的审计日志，以结构化的格式，发送到一个中心化的日志系统中。</li><li>集中存储：这些高度敏感的审计日志，应该被存储在一个安全的、防篡改的、有长期保留策略的存储系统中。可以使用专门的安全信息和事件管理（SIEM）系统，或者一个独立的、有严格访问控制的Elasticsearch/Loki集群。</li><li>分析与告警：一个实时的分析引擎会持续地扫描审计日志流。根据预先定义的审计规则（例如，“任何对生产环境Secret的读取操作都应立即告警”），来发现可疑行为并触发告警。</li><li>查询与报告：为安全和审计人员提供一个专门的查询界面，让他们可以方便地对历史审计日志进行检索和分析，并生成合规报告。</li></ol><p>一个完善的云审计平台，是整个AI云平台安全与合规的最后一道防线，也是建立用户和监管机构信任的基础。</p><h2 id=124-本章小结>12.4 本章小结</h2><p>在本章中，我们完成了构建一个企业级AI基础设施的“最后一块拼图”——管理与运营平台的建设。我们认识到，一个成功的云平台，其价值不仅在于底层技术的先进性，更在于上层治理体系的完善性。这个治理体系，我们将其分解为相辅相成、缺一不可的三大子平台。</p><ol><li>我们构建了云运维平台，这是保障集群稳定与健康的“市政工程中心”。</li></ol><p>通过硬件基础设施的自动化管理（基于PXE, Ansible），我们实现了从裸金属到可用操作系统的无人值守交付。</p><p>通过以Prometheus和Grafana为核心的全景式监控告警系统，我们为集群安装了覆盖所有层级的“眼睛”和“神经”，实现了从硬件到应用的端到端可观测性。</p><p>通过建立一个权威的、自动化的CMDB，我们为所有运维活动提供了“唯一的真相来源”，实现了配置、变更和故障管理的系统化。</p><ol start=2><li>我们构建了云运营平台，这是实现资源价值闭环的“商业与财政中心”。</li></ol><p>通过多租户与资源配额管理，我们实现了资源的公平、隔离分配。</p><p>通过精细化的计量计费系统，我们学会了如何度量和量化资源的使用价值。</p><p>通过打造一个自助服务门户，我们极大地提升了用户体验和运营效率，实现了从“手工作坊”到“云服务超市”的转变。</p><ol start=3><li>我们构建了云审计平台，这是确保平台安全与合规的“监察中心”。通过对所有关键操作的记录和分析，我们为平台的安全运行提供了可追溯的保障，满足了企业级的合规要求。</li></ol><p>至此，我们已经从一个硬件工程师、软件工程师、网络工程师、存储工程师，一路成长为一个能够全面掌控一个复杂、大规模AI云平台的首席架构师和平台运营官。我们不仅知道如何“建造”这座AI都市，更懂得了如何“治理”它——如何让它稳定运行，如何让它创造价值，如何让它安全合-compliant。</p><p>在本书的最后一章，我们将以一个具体的落地案例，来将前面所有章节学习到的理论知识进行一次融会贯通的实践，完整地展示如何从零开始，为一个真实的机器学习应用（如自动驾驶模型训练），设计和实现一个端到端的GPU计算平台。这将是对我们整个学习旅程的一次终极检验和升华。</p></div><div class=post_footer><div class=meta><div class=info><span class="field tags"><i class=ri-stack-line></i>
<a href=https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/>书稿</a></span></div></div></div></div><div class=doc_comments></div></div></div></div><a id=back_to_top href=# class=back_to_top><i class=ri-arrow-up-s-line></i></a><footer class=footer><div class=powered_by><a href=https://varkai.com>Designed by VarKai, </a><a href=http://www.gohugo.io/>Proudly published with Hugo,</a></div><div class=footer_slogan><span>法不净空，觉无性也。</span></div><div class=powered_by style=margin-top:10px;font-size:14px><a href=https://zhurongshuo.com/>Copyright © 2010-2025 祝融说 zhurongshuo.com All Rights Reserved.</a></div></footer><script defer src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><link href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.css rel=stylesheet integrity="sha256-7qiTu3a8qjjWtcX9w+f2ulVUZSUdCZFEK62eRlmLmCE=" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script defer src=https://zhurongshuo.com/js/zozo.js></script><script type=text/javascript async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-KKJ5ZEG1NB"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KKJ5ZEG1NB")</script></body></html>