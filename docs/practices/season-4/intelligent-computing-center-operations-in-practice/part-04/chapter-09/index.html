<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=google-site-verification content="8_xpI-TS3tNV8UPug-Q6Ef3BhKTcy0WOG7dEdAcm2zk"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="祝融"><link rel=dns-prefetch href=//cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=preconnect href=https://www.googletagmanager.com crossorigin><link rel=canonical href=https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-04/chapter-09/><title>祝融说。 第9章：构建全链路监控体系</title><meta property="og:title" content="第9章：构建全链路监控体系"><meta property="og:url" content="https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-04/chapter-09/"><meta property="og:site_name" content="祝融说。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:published_time" content="2025-11-29T00:00:00+08:00"><meta property="article:modified_time" content="2025-11-29T00:00:00+08:00"><meta property="article:tag" content="书稿"><meta name=description content="至此，我们已经走过了从硬件选型、平台搭建到模型训练与推理服务化的完整旅程。我们构建的智算中心，如同一座精密的、高速运转的巨型工厂，每一秒都在进行着海量的计算。然而，复杂性与脆弱性是一对孪生兄弟。在这座工厂里，任何一个微小的环节——一块过热的GPU、一个拥堵的网络端口、一个配置不当的推理引擎——都可能引发连锁反应，导致昂贵的训练任务失败或在线服务中断。
"><meta property="og:description" content="至此，我们已经走过了从硬件选型、平台搭建到模型训练与推理服务化的完整旅程。我们构建的智算中心，如同一座精密的、高速运转的巨型工厂，每一秒都在进行着海量的计算。然而，复杂性与脆弱性是一对孪生兄弟。在这座工厂里，任何一个微小的环节——一块过热的GPU、一个拥堵的网络端口、一个配置不当的推理引擎——都可能引发连锁反应，导致昂贵的训练任务失败或在线服务中断。
"><meta property="og:image" content="https://zhurongshuo.com/images/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="第9章：构建全链路监控体系"><meta name=twitter:description content="至此，我们已经走过了从硬件选型、平台搭建到模型训练与推理服务化的完整旅程。我们构建的智算中心，如同一座精密的、高速运转的巨型工厂，每一秒都在进行着海量的计算。然而，复杂性与脆弱性是一对孪生兄弟。在这座工厂里，任何一个微小的环节——一块过热的GPU、一个拥堵的网络端口、一个配置不当的推理引擎——都可能引发连锁反应，导致昂贵的训练任务失败或在线服务中断。
"><meta name=twitter:image content="https://zhurongshuo.com/images/favicon.ico"><meta name=keywords content="智算中心运营实战：从基础设施到大模型全栈优化,第9章：构建全链路监控体系"><link rel="shortcut icon" href=https://zhurongshuo.com/images/favicon.ico><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/animate-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/zozo.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/remixicon-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/highlight.css><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"第9章：构建全链路监控体系","description":"至此，我们已经走过了从硬件选型、平台搭建到模型训练与推理服务化的完整旅程。我们构建的智算中心，如同一座精密的、高速运转的巨型工厂，每一秒都在进行着海量的计算。然而，复杂性与脆弱性是一对孪生兄弟。在这座工厂里，任何一个微小的环节——一块过热的GPU、一个拥堵的网络端口、一个配置不当的推理引擎——都可能引发连锁反应，导致昂贵的训练任务失败或在线服务中断。\n","datePublished":"2025-11-29T00:00:00\u002b08:00","dateModified":"2025-11-29T00:00:00\u002b08:00","author":{"@type":"Person","name":"祝融"},"publisher":{"@type":"Organization","name":"祝融说。","logo":{"@type":"ImageObject","url":"https:\/\/zhurongshuo.com\/images\/favicon.ico"}},"image":"https:\/\/zhurongshuo.com\/images\/favicon.ico","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zhurongshuo.com\/practices\/season-4\/intelligent-computing-center-operations-in-practice\/part-04\/chapter-09\/"},"keywords":"书稿"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"首页","item":"https:\/\/zhurongshuo.com\/"},{"@type":"ListItem","position":2,"name":"practices","item":"https:\/\/zhurongshuo.com\/practices/"},{"@type":"ListItem","position":3,"name":"第9章：构建全链路监控体系","item":"https:\/\/zhurongshuo.com\/practices\/season-4\/intelligent-computing-center-operations-in-practice\/part-04\/chapter-09\/"}]}</script></head><body><div class="main animate__animated animate__fadeInDown"><div class="nav_container animated fadeInDown"><div class=site_nav id=site_nav><ul><li><a href=https://zhurongshuo.com/>首页</a></li><li><a href=https://zhurongshuo.com/start/>开始</a></li><li><a href=https://zhurongshuo.com/advanced/>进阶rc</a></li><li><a href=https://zhurongshuo.com/posts/>归档</a></li><li><a href=https://zhurongshuo.com/tags/>标签</a></li><li><a href=https://zhurongshuo.com/about/>关于</a></li></ul></div><div class=menu_icon><a id=menu_icon><i class=ri-menu-line></i></a></div></div><div class="header animated fadeInDown"><div class=site_title_container><div class=site_title><h1><a href=https://zhurongshuo.com/><span class=web-font>祝融说。</span></a></h1></div><div class=description><p class=sub_title>法不净空，觉无性也。</p><div class=my_socials><a href=https://zhurongshuo.com/books/ title=book-open><i class=ri-book-open-line></i></a>
<a href=https://zhurongshuo.com/practices/ title=trophy><i class=ri-trophy-line></i></a>
<a href=https://zhurongshuo.com/gallery/ title=gallery><i class=ri-gallery-line></i></a>
<a href=https://zhurongshuo.com/about/ title=game><i class=ri-game-line></i></a>
<a href type=application/rss+xml title=rss target=_blank><i class=ri-rss-fill></i></a></div></div></div></div><div class=content><div class=post_page><div class="post animate__animated animate__fadeInDown"><div class="post_title post_detail_title"><h2><a href=https://zhurongshuo.com/practices/season-4/intelligent-computing-center-operations-in-practice/part-04/chapter-09/>第9章：构建全链路监控体系</a></h2><span class=date>2025.11.29</span></div><div class="post_content markdown"><p>至此，我们已经走过了从硬件选型、平台搭建到模型训练与推理服务化的完整旅程。我们构建的智算中心，如同一座精密的、高速运转的巨型工厂，每一秒都在进行着海量的计算。然而，复杂性与脆弱性是一对孪生兄弟。在这座工厂里，任何一个微小的环节——一块过热的GPU、一个拥堵的网络端口、一个配置不当的推理引擎——都可能引发连锁反应，导致昂贵的训练任务失败或在线服务中断。</p><p>我们如何才能洞悉这座黑暗工厂的内部运作，提前预警风险，快速定位故障？答案是构建一个全链路、多层次的可观测性（Observability）体系。</p><p>“监控（Monitoring）”告诉我们“系统哪里出错了”，而“可观测性”则要回答“系统为什么出错了”。它不仅仅是收集指标，更是要将来自硬件、平台、应用等不同层面的数据（Metrics, Logs, Traces）关联起来，为我们提供一个可钻取、可分析的全局视图。</p><p>本章，我们将以业界主流的Prometheus + Grafana技术栈为核心，从零开始构建一套覆盖“硬件-平台-业务”三层的智算中心监控体系。我们将学习如何从NVIDIA和华为的硬件中“抠”出最核心的指标，如何从vLLM等业务应用中提取关键性能数据，并最终将这些数据汇聚到一块精心设计的“智算运营驾驶舱”Grafana大屏上。这块大屏，将成为你管理整个智算中心的“中控台”。</p><h2 id=91-采集层dcgm-exportern卡与-npu-exporter华为指标抓取>9.1 采集层：DCGM-Exporter（N卡）与 NPU-Exporter（华为）指标抓取</h2><p>可观测性的第一步是数据采集。对于智算中心，最基础、最重要的监控数据源自于底层的AI加速硬件。我们需要实时了解每一张GPU/NPU的健康状况和负载情况。</p><p>Prometheus是一个基于拉（Pull）模型的时序数据库。它会周期性地访问目标（Target）暴露出的一个HTTP端点（通常是<code>/metrics</code>），并抓取符合其特定格式的指标数据。为了让Prometheus能够“读懂”GPU/NPU的状态，我们需要一个“翻译官”——Exporter。</p><h3 id=911-监控nvidia-gpudcgm-exporter>9.1.1 监控NVIDIA GPU：DCGM-Exporter</h3><p>NVIDIA提供了一套强大的数据中心GPU管理工具集，名为DCGM (Data Center GPU Manager)。DCGM比我们常用的<code>nvidia-smi</code>要强大得多，它能以更高的频率、更低的开销，提供更丰富的指标和健康检查功能。DCGM-Exporter就是将DCGM收集到的海量指标，转换为Prometheus能识别的格式的官方工具。</p><p>DCGM的核心优势：</p><ul><li>高性能采集： DCGM在GPU驱动层面进行数据采集，开销极小。</li><li>丰富的指标： 除了<code>nvidia-smi</code>能看到的GPU利用率、显存使用、温度、功耗，DCGM还能提供更深层次的指标，如：<ul><li>SM Clock/Memory Clock: SM（流多处理器）和显存的实际运行频率。</li><li>PCIe Replays: PCIe总线的重传次数，是诊断硬件链路问题的重要指标。</li><li>NVLink Bandwidth/Errors: NVLink的带宽使用率和错误计数。</li><li>XID Errors: 关键的GPU内部错误代码，是排查“掉卡”等严重故障的线索。</li><li>ECC Errors: 显存的纠错码错误计数，分为可纠正（Correctable）和不可纠正（Uncorrectable）。不可纠正的ECC错误通常意味着GPU硬件故障。</li></ul></li><li>主动健康检查： DCGM可以主动对GPU进行诊断，如显存压力测试、PCIe带宽测试等。</li></ul><p>部署DCGM-Exporter（以K8s DaemonSet为例）：</p><p>在Kubernetes集群中，最佳实践是将DCGM-Exporter作为DaemonSet部署，确保每个GPU节点上都有一个Exporter实例在运行。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>DaemonSet</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>dcgm-exporter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>monitoring</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>app.kubernetes.io/name</span><span class=p>:</span><span class=w> </span><span class=l>dcgm-exporter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>app.kubernetes.io/name</span><span class=p>:</span><span class=w> </span><span class=l>dcgm-exporter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>nodeSelector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>nvidia.com/gpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w> </span><span class=c># 只在有NVIDIA GPU的节点上运行</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>nvcr.io/nvidia/k8s/dcgm-exporter:3.3.0-3.1.8-ubuntu22.04</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>dcgm-exporter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>9400</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>securityContext</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>runAsUser</span><span class=p>:</span><span class=w> </span><span class=m>0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=c># ... 需要挂载一些必要的设备和目录</span><span class=w>
</span></span></span></code></pre></div><p>配置Prometheus抓取</p><p>你需要让Prometheus能够自动发现这些Exporter。在K8s中，这通常通过为DaemonSet的Pod添加特定的<code>annotations</code>来实现，Prometheus Operator会根据这些注解自动生成抓取配置。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># Pod template annotations</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>prometheus.io/scrape</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;true&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>prometheus.io/path</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;/metrics&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>prometheus.io/port</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;9400&#39;</span><span class=w>
</span></span></span></code></pre></div><p>核心DCGM指标解读（在PromQL中使用）：</p><ul><li><code>DCGM_FI_DEV_GPU_UTIL</code>: GPU利用率 (%)，等同于<code>nvidia-smi</code>的<code>GPU-Util</code>。</li><li><code>DCGM_FI_DEV_FB_USED</code>: 已使用的显存大小 (MB)。</li><li><code>DCGM_FI_DEV_POWER_USAGE</code>: 功耗 (W)。</li><li><code>DCGM_FI_DEV_GPU_TEMP</code>: GPU核心温度 (°C)。</li><li><code>DCGM_FI_DEV_XID_ERRORS</code>: XID错误计数。<code>rate(DCGM_FI_DEV_XID_ERRORS[5m]) > 0</code> 是一个非常关键的告警规则。</li><li><code>DCGM_FI_DEV_UNCORRECTED_SBE_ERRORS</code> / <code>DBE_ERRORS</code>: 不可纠正的ECC错误。出现增长通常意味着需要更换硬件。</li><li><code>DCGM_FI_PROF_NVLINK_TX_BYTES</code>, <code>RX_BYTES</code>: NVLink的发送/接收字节数。通过<code>rate()</code>可以计算出实时带宽。</li><li><code>DCGM_FI_PROF_PCIE_RX_BYTES</code>, <code>TX_BYTES</code>: PCIe的发送/接收字节数。</li></ul><h3 id=912-监控华为昇腾npunpu-exporter>9.1.2 监控华为昇腾NPU：NPU-Exporter</h3><p>对于华为昇腾平台，社区和华为官方也提供了类似的Exporter——通常称为NPU-Exporter。其原理与DCGM-Exporter完全相同：在后台调用<code>npu-smi</code>或CANN的底层API来获取NPU状态，并将其转换为Prometheus格式。</p><p>部署NPU-Exporter：</p><p>同样以DaemonSet的形式部署在所有昇腾节点上。你需要从华为的AscendHub或相关开源社区获取其容器镜像和部署YAML。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># 示例DaemonSet</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>DaemonSet</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>npu-exporter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>monitoring</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>nodeSelector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>huawei.com/npu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w> </span><span class=c># 只在昇腾节点运行</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ascendhub.huawei.com/public-ascendhub/npu-exporter:latest</span><span class=w> </span><span class=c># 镜像地址请以官方为准</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>npu-exporter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>9101</span><span class=w> </span><span class=c># 端口可能不同</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=c># ...</span><span class=w>
</span></span></span></code></pre></div><p>核心NPU指标解读：</p><p>NPU-Exporter暴露的指标名称可能因版本而异，但其核心概念与DCGM是相通的。</p><ul><li><code>npu_utilization_ratio</code>: NPU利用率，可能包含AI Core、AI CPU、Control CPU等多个维度的利用率。<code>AICore_utilization</code> 是最重要的，它反映了核心计算单元的繁忙程度。</li><li><code>npu_memory_used_bytes</code>: 已使用的HBM（高带宽内存）大小。</li><li><code>npu_temperature_celsius</code>: NPU芯片温度。</li><li><code>npu_power_watts</code>: 功耗。</li><li><code>npu_hbm_bandwidth_usage_ratio</code>: HBM带宽利用率。这是一个非常关键的性能指标，如果很低，可能意味着存在“内存墙”问题。</li><li><code>npu_roce_bandwidth_bytes_total</code>: RoCE网络的收发字节数，用于监控分布式训练的通信流量。</li></ul><p>小结： 通过部署DCGM-Exporter和NPU-Exporter，我们完成了可观测性体系的“物理层”数据采集。现在，Prometheus中已经源源不断地汇入了来自每一张AI加速卡的“心跳”和“血压”数据。这是后续所有告警和可视化分析的基础。</p><h2 id=92-业务层token生成速率请求队列长度显存碎片率监控>9.2 业务层：Token生成速率、请求队列长度、显存碎片率监控</h2><p>仅仅监控硬件是远远不够的。一个GPU利用率100%的服务，可能因为请求大量积压而导致用户体验极差。我们需要深入到“业务应用”的内部，去采集那些能直接反映服务质量和效率的指标。对于大模型推理服务（如基于vLLM或TensorRT-LLM构建的服务），我们需要关注以下几类核心业务指标。</p><h3 id=921-如何从应用中暴露业务指标>9.2.1 如何从应用中暴露业务指标？</h3><p>现代的推理引擎（如vLLM, Triton）通常已经内置了Prometheus Exporter的功能。你只需要在启动时开启一个选项，它就会自动暴露一个<code>/metrics</code>端点。</p><ul><li>vLLM的例子：vLLM的<code>AsyncLLMEngine</code>和API Server已经集成了Prometheus指标。你可以直接从其<code>/metrics</code>端点获取丰富的业务数据。</li><li>Triton的例子：Triton Inference Server原生支持Prometheus指标，默认在<code>http://&lt;triton-server>:8002/metrics</code>暴露。</li><li>自定义应用的实现：如果你的应用没有内置支持，可以使用Prometheus的官方Python客户端库（<code>prometheus-client</code>）来轻松地添加自定义指标。</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>prometheus_client</span> <span class=kn>import</span> <span class=n>Counter</span><span class=p>,</span> <span class=n>Gauge</span><span class=p>,</span> <span class=n>Histogram</span><span class=p>,</span> <span class=n>start_http_server</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义指标</span>
</span></span><span class=line><span class=cl><span class=n>REQUESTS_IN_QUEUE</span> <span class=o>=</span> <span class=n>Gauge</span><span class=p>(</span><span class=s1>&#39;my_app_requests_in_queue&#39;</span><span class=p>,</span> <span class=s1>&#39;Number of requests waiting in the queue&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>TTFT_HISTOGRAM</span> <span class=o>=</span> <span class=n>Histogram</span><span class=p>(</span><span class=s1>&#39;my_app_ttft_seconds&#39;</span><span class=p>,</span> <span class=s1>&#39;Time to first token histogram&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在你的代码逻辑中更新指标</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>handle_request</span><span class=p>(</span><span class=n>request</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>REQUESTS_IN_QUEUE</span><span class=o>.</span><span class=n>inc</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... process request ...</span>
</span></span><span class=line><span class=cl>    <span class=n>ttft</span> <span class=o>=</span> <span class=n>measure_ttft</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>TTFT_HISTOGRAM</span><span class=o>.</span><span class=n>observe</span><span class=p>(</span><span class=n>ttft</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>REQUESTS_IN_QUEUE</span><span class=o>.</span><span class=n>dec</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 启动一个HTTP服务器来暴露指标</span>
</span></span><span class=line><span class=cl><span class=n>start_http_server</span><span class=p>(</span><span class=mi>8000</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=922-核心业务指标详解>9.2.2 核心业务指标详解</h3><h4 id=请求与队列指标-反映服务负载与健康度>请求与队列指标 (反映服务负载与健康度)</h4><ul><li><code>llm_requests_in_queue_total</code> (Gauge): 等待队列中的请求数量。<ul><li>监控与告警： 这个指标持续增长，是服务即将过载的最直接信号。需要设置一个告警阈值，例如当队列长度持续超过某个值（如100）达5分钟，就立即告警，提示需要扩容。</li></ul></li><li><code>llm_requests_running_total</code> (Gauge): 正在GPU上处理的请求数量。<ul><li>监控： 这个值应该与你设置的<code>max_num_batched_tokens</code>等参数相关，反映了GPU的并发处理能力。</li></ul></li><li><code>llm_requests_success_total</code> / <code>llm_requests_failed_total</code> (Counter): 成功和失败的请求总数。<ul><li>监控与告警： <code>rate(llm_requests_failed_total[5m])</code> 可以计算出失败率。失败率突然飙升是严重故障的标志。</li></ul></li></ul><h4 id=性能与吞吐量指标-反映服务效率>性能与吞吐量指标 (反映服务效率)</h4><ul><li><code>llm_generation_tokens_total</code> (Counter): 生成的总Token数量。<ul><li>计算TPS (Tokens Per Second): <code>rate(llm_generation_tokens_total[5m])</code> 就是整个服务的实时Token生成速率。这是衡量服务总吞吐量的黄金指标。</li></ul></li><li><code>llm_prompt_tokens_total</code> (Counter): 处理的总Prompt Token数量。<ul><li>计算Prompt Throughput: <code>rate(llm_prompt_tokens_total[5m])</code>。</li></ul></li><li><code>llm_time_to_first_token_seconds_bucket</code> (Histogram): TTFT的直方图分布。<ul><li>计算百分位TTFT: <code>histogram_quantile(0.99, sum(rate(llm_time_to_first_token_seconds_bucket[5m])) by (le))</code>。计算99百分位的TTFT，是评估服务SLA（服务等级协议）的关键。例如，你可以承诺“99%的请求TTFT在500ms以内”。</li></ul></li><li><code>llm_time_per_output_token_seconds_bucket</code> (Histogram): TPOT的直方图分布。<ul><li>计算百分位TPOT: <code>histogram_quantile(0.99, ...)</code>。反映了最坏情况下的生成速度。</li></ul></li></ul><h4 id=资源管理指标-反映引擎内部效率>资源管理指标 (反映引擎内部效率)</h4><ul><li><code>vllm_gpu_cache_usage_perc</code> (Gauge): (vLLM特有) KV Cache的利用率。<ul><li>监控： 这个值应该持续保持在高位（如90%以上），这证明PagedAttention正在高效工作。如果这个值很低，但请求已经开始排队，可能意味着有其他瓶颈。</li></ul></li><li>显存碎片率（通常需要间接计算或由特定Exporter提供）：<ul><li>计算方法： <code>(显存总块数 - 显存空闲块数 - 显存已使用块数) / 显存总块数</code>。</li><li>监控： 理想情况下，这个值应该接近于0。如果持续升高，表明引擎的内存管理器可能存在问题。</li></ul></li><li><code>vllm_scheduler_running_requests</code>, <code>swapped_requests</code>, <code>waiting_requests</code> (Gauges): vLLM调度器内部状态，帮助深入分析请求的处理流程。</li></ul><p>通过将这些业务层指标与前一节的硬件层指标结合，我们就能形成一个完整的分析链路。例如：</p><ul><li>现象： 99百分位TTFT突然飙升。</li><li>分析：<ul><li>查看<code>llm_requests_in_queue_total</code>，如果队列长度也在飙升 -> 请求积压导致。</li><li>查看<code>DCGM_FI_DEV_GPU_UTIL</code>，如果GPU利用率已经100% -> 算力瓶颈，需要扩容。</li><li>如果GPU利用率不高，但队列积压 -> 可能是CPU瓶颈（Python代码、API服务器）、网络I/O瓶颈，或者推理引擎的调度逻辑出了问题。</li></ul></li></ul><h2 id=93-可视化实战从0搭建一套智算运营驾驶舱grafana大屏>9.3 可视化实战：从0搭建一套“智算运营驾驶舱”Grafana大屏</h2><p>数据采集完成，现在我们需要将这些冰冷的数字，变成直观、易懂、可交互的图表。Grafana是这个任务的不二之选。一个好的Grafana Dashboard，不仅是运维人员的“作战指挥室”，更是向管理层展示运营成果、汇报资源利用率的“商业智能（BI）”面板。</p><p>我们将设计一个“智算运营驾驶舱”，它将包含三个核心部分：全局概览、训练集群监控 和 推理服务监控。</p><p>前提： 你已经部署好了Prometheus和Grafana，并且Prometheus已经配置为抓取DCGM-Exporter, NPU-Exporter, 以及推理服务的业务指标。</p><h3 id=第一步设计dashboard结构-layout--variables>第一步：设计Dashboard结构 (Layout & Variables)</h3><ul><li>创建新的Dashboard。</li><li>使用模板变量 (Template Variables)： 这是让Dashboard变得“活”起来的关键。<ul><li><code>$node</code>: 创建一个类型为<code>Query</code>的变量，查询表达式为<code>label_values(node_uname_info, nodename)</code>，用于在节点间切换。</li><li><code>$gpu</code>: 创建一个类型为<code>Query</code>的变量，查询表达式为<code>label_values({__name__=~"DCGM_FI_DEV_GPU_UTIL"}, gpu)</code>，用于在单个GPU间切换。</li><li><code>$service</code>: 创建一个查询，获取所有推理服务的名称，<code>label_values(llm_requests_in_queue_total, service_name)</code>。</li></ul></li></ul><h3 id=第二步构建全局概览-the-big-picture>第二步：构建“全局概览” (The Big Picture)</h3><p>这部分面向管理者和一线运维的“第一眼”，提供最核心的宏观指标。</p><ul><li><p>Stat Panel: 核心KPI</p><ul><li>GPU总数/NPU总数： <code>count(count by (instance)(DCGM_FI_DEV_GPU_UTIL))</code></li><li>GPU总利用率 (Avg): <code>avg(DCGM_FI_DEV_GPU_UTIL)</code></li><li>GPU总功耗 (Sum): <code>sum(DCGM_FI_DEV_POWER_USAGE) / 1000</code> (单位KW)</li><li>告警中的GPU数量： <code>count(ALERTS{alertstate="firing", alertname=~"GPU.*"})</code></li></ul></li><li><p>Time Series Panel: 全局资源利用率趋势</p><ul><li>查询A (GPU Util): <code>avg(DCGM_FI_DEV_GPU_UTIL) by (job)</code> (如果使用K8s，可以按<code>namespace</code>或<code>pod</code>聚合)</li><li>查询B (Memory Util): <code>avg(DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_TOTAL) * 100</code></li></ul></li><li><p>Table Panel: 节点资源排行榜</p><ul><li>按平均GPU利用率对节点排序，快速发现高负载或低负载的节点。</li><li>查询: <code>avg by (nodename) (DCGM_FI_DEV_GPU_UTIL)</code></li></ul></li></ul><h3 id=第三步构建训练集群钻取视图-training-deep-dive>第三步：构建“训练集群钻取视图” (Training Deep Dive)</h3><p>这部分专注于诊断和分析训练任务。</p><ul><li><p>Row: 按节点和GPU钻取</p><ul><li>使用我们创建的<code>$node</code>和<code>$gpu</code>变量。</li></ul></li><li><p>Time Series Panel: 单GPU核心指标 (重复这个Panel，使其显示<code>$node</code>上的所有GPU)</p><ul><li>GPU/NPU Util: <code>DCGM_FI_DEV_GPU_UTIL{nodename="$node", gpu="$gpu"}</code></li><li>Memory Used: <code>DCGM_FI_DEV_FB_USED{nodename="$node", gpu="$gpu"}</code></li><li>Power & Temp: <code>DCGM_FI_DEV_POWER_USAGE{...}</code>, <code>DCGM_FI_DEV_GPU_TEMP{...}</code></li></ul></li><li><p>Time Series Panel: 网络通信监控</p><ul><li>NVLink Bandwidth: <code>rate(DCGM_FI_PROF_NVLINK_TX_BYTES{...}[5m]) / 1024 / 1024</code> (MB/s)</li><li>RoCE Bandwidth: <code>rate(npu_roce_bandwidth_bytes_total{...}[5m])</code></li><li>意义： 在分布式训练时，这些图上应该能看到规律性的、高峰值的通信流量。如果流量很低或没有，说明分布式通信可能没正常工作。</li></ul></li><li><p>Stat Panel / Table: 硬件错误监控</p><ul><li>XID Errors: <code>sum(rate(DCGM_FI_DEV_XID_ERRORS{nodename="$node"}[10m])) by (gpu)</code></li><li>ECC Errors: <code>sum(rate(DCGM_FI_DEV_UNCORRECTED_SBE_ERRORS{...}[10m])) by (gpu)</code></li><li>关键： 任何非零值都值得高度警惕！</li></ul></li></ul><h3 id=第四步构建推理服务钻取视图-inference-deep-dive>第四步：构建“推理服务钻取视图” (Inference Deep Dive)</h3><p>这部分专注于评估在线服务的性能和健康度。</p><ul><li><p>Row: 按服务和实例钻取</p><ul><li>使用<code>$service</code>变量。</li></ul></li><li><p>Time Series Panel: 服务质量 (QoS)</p><ul><li>99th TTFT: <code>histogram_quantile(0.99, sum(rate(llm_time_to_first_token_seconds_bucket{service_name="$service"}[5m])) by (le))</code></li><li>Avg TTFT: <code>sum(rate(llm_time_to_first_token_seconds_sum[5m])) / sum(rate(llm_time_to_first_token_seconds_count[5m]))</code></li><li>Error Rate: <code>sum(rate(llm_requests_failed_total{service_name="$service"}[5m])) / sum(rate(llm_requests_total{service_name="$service"}[5m]))</code></li></ul></li><li><p>Time Series Panel: 吞吐量与负载</p><ul><li>TPS (Tokens/sec): <code>sum(rate(llm_generation_tokens_total{service_name="$service"}[5m]))</code></li><li>RPS (Requests/sec): <code>sum(rate(llm_requests_total{service_name="$service"}[5m]))</code></li><li>Queue Length: <code>llm_requests_in_queue_total{service_name="$service"}</code></li></ul></li><li><p>Time Series Panel: 引擎内部状态</p><ul><li>KV Cache Usage: <code>vllm_gpu_cache_usage_perc{service_name="$service"}</code></li><li>Running vs Waiting Requests: <code>vllm_scheduler_running_requests</code>, <code>vllm_scheduler_waiting_requests</code></li></ul></li></ul><h3 id=第五步配置告警-alerting>第五步：配置告警 (Alerting)</h3><p>Grafana集成了强大的告警功能。你可以为几乎任何一个Panel配置告警规则。</p><p>关键告警规则示例：</p><ul><li>硬件告警:<ul><li><code>GPU_Too_Hot</code>: <code>DCGM_FI_DEV_GPU_TEMP > 85</code> for 5m</li><li><code>GPU_XID_Error</code>: <code>rate(DCGM_FI_DEV_XID_ERRORS[5m]) > 0</code></li><li><code>GPU_Uncorrectable_ECC</code>: <code>increase(DCGM_FI_DEV_UNCORRECTED_SBE_ERRORS[10m]) > 0</code></li></ul></li><li>业务告警:<ul><li><code>Inference_High_TTFT</code>: 99th TTFT > 1s for 5m</li><li><code>Inference_High_Queue_Length</code>: <code>llm_requests_in_queue_total > 100</code> for 10m</li><li><code>Inference_High_Error_Rate</code>: Error Rate > 5% for 1m</li></ul></li></ul><p>将这些告警规则配置好，并对接上你的告警通知渠道（如Slack, PagerDuty, 钉钉），你就拥有了一个7x24小时不间断的“智能哨兵”。</p><p>总结：</p><p>一个精心设计的Grafana Dashboard，远不止是一堆图表的堆砌。它是一个故事板，讲述了你的智算中心从硬件到业务的完整故事。它是一个诊断仪，能帮助你快速地从宏观现象钻取到微观根因。它更是一个价值放大器，将你和你的团队在幕后所做的繁重而复杂的运维工作，以最直观、最有冲击力的方式，呈现在了所有相关方面前。这，就是可观测性的终极魅力。</p></div><div class=post_footer><div class=meta><div class=info><span class="field tags"><i class=ri-stack-line></i>
<a href=https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/>书稿</a></span></div></div></div></div><div class=doc_comments></div></div></div></div><a id=back_to_top href=# class=back_to_top><i class=ri-arrow-up-s-line></i></a><footer class=footer><div class=powered_by><a href=https://varkai.com>Designed by VarKai, </a><a href=http://www.gohugo.io/>Proudly published with Hugo,</a></div><div class=footer_slogan><span>法不净空，觉无性也。</span></div><div class=powered_by style=margin-top:10px;font-size:14px><a href=https://zhurongshuo.com/>Copyright © 2010-2025 祝融说 zhurongshuo.com All Rights Reserved.</a></div></footer><script defer src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><link href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.css rel=stylesheet integrity="sha256-7qiTu3a8qjjWtcX9w+f2ulVUZSUdCZFEK62eRlmLmCE=" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script defer src=https://zhurongshuo.com/js/zozo.js></script><script type=text/javascript async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-KKJ5ZEG1NB"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KKJ5ZEG1NB")</script></body></html>