<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=google-site-verification content="8_xpI-TS3tNV8UPug-Q6Ef3BhKTcy0WOG7dEdAcm2zk"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="祝融"><link rel=dns-prefetch href=//cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=preconnect href=https://www.googletagmanager.com crossorigin><link rel=canonical href=https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-12/><title>祝融说。 第十二章：当LLM遇见知识图谱：构建与应用</title><meta property="og:title" content="第十二章：当LLM遇见知识图谱：构建与应用"><meta property="og:url" content="https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-12/"><meta property="og:site_name" content="祝融说。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:published_time" content="2025-12-09T00:00:00+08:00"><meta property="article:modified_time" content="2025-12-09T00:00:00+08:00"><meta property="article:tag" content="书稿"><meta name=description content="在前面的章节中，我们已经深入探索了如何构建、微调和部署强大的大语言模型（LLM）。我们知道，LLM通过在海量文本上进行预训练，学习到了丰富的世界知识和强大的语言能力。它像一个博览群书、无所不知的“通才”，能够就任何话题侃侃而谈。
然而，我们也清楚地认识到LLM的固有缺陷：
"><meta property="og:description" content="在前面的章节中，我们已经深入探索了如何构建、微调和部署强大的大语言模型（LLM）。我们知道，LLM通过在海量文本上进行预训练，学习到了丰富的世界知识和强大的语言能力。它像一个博览群书、无所不知的“通才”，能够就任何话题侃侃而谈。
然而，我们也清楚地认识到LLM的固有缺陷：
"><meta property="og:image" content="https://zhurongshuo.com/images/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="第十二章：当LLM遇见知识图谱：构建与应用"><meta name=twitter:description content="在前面的章节中，我们已经深入探索了如何构建、微调和部署强大的大语言模型（LLM）。我们知道，LLM通过在海量文本上进行预训练，学习到了丰富的世界知识和强大的语言能力。它像一个博览群书、无所不知的“通才”，能够就任何话题侃侃而谈。
然而，我们也清楚地认识到LLM的固有缺陷：
"><meta name=twitter:image content="https://zhurongshuo.com/images/favicon.ico"><meta name=keywords content="AI工程师实战：从Python基础到LLM应用与性能优化,第十二章：当LLM遇见知识图谱：构建与应用"><link rel="shortcut icon" href=https://zhurongshuo.com/images/favicon.ico><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/animate-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/zozo.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/remixicon-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/highlight.css><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"第十二章：当LLM遇见知识图谱：构建与应用","description":"在前面的章节中，我们已经深入探索了如何构建、微调和部署强大的大语言模型（LLM）。我们知道，LLM通过在海量文本上进行预训练，学习到了丰富的世界知识和强大的语言能力。它像一个博览群书、无所不知的“通才”，能够就任何话题侃侃而谈。\n然而，我们也清楚地认识到LLM的固有缺陷：\n","datePublished":"2025-12-09T00:00:00\u002b08:00","dateModified":"2025-12-09T00:00:00\u002b08:00","author":{"@type":"Person","name":"祝融"},"publisher":{"@type":"Organization","name":"祝融说。","logo":{"@type":"ImageObject","url":"https:\/\/zhurongshuo.com\/images\/favicon.ico"}},"image":"https:\/\/zhurongshuo.com\/images\/favicon.ico","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zhurongshuo.com\/practices\/season-4\/ai-engineer-in-action\/part-03\/chapter-12\/"},"keywords":"书稿"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"首页","item":"https:\/\/zhurongshuo.com\/"},{"@type":"ListItem","position":2,"name":"practices","item":"https:\/\/zhurongshuo.com\/practices/"},{"@type":"ListItem","position":3,"name":"第十二章：当LLM遇见知识图谱：构建与应用","item":"https:\/\/zhurongshuo.com\/practices\/season-4\/ai-engineer-in-action\/part-03\/chapter-12\/"}]}</script></head><body><div class="main animate__animated animate__fadeInDown"><div class="nav_container animated fadeInDown"><div class=site_nav id=site_nav><ul><li><a href=https://zhurongshuo.com/>首页</a></li><li><a href=https://zhurongshuo.com/start/>开始</a></li><li><a href=https://zhurongshuo.com/advanced/>进阶rc</a></li><li><a href=https://zhurongshuo.com/posts/>归档</a></li><li><a href=https://zhurongshuo.com/tags/>标签</a></li><li><a href=https://zhurongshuo.com/about/>关于</a></li></ul></div><div class=menu_icon><a id=menu_icon><i class=ri-menu-line></i></a></div></div><div class="header animated fadeInDown"><div class=site_title_container><div class=site_title><h1><a href=https://zhurongshuo.com/><span class=web-font>祝融说。</span></a></h1></div><div class=description><p class=sub_title>法不净空，觉无性也。</p><div class=my_socials><a href=https://zhurongshuo.com/books/ title=book-open><i class=ri-book-open-line></i></a>
<a href=https://zhurongshuo.com/practices/ title=trophy><i class=ri-trophy-line></i></a>
<a href=https://zhurongshuo.com/gallery/ title=gallery><i class=ri-gallery-line></i></a>
<a href=https://zhurongshuo.com/about/ title=game><i class=ri-game-line></i></a>
<a href type=application/rss+xml title=rss target=_blank><i class=ri-rss-fill></i></a></div></div></div></div><div class=content><div class=post_page><div class="post animate__animated animate__fadeInDown"><div class="post_title post_detail_title"><h2><a href=https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-12/>第十二章：当LLM遇见知识图谱：构建与应用</a></h2><span class=date>2025.12.09</span></div><div class="post_content markdown"><p>在前面的章节中，我们已经深入探索了如何构建、微调和部署强大的大语言模型（LLM）。我们知道，LLM通过在海量文本上进行预训练，学习到了丰富的世界知识和强大的语言能力。它像一个博览群书、无所不知的“通才”，能够就任何话题侃侃而谈。</p><p>然而，我们也清楚地认识到LLM的固有缺陷：</p><ul><li>知识是隐性的、非结构化的：LLM的知识存储在其数十亿个参数构成的“黑箱”之中，我们无法轻易地对其进行审查、编辑或更新。</li><li>容易产生幻觉：它的知识是统计性的，而非事实性的。当被问及它不确定或不知道的信息时，它倾向于“编造”看似合理的答案。</li><li>逻辑推理能力有限：尽管LLM展现出一定的推理能力，但它在处理复杂、多跳的逻辑关系时，仍然容易出错。</li></ul><p>与此同时，在人工智能领域，存在着另一条历史悠久、思想迥异的技术路线——知识图谱（Knowledge Graph, KG）。知识图谱以一种结构化的、图的形式来表示世界知识。它由实体（Entities）（如“莱昂纳多·迪卡普里奥”、“《泰坦尼克号》”）和连接这些实体的关系（Relations）（如“主演”、“导演”）组成。</p><p>知识图谱像一个严谨、精确的“专家”，它的每一个知识点都是明确的、可验证的、可解释的。它的优势恰好是LLM的劣势：
知识是显性的、结构化的：我们可以清晰地看到、查询和修改图中的每一个事实。</p><p>事实性强，无幻觉：图中存储的都是确定的事实，不存在模糊和编造。
强大的多跳推理能力：图数据库天然支持沿着关系路径进行复杂查询，例如“找出所有由詹姆斯·卡梅隆导演，并且由莱昂纳多·迪卡普里奥主演的电影的类型”。</p><p>当“博学”的LLM遇见“严谨”的知识图谱，一场深刻的化学反应正在发生。这两种技术范式的结合，被认为是构建下一代更强大、更可靠、更可解释的AI系统的关键。LLM强大的自然语言理解能力，可以被用来自动地从非结构化文本中构建知识图谱；而知识图谱精确的、结构化的知识，则可以反过来增强LLM，为其提供事实依据，提升其推理的精准度。</p><p>本章，我们将深入探索这个激动人心的交叉领域。我们将学习：</p><ul><li>知识图谱基础：我们将从零开始，理解实体、关系、三元组这些基本概念，并了解专门用于存储和查询图数据的图数据库。</li><li>Neo4j与Cypher：我们将上手业界最流行的图数据库——Neo4j，并学习其强大直观的图查询语言Cypher。</li><li>从文本自动构建知识图谱：我们将利用LLM的强大能力，设计一套工作流，从非结构化文本中自动提取实体和关系，并将其注入知识图谱。</li><li>KG-RAG：我们将学习一种比传统向量检索更高级的RAG范式——知识图谱增强的检索（KG-RAG）。你将理解如何将用户的自然语言问题，转换为对知识图谱的结构化查询，从而获得更精准、更具解释性的答案。</li><li>实战项目：我们将通过一个完整的实战项目——构建一个小型电影知识图谱，并结合LLM实现自然语言查询——将本章所有技术融会贯通，亲手打造一个能用大白话提问的“电影知识专家”。</li></ul><p>掌握LLM与知识图谱的融合技术，将使你站在AI应用开发的最前沿。你将能够构建出不仅“能说会道”，而且“有理有据”的AI系统，真正迈向更可信、更智能的未来。</p><h2 id=121-知识图谱基础实体关系与图数据库>12.1 知识图谱基础：实体、关系与图数据库</h2><h3 id=1211-什么是知识图谱>12.1.1 什么是知识图谱？</h3><p>知识图谱（Knowledge Graph, KG）本质上是一个语义网络（Semantic Network），它以图（Graph）的数据结构，来描述现实世界中的概念、实体及其相互关系。</p><p>一个知识图谱由最基本的单元——三元组（Triple）——构成。一个三元组的形式是 (头实体, 关系, 尾实体)，或者说 (Subject, Predicate, Object)。</p><p>例如，对于事实“莱昂纳多主演了《泰坦尼克号》”，我们可以将其表示为：</p><ul><li>头实体（Subject）：莱昂纳多·迪卡普里奥</li><li>关系（Predicate）：主演</li><li>尾实体（Object）：《泰坦尼克号》</li></ul><p>当成千上万个这样的三元组汇集在一起时，它们就交织成了一张巨大的、网状的知识图谱。</p><p>一个简单的电影知识图谱示例</p><p>在这个图中：</p><ul><li>节点（Nodes） 或 实体（Entities）：代表现实世界中的对象，如<code>Tom Hanks</code>（演员）、<code>Forrest Gump</code>（电影）。节点可以有标签（Labels）来表示其类型（如<code>:Person</code>, <code>:Movie</code>），以及属性（Properties）来存储其自身的信息（如<code>name: "Tom Hanks"</code>, <code>born: 1956</code>）。</li><li>边（Edges） 或 关系（Relations）：代表实体之间的联系，如<code>ACTED_IN</code>。关系也可以有属性（如<code>roles: ["Forrest"]</code>）。</li></ul><h3 id=1212-为什么需要图数据库>12.1.2 为什么需要图数据库？</h3><p>你可能会问，这些信息不也可以用传统的关系型数据库（如MySQL）来存储吗？比如创建一张<code>actors</code>表，一张<code>movies</code>表，再创建一张<code>acting_relations</code>中间表。</p><p>对于简单、固定的查询，关系型数据库是可行的。但当我们需要探索实体之间复杂、多跳、未知深度的关系时，关系型数据库的弊端就暴露无遗了。</p><p>想象一个查询：“找出与Tom Hanks合作过的演员，这些演员又与其他哪些导演合作过？”</p><p>在关系型数据库中，这需要进行多次、代价高昂的<code>JOIN</code>操作。随着查询深度的增加，<code>JOIN</code>的次数会呈指数级增长，查询性能会急剧下降。</p><p>在图数据库中，这个查询非常自然。它就像从<code>Tom Hanks</code>这个节点出发，沿着<code>ACTED_IN</code>关系找到他演过的电影，再从这些电影节点出发，沿着<code>ACTED_IN</code>的反向关系找到其他演员，再从这些演员出发... 这个过程称为图遍历（Graph Traversal）。图数据库对这种遍历操作进行了深度优化，其性能远超关系型数据库。</p><p>图数据库的核心优势：Index-free Adjacency（免索引邻接）。每个节点都直接持有指向其邻居节点的“指针”。当需要遍历时，数据库可以直接跟随这些指针，而无需像关系型数据库那样通过索引去查找匹配的行。这使得图数据库在处理深度关联查询时，性能不会随着数据总量的增加而显著下降。</p><h3 id=1213-知识图谱的类型>12.1.3 知识图谱的类型</h3><p>通用知识图谱（General KG）：旨在覆盖尽可能广泛的通用领域知识。著名的例子有Google Knowledge Graph, Wikidata, DBpedia, Freebase。它们规模巨大，知识面广，但可能不够深入或实时。</p><p>领域知识图谱（Domain-specific KG）：专注于某个特定领域，如金融、医疗、电商、法律等。它们通常由企业自己构建，包含大量私有的、专业的知识，是企业重要的知识资产。我们本章的重点，就是如何构建和应用领域知识图谱。</p><h2 id=122-neo4j入门与cypher查询语言>12.2 Neo4j入门与Cypher查询语言</h2><p>Neo4j是目前最流行、最成熟的图数据库之一。它是一个原生的图数据库，完全围绕图的结构进行设计和优化。</p><h3 id=1221-安装与启动neo4j>12.2.1 安装与启动Neo4j</h3><p>最简单的方式是使用Docker：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --name neo4j-llm <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    -p 7474:7474 -p 7687:7687 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    -d <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    -e <span class=nv>NEO4J_AUTH</span><span class=o>=</span>neo4j/password <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    neo4j:latest
</span></span></code></pre></div><p><code>7474</code>端口是Neo4j Browser的HTTP端口，一个用于交互式查询和可视化的Web界面。</p><p><code>7687</code>端口是Bolt协议的端口，是应用程序通过驱动程序连接Neo4j的端口。</p><p>启动后，在浏览器中访问<code>http://localhost:7474</code>，使用用户名<code>neo4j</code>和密码<code>password</code>登录，即可进入Neo4j Browser。</p><h3 id=1222-cypher为图而生的查询语言>12.2.2 Cypher：为图而生的查询语言</h3><p>Cypher是Neo4j的声明式图查询语言。它的设计哲学是“用ASCII艺术来画图”，语法非常直观。</p><p>核心语法元素：</p><ul><li>节点：用圆括号<code>()</code>表示。<ul><li><code>(n)</code>：一个匿名的、任意类型的节点。</li><li><code>(p:Person)</code>：一个标签为<code>Person</code>的节点，并用变量<code>p</code>来引用它。</li><li><code>(m:Movie {title: 'Forrest Gump'})</code>：一个标签为<code>Movie</code>，且<code>title</code>属性为'Forrest Gump'的节点。</li></ul></li><li>关系：用方括号<code>[]</code>和箭头<code>--></code>或<code>&lt;--</code>表示。<ul><li><code>-[r]-</code>：一个匿名的、任意方向的关系。</li><li><code>-[r:ACTED_IN]-></code>：一个类型为<code>ACTED_IN</code>、方向从左到右的关系，并用变量<code>r</code>引用它。</li><li><code>-[r:DIRECTED {year: 1994}]-></code>：一个带属性的关系。</li></ul></li><li>模式（Pattern）：将节点和关系组合起来，描述你想要查找的图结构。<ul><li><code>(p:Person)-[:ACTED_IN]->(m:Movie)</code>：描述了一个人参演了一部电影的模式。</li></ul></li></ul><p>常用Cypher子句：</p><ul><li><p><code>CREATE</code>：创建节点和关系。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>CREATE (p:Person {name: &#39;Tom Hanks&#39;, born: 1956})
</span></span><span class=line><span class=cl>CREATE (m:Movie {title: &#39;Forrest Gump&#39;, released: 1994})
</span></span><span class=line><span class=cl>CREATE (p)-[:ACTED_IN {roles: [&#39;Forrest&#39;]}]-&gt;(m)
</span></span></code></pre></div></li><li><p><code>MATCH</code>：匹配图中的模式，这是最常用的查询子句。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>// 查找Tom Hanks演过的所有电影
</span></span><span class=line><span class=cl>MATCH (p:Person {name: &#39;Tom Hanks&#39;})-[:ACTED_IN]-&gt;(m:Movie)
</span></span><span class=line><span class=cl>RETURN m.title
</span></span></code></pre></div></li><li><p><code>RETURN</code>：指定查询返回的结果。</p></li><li><p><code>WHERE</code>：添加过滤条件。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>// 查找1990年后上映的，由Tom Hanks主演的电影
</span></span><span class=line><span class=cl>MATCH (p:Person {name: &#39;Tom Hanks&#39;})-[:ACTED_IN]-&gt;(m:Movie)
</span></span><span class=line><span class=cl>WHERE m.released &gt; 1990
</span></span><span class=line><span class=cl>RETURN m.title, m.released
</span></span></code></pre></div></li><li><p><code>MERGE</code>：智能版的<code>CREATE</code>。如果模式不存在，则创建它；如果已存在，则匹配它。这常用于避免创建重复的节点。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>MERGE (p:Person {name: &#39;Robert Zemeckis&#39;})
</span></span><span class=line><span class=cl>MERGE (m:Movie {title: &#39;Forrest Gump&#39;})
</span></span><span class=line><span class=cl>MERGE (p)-[:DIRECTED]-&gt;(m)
</span></span></code></pre></div></li><li><p><code>DELETE</code>：删除节点和关系。</p></li><li><p><code>SET</code>：修改节点或关系的属性。</p></li></ul><p>多跳查询示例：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>// 查找与Tom Hanks合作过的演员（不包括他自己）
</span></span><span class=line><span class=cl>MATCH (tom:Person {name: &#39;Tom Hanks&#39;})-[:ACTED_IN]-&gt;(m:Movie)&lt;-[:ACTED_IN]-(cofactor:Person)
</span></span><span class=line><span class=cl>WHERE tom &lt;&gt; cofactor
</span></span><span class=line><span class=cl>RETURN DISTINCT cofactor.name
</span></span></code></pre></div><p>这个查询的直观解释是：找到Tom Hanks，沿着<code>ACTED_IN</code>关系找到他演的电影，再从这些电影沿着<code>ACTED_IN</code>的反向关系找到其他演员。Cypher的表达能力和直观性，使其成为处理图数据的强大工具。</p><h2 id=123-从文本中自动构建知识图谱>12.3 从文本中自动构建知识图谱</h2><p>手动构建知识图谱费时费力。利用LLM强大的自然语言理解和结构化信息提取能力，我们可以实现从非结构化文本中自动构建知识图谱（KG Auto-construction）。</p><p>工作流程：</p><ol><li>定义图谱模式（Schema）：首先，明确你希望图谱中包含哪些类型的实体和关系。例如，在电影领域，实体类型可以是<code>:Movie</code>, <code>:Person</code>, <code>:Genre</code>；关系类型可以是<code>:ACTED_IN</code>, <code>:DIRECTED</code>, <code>:BELONGS_TO_GENRE</code>。</li><li>设计提取Prompt：设计一个强大的Prompt，指导LLM从给定的文本中，提取出符合我们定义的Schema的三元组。</li><li>文本处理与信息提取：将源文档（如维基百科页面、新闻文章）分块，然后将每个文本块连同提取Prompt一起发送给LLM。</li><li>结构化输出解析：要求LLM以JSON等结构化格式返回提取结果，便于程序解析。</li><li>注入图数据库：将解析出的三元组，使用<code>MERGE</code>语句写入Neo4j，构建或更新知识图谱。</li></ol><p>示例：使用LLM从文本中提取电影信息</p><p>输入文本（Input Text）：</p><blockquote><p>"Forrest Gump is a 1994 American comedy-drama film directed by Robert Zemeckis and written by Eric Roth. It is based on the 1986 novel of the same name by Winston Groom. The film stars Tom Hanks, Robin Wright, Gary Sinise, Mykelti Williamson and Sally Field."</p></blockquote><p>提取Prompt (Extraction Prompt)：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>You are an expert in knowledge graph construction. From the text provided, extract entities and relationships according to the following schema.
</span></span><span class=line><span class=cl>Return the result in a JSON format with two keys: &#34;entities&#34; and &#34;relationships&#34;.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Schema:
</span></span><span class=line><span class=cl>- Entities:
</span></span><span class=line><span class=cl>  - Person: {name: string}
</span></span><span class=line><span class=cl>  - Movie: {title: string, released: integer}
</span></span><span class=line><span class=cl>  - Genre: {name: string}
</span></span><span class=line><span class=cl>- Relationships:
</span></span><span class=line><span class=cl>  - (Person)-[:ACTED_IN]-&gt;(Movie)
</span></span><span class=line><span class=cl>  - (Person)-[:DIRECTED]-&gt;(Movie)
</span></span><span class=line><span class=cl>  - (Movie)-[:BELONGS_TO_GENRE]-&gt;(Genre)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Text:
</span></span><span class=line><span class=cl>&#34;&#34;&#34;
</span></span><span class=line><span class=cl>Forrest Gump is a 1994 American comedy-drama film directed by Robert Zemeckis and written by Eric Roth. It is based on the 1986 novel of the same name by Winston Groom. The film stars Tom Hanks, Robin Wright, Gary Sinise, Mykelti Williamson and Sally Field.
</span></span><span class=line><span class=cl>&#34;&#34;&#34;
</span></span></code></pre></div><p>LLM的预期JSON输出 (Expected JSON Output)：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;entities&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Movie&#34;</span><span class=p>,</span> <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Forrest Gump&#34;</span><span class=p>,</span> <span class=nt>&#34;released&#34;</span><span class=p>:</span> <span class=mi>1994</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Person&#34;</span><span class=p>,</span> <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Robert Zemeckis&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Person&#34;</span><span class=p>,</span> <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Tom Hanks&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Person&#34;</span><span class=p>,</span> <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Robin Wright&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Genre&#34;</span><span class=p>,</span> <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Comedy&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Genre&#34;</span><span class=p>,</span> <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Drama&#34;</span><span class=p>}}</span>
</span></span><span class=line><span class=cl>  <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;relationships&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;source&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Person&#34;</span><span class=p>,</span> <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Robert Zemeckis&#34;</span><span class=p>},</span> <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;DIRECTED&#34;</span><span class=p>,</span> <span class=nt>&#34;target&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Movie&#34;</span><span class=p>,</span> <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Forrest Gump&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;source&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Person&#34;</span><span class=p>,</span> <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Tom Hanks&#34;</span><span class=p>},</span> <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;ACTED_IN&#34;</span><span class=p>,</span> <span class=nt>&#34;target&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Movie&#34;</span><span class=p>,</span> <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Forrest Gump&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;source&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Person&#34;</span><span class=p>,</span> <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Robin Wright&#34;</span><span class=p>},</span> <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;ACTED_IN&#34;</span><span class=p>,</span> <span class=nt>&#34;target&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Movie&#34;</span><span class=p>,</span> <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Forrest Gump&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;source&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Movie&#34;</span><span class=p>,</span> <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Forrest Gump&#34;</span><span class=p>},</span> <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;BELONGS_TO_GENRE&#34;</span><span class=p>,</span> <span class=nt>&#34;target&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Genre&#34;</span><span class=p>,</span> <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Comedy&#34;</span><span class=p>}},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;source&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Movie&#34;</span><span class=p>,</span> <span class=nt>&#34;title&#34;</span><span class=p>:</span> <span class=s2>&#34;Forrest Gump&#34;</span><span class=p>},</span> <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;BELONGS_TO_GENRE&#34;</span><span class=p>,</span> <span class=nt>&#34;target&#34;</span><span class=p>:</span> <span class=p>{</span><span class=nt>&#34;label&#34;</span><span class=p>:</span> <span class=s2>&#34;Genre&#34;</span><span class=p>,</span> <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;Drama&#34;</span><span class=p>}}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>注入Neo4j的Python代码片段：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>neo4j</span> <span class=kn>import</span> <span class=n>GraphDatabase</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>driver</span> <span class=o>=</span> <span class=n>GraphDatabase</span><span class=o>.</span><span class=n>driver</span><span class=p>(</span><span class=s2>&#34;bolt://localhost:7687&#34;</span><span class=p>,</span> <span class=n>auth</span><span class=o>=</span><span class=p>(</span><span class=s2>&#34;neo4j&#34;</span><span class=p>,</span> <span class=s2>&#34;password&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>add_to_graph</span><span class=p>(</span><span class=n>tx</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>entity</span> <span class=ow>in</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;entities&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>tx</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MERGE (n:</span><span class=si>{</span><span class=n>entity</span><span class=p>[</span><span class=s1>&#39;label&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> </span><span class=se>{{</span><span class=s2>name: $name</span><span class=se>}}</span><span class=s2>)&#34;</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=n>entity</span><span class=p>[</span><span class=s1>&#39;properties&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;name&#39;</span><span class=p>)</span> <span class=ow>or</span> <span class=n>entity</span><span class=p>[</span><span class=s1>&#39;properties&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;title&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>rel</span> <span class=ow>in</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;relationships&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>source_name</span> <span class=o>=</span> <span class=n>rel</span><span class=p>[</span><span class=s1>&#39;source&#39;</span><span class=p>][</span><span class=s1>&#39;name&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>target_name</span> <span class=o>=</span> <span class=n>rel</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>][</span><span class=s1>&#39;title&#39;</span><span class=p>]</span> <span class=k>if</span> <span class=n>rel</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>][</span><span class=s1>&#39;label&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Movie&#39;</span> <span class=k>else</span> <span class=n>rel</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>][</span><span class=s1>&#39;name&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>tx</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>            MATCH (a:</span><span class=si>{</span><span class=n>rel</span><span class=p>[</span><span class=s1>&#39;source&#39;</span><span class=p>][</span><span class=s1>&#39;label&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> </span><span class=se>{{</span><span class=s2>name: $source_name</span><span class=se>}}</span><span class=s2>)
</span></span></span><span class=line><span class=cl><span class=s2>            MATCH (b:</span><span class=si>{</span><span class=n>rel</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>][</span><span class=s1>&#39;label&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> </span><span class=se>{{</span><span class=s2>name: $target_name</span><span class=se>}}</span><span class=s2>)
</span></span></span><span class=line><span class=cl><span class=s2>            MERGE (a)-[:</span><span class=si>{</span><span class=n>rel</span><span class=p>[</span><span class=s1>&#39;type&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>]-&gt;(b)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span><span class=p>,</span> <span class=n>source_name</span><span class=o>=</span><span class=n>source_name</span><span class=p>,</span> <span class=n>target_name</span><span class=o>=</span><span class=n>target_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>driver</span><span class=o>.</span><span class=n>session</span><span class=p>()</span> <span class=k>as</span> <span class=n>session</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>session</span><span class=o>.</span><span class=n>write_transaction</span><span class=p>(</span><span class=n>add_to_graph</span><span class=p>,</span> <span class=n>llm_output_json</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>driver</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span></code></pre></div><p>通过重复这个“提取-注入”的过程，我们就可以将大量的非结构化文档，转化为一个结构精良、知识丰富的领域知识图谱。</p><h2 id=124-kg-rag用知识图谱增强检索的精准度>12.4 KG-RAG：用知识图谱增强检索的精准度</h2><p>我们在第九章学习了基于向量检索的RAG（Vector-RAG）。它的优点是实现简单，能处理任何文本。但它也存在问题：</p><ul><li>检索不够精准：基于语义相似度的检索，有时会召回一些不完全相关，或者包含噪声的文本块。</li><li>缺乏可解释性：我们不知道为什么这些文本块被认为是“相似”的。</li><li>难以回答聚合或比较性问题：例如“A和B共同出演了哪些电影？”，这种问题很难通过检索独立的文本块来回答。</li></ul><p>知识图谱增强的检索（KG-RAG）提供了一种更精准、更可解释的解决方案。其核心思想是：将用户的自然语言问题，转换为对知识图谱的结构化查询（如Cypher），直接从图中获取精确的事实，再将这些事实作为上下文提供给LLM来生成最终的自然语言答案。</p><p>KG-RAG工作流程：</p><ol><li>问题 -> Cypher转换：这是最关键的一步。我们利用LLM的强大代码生成能力，将用户的自然语言问题（如“汤姆·汉克斯演过哪些电影？”）转换为一条Cypher查询语句（<code>MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN m.title</code>）。为了让LLM能生成正确的Cypher，我们需要在Prompt中向它提供图谱的Schema信息（节点标签、属性、关系类型）。</li><li>执行Cypher查询：在Neo4j数据库中执行生成的Cypher语句。</li><li>获取结构化结果：得到一个精确的、表格形式的结果（例如，一个电影标题列表）。</li><li>结果 -> 自然语言：将这个结构化的查询结果，连同原始问题一起，再次发送给LLM，让它将这些事实“润色”成一句通顺的、人类可读的回答。</li></ol><p>示例：</p><p>用户问题: "Who directed the movie Forrest Gump?"</p><p>第一步：Text-to-Cypher</p><p>Prompt:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>You are an expert Neo4j developer. Given a question and the graph schema, generate a Cypher query to answer the question.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Schema:
</span></span><span class=line><span class=cl>Node labels: Person, Movie
</span></span><span class=line><span class=cl>Relationship types: ACTED_IN, DIRECTED
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Question: Who directed the movie Forrest Gump?
</span></span></code></pre></div><p>LLM生成的Cypher:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>MATCH (p:Person)-[:DIRECTED]-&gt;(m:Movie {title: &#39;Forrest Gump&#39;})
</span></span><span class=line><span class=cl>RETURN p.name
</span></span></code></pre></div><p>第二步：执行查询</p><p>在Neo4j中执行该查询，得到结果：<code>[{"p.name": "Robert Zemeckis"}]</code></p><p>第三步：生成最终答案</p><p>Prompt:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>You are a helpful assistant. Based on the user&#39;s question and the retrieved data, provide a natural language answer.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Question: Who directed the movie Forrest Gump?
</span></span><span class=line><span class=cl>Retrieved Data: Robert Zemeckis
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Answer:
</span></span></code></pre></div><p>LLM生成的答案: "The movie Forrest Gump was directed by Robert Zemeckis."</p><p>KG-RAG的优势：</p><ul><li>精准性：直接从图中获取事实，避免了向量检索的不确定性。</li><li>可解释性：生成的Cypher查询本身，就是对答案来源的最好解释。</li><li>强大的推理能力：能够回答需要多跳推理、聚合、过滤的复杂问题。</li></ul><p>混合策略：在实践中，我们常常将Vector-RAG和KG-RAG结合起来。对于事实性、实体性的问题，优先使用KG-RAG；对于更开放、更概念性的问题，则回退到Vector-RAG。</p><h2 id=125-实战项目构建一个小型电影知识图谱并结合llm实现自然语言查询>12.5 实战项目：构建一个小型电影知识图谱，并结合LLM实现自然语言查询</h2><p>项目目标：我们将使用一小部分维基百科的电影简介文本，自动构建一个包含电影、演员、导演的Neo4j知识图谱，并实现一个能够将用户自然语言问题转换为Cypher查询并返回答案的问答系统。</p><p>技术栈：<code>openai</code> (or other LLM library), <code>neo4j</code>, <code>langchain</code> (for simplification)</p><p>第一步：环境准备</p><ol><li>启动Neo4j Docker容器（如12.2节所示）。</li><li>安装库: <code>pip install langchain langchain-openai neo4j</code></li><li>准备一些电影简介文本文件，例如<code>forrest_gump.txt</code>, <code>the_matrix.txt</code>。</li></ol><p>第二步：从文本构建知识图谱（使用LangChain简化）</p><p>LangChain提供了方便的工具来简化这个流程。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># build_kg.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_openai</span> <span class=kn>import</span> <span class=n>ChatOpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.graphs</span> <span class=kn>import</span> <span class=n>Neo4jGraph</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains</span> <span class=kn>import</span> <span class=n>GraphCypherQAChain</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.prompts</span> <span class=kn>import</span> <span class=n>PromptTemplate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains.graph_qa.cypher</span> <span class=kn>import</span> <span class=n>GraphCypherQAChain</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># --- 1. 连接Neo4j ---</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;OPENAI_API_KEY&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;...&#34;</span>
</span></span><span class=line><span class=cl><span class=n>graph</span> <span class=o>=</span> <span class=n>Neo4jGraph</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>url</span><span class=o>=</span><span class=s2>&#34;bolt://localhost:7687&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>username</span><span class=o>=</span><span class=s2>&#34;neo4j&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>password</span><span class=o>=</span><span class=s2>&#34;password&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># --- 2. 定义从文本提取图谱的函数 ---</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains</span> <span class=kn>import</span> <span class=n>LLMChain</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.prompts.prompt</span> <span class=kn>import</span> <span class=n>PromptTemplate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_core.output_parsers</span> <span class=kn>import</span> <span class=n>StrOutputParser</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>ChatOpenAI</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4&#34;</span><span class=p>,</span> <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>extraction_prompt</span> <span class=o>=</span> <span class=n>PromptTemplate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>template</span><span class=o>=</span><span class=s2>&#34;&#34;&#34;From the text below, extract the following entities and relationships.
</span></span></span><span class=line><span class=cl><span class=s2>    Return the result as a list of Cypher MERGE statements.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Schema:
</span></span></span><span class=line><span class=cl><span class=s2>    Nodes: Person, Movie
</span></span></span><span class=line><span class=cl><span class=s2>    Relationships: ACTED_IN, DIRECTED
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Text:
</span></span></span><span class=line><span class=cl><span class=s2>    </span><span class=si>{text}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>input_variables</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;text&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_and_store_graph</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Extract graph data using LLM</span>
</span></span><span class=line><span class=cl>    <span class=n>chain</span> <span class=o>=</span> <span class=n>LLMChain</span><span class=p>(</span><span class=n>llm</span><span class=o>=</span><span class=n>llm</span><span class=p>,</span> <span class=n>prompt</span><span class=o>=</span><span class=n>extraction_prompt</span><span class=p>,</span> <span class=n>output_parser</span><span class=o>=</span><span class=n>StrOutputParser</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>cypher_statements</span> <span class=o>=</span> <span class=n>chain</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>    <span class=c1># Store data in Neo4j</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>stmt</span> <span class=ow>in</span> <span class=n>cypher_statements</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>stmt</span><span class=o>.</span><span class=n>strip</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>graph</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=n>stmt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Executed: </span><span class=si>{</span><span class=n>stmt</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Error executing </span><span class=si>{</span><span class=n>stmt</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># --- 3. 读取文本并构建图谱 ---</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&#34;forrest_gump.txt&#34;</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>forrest_gump_text</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>extract_and_store_graph</span><span class=p>(</span><span class=n>forrest_gump_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&#34;the_matrix.txt&#34;</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>the_matrix_text</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>extract_and_store_graph</span><span class=p>(</span><span class=n>the_matrix_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;知识图谱构建完成。&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><em>注意：上述<code>extraction_prompt</code>要求LLM直接生成Cypher语句，这是一种更直接高效的方式。你需要确保LLM（如GPT-4）有足够强的代码生成能力。</em></p><p>第三步：实现Text-to-Cypher问答链</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># qa_with_kg.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_openai</span> <span class=kn>import</span> <span class=n>ChatOpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.graphs</span> <span class=kn>import</span> <span class=n>Neo4jGraph</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.chains</span> <span class=kn>import</span> <span class=n>GraphCypherQAChain</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># --- 1. 连接Neo4j和LLM ---</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;OPENAI_API_KEY&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;...&#34;</span>
</span></span><span class=line><span class=cl><span class=n>graph</span> <span class=o>=</span> <span class=n>Neo4jGraph</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>url</span><span class=o>=</span><span class=s2>&#34;bolt://localhost:7687&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>username</span><span class=o>=</span><span class=s2>&#34;neo4j&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>password</span><span class=o>=</span><span class=s2>&#34;password&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>ChatOpenAI</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4&#34;</span><span class=p>,</span> <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># --- 2. 创建GraphCypherQAChain ---</span>
</span></span><span class=line><span class=cl><span class=c1># LangChain的这个链封装了Text-to-Cypher和结果合成的完整流程</span>
</span></span><span class=line><span class=cl><span class=n>chain</span> <span class=o>=</span> <span class=n>GraphCypherQAChain</span><span class=o>.</span><span class=n>from_llm</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>graph</span><span class=o>=</span><span class=n>graph</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>llm</span><span class=o>=</span><span class=n>llm</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span> <span class=c1># 打印出生成的Cypher和中间步骤</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># --- 3. 进行提问 ---</span>
</span></span><span class=line><span class=cl><span class=n>questions</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Who acted in the movie Forrest Gump?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Which movies did Keanu Reeves act in?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Who directed The Matrix?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>question</span> <span class=ow>in</span> <span class=n>questions</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Question: </span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span><span class=s2>&#34;query&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>})</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Answer: </span><span class=si>{</span><span class=n>result</span><span class=p>[</span><span class=s1>&#39;result&#39;</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>当你运行<code>qa_with_kg.py</code>时，<code>verbose=True</code>会让你看到神奇的幕后过程：</p><ol><li>对于问题 "Who acted in the movie Forrest Gump?"，LLM会生成类似 <code>MATCH (p:Person)-[:ACTED_IN]->(m:Movie {title: 'Forrest Gump'}) RETURN p.name</code> 的Cypher。</li><li><code>GraphCypherQAChain</code>会执行这个Cypher，从Neo4j获取演员列表。</li><li>最后，LLM会将这个列表格式化成一句通顺的回答，如 "Tom Hanks, Robin Wright, and Gary Sinise acted in the movie Forrest Gump."</li></ol><p>这个项目完美地展示了LLM与知识图谱如何协同工作，将非结构化的知识转化为可查询的结构化资产，并最终以自然语言的形式服务于用户，实现了1+1>2的效果。</p><h2 id=本章小结>本章小结</h2><p>在本章中，我们探索了AI领域一个极具深度和价值的前沿方向——大语言模型与知识图谱的融合。</p><p>我们从知识图谱的基础出发，理解了其作为一种结构化知识表示方法的强大之处，并学习了如何使用业界领先的图数据库Neo4j及其查询语言Cypher来存储和查询复杂的关联数据。</p><p>我们掌握了一项核心的工程能力：利用LLM从非结构化文本中自动构建知识图谱。我们学会了如何设计Prompt，引导LLM提取实体和关系，并将其持久化到图数据库中，将沉睡的文本数据转化为鲜活的知识网络。</p><p>在此基础上，我们学习了一种更高级的RAG范式——KG-RAG。我们理解了其如何通过Text-to-Cypher技术，将用户的自然语言问题转换为对知识图谱的精准查询，从而克服了传统向量检索的局限性，获得了更精确、更可解释的答案。</p><p>最后，通过一个构建电影知识图谱问答系统的实战项目，我们将所有理论和技术点串联起来，亲手打造了一个LLM与KG协同工作的智能应用。</p><p>完成本章后，你的AI工具箱中又增添了一件强大的“神器”。你不再仅仅依赖于LLM自身的、模糊的、不可控的知识，而是学会了如何为其配备一个精确、可靠、可演进的“外置事实大脑”。这种将LLM的语言能力与知识图谱的结构化推理能力相结合的复合型系统构建能力，将使你在面对需要高事实性、强逻辑性的复杂AI应用场景时，游刃有余，展现出卓越的工程设计和创新能力。</p></div><div class=post_footer><div class=meta><div class=info><span class="field tags"><i class=ri-stack-line></i>
<a href=https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/>书稿</a></span></div></div></div></div><div class=doc_comments></div></div></div></div><a id=back_to_top href=# class=back_to_top><i class=ri-arrow-up-s-line></i></a><footer class=footer><div class=powered_by><a href=https://varkai.com>Designed by VarKai, </a><a href=http://www.gohugo.io/>Proudly published with Hugo,</a></div><div class=footer_slogan><span>法不净空，觉无性也。</span></div><div class=powered_by style=margin-top:10px;font-size:14px><a href=https://zhurongshuo.com/>Copyright © 2010-2025 祝融说 zhurongshuo.com All Rights Reserved.</a></div></footer><script defer src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><link href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.css rel=stylesheet integrity="sha256-7qiTu3a8qjjWtcX9w+f2ulVUZSUdCZFEK62eRlmLmCE=" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script defer src=https://zhurongshuo.com/js/zozo.js></script><script type=text/javascript async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-KKJ5ZEG1NB"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KKJ5ZEG1NB")</script></body></html>