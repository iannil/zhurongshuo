<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=google-site-verification content="8_xpI-TS3tNV8UPug-Q6Ef3BhKTcy0WOG7dEdAcm2zk"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="祝融"><link rel=dns-prefetch href=//cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=preconnect href=https://www.googletagmanager.com crossorigin><link rel=canonical href=https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-02/><title>祝融说。 第二章：数据科学核心工具链实战</title><meta property="og:title" content="第二章：数据科学核心工具链实战"><meta property="og:url" content="https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-02/"><meta property="og:site_name" content="祝融说。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:published_time" content="2025-12-09T00:00:00+08:00"><meta property="article:modified_time" content="2025-12-09T00:00:00+08:00"><meta property="article:tag" content="书稿"><meta name=description content="如果说上一章我们修炼的Python内功是AI工程师的“心法”，那么本章将要锻造的，则是我们手中最锋利的“兵器”——数据科学核心工具链。在人工智能的世界里，数据是驱动一切的燃料。原始数据，如同未经提炼的矿石，驳杂而混乱；而模型的输入，则需要是规整、纯净的“金条”。从矿石到金条的这一过程，便是数据科学的“炼金术”，其核心技艺就蕴藏在Numpy、Pandas、Matplotlib和Scikit-learn这四大神器之中。
"><meta property="og:description" content="如果说上一章我们修炼的Python内功是AI工程师的“心法”，那么本章将要锻造的，则是我们手中最锋利的“兵器”——数据科学核心工具链。在人工智能的世界里，数据是驱动一切的燃料。原始数据，如同未经提炼的矿石，驳杂而混乱；而模型的输入，则需要是规整、纯净的“金条”。从矿石到金条的这一过程，便是数据科学的“炼金术”，其核心技艺就蕴藏在Numpy、Pandas、Matplotlib和Scikit-learn这四大神器之中。
"><meta property="og:image" content="https://zhurongshuo.com/images/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="第二章：数据科学核心工具链实战"><meta name=twitter:description content="如果说上一章我们修炼的Python内功是AI工程师的“心法”，那么本章将要锻造的，则是我们手中最锋利的“兵器”——数据科学核心工具链。在人工智能的世界里，数据是驱动一切的燃料。原始数据，如同未经提炼的矿石，驳杂而混乱；而模型的输入，则需要是规整、纯净的“金条”。从矿石到金条的这一过程，便是数据科学的“炼金术”，其核心技艺就蕴藏在Numpy、Pandas、Matplotlib和Scikit-learn这四大神器之中。
"><meta name=twitter:image content="https://zhurongshuo.com/images/favicon.ico"><meta name=keywords content="AI工程师实战：从Python基础到LLM应用与性能优化,第二章：数据科学核心工具链实战"><link rel="shortcut icon" href=https://zhurongshuo.com/images/favicon.ico><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/animate-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/zozo.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/remixicon-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/highlight.css><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"第二章：数据科学核心工具链实战","description":"如果说上一章我们修炼的Python内功是AI工程师的“心法”，那么本章将要锻造的，则是我们手中最锋利的“兵器”——数据科学核心工具链。在人工智能的世界里，数据是驱动一切的燃料。原始数据，如同未经提炼的矿石，驳杂而混乱；而模型的输入，则需要是规整、纯净的“金条”。从矿石到金条的这一过程，便是数据科学的“炼金术”，其核心技艺就蕴藏在Numpy、Pandas、Matplotlib和Scikit-learn这四大神器之中。\n","datePublished":"2025-12-09T00:00:00\u002b08:00","dateModified":"2025-12-09T00:00:00\u002b08:00","author":{"@type":"Person","name":"祝融"},"publisher":{"@type":"Organization","name":"祝融说。","logo":{"@type":"ImageObject","url":"https:\/\/zhurongshuo.com\/images\/favicon.ico"}},"image":"https:\/\/zhurongshuo.com\/images\/favicon.ico","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zhurongshuo.com\/practices\/season-4\/ai-engineer-in-action\/part-01\/chapter-02\/"},"keywords":"书稿"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"首页","item":"https:\/\/zhurongshuo.com\/"},{"@type":"ListItem","position":2,"name":"practices","item":"https:\/\/zhurongshuo.com\/practices/"},{"@type":"ListItem","position":3,"name":"第二章：数据科学核心工具链实战","item":"https:\/\/zhurongshuo.com\/practices\/season-4\/ai-engineer-in-action\/part-01\/chapter-02\/"}]}</script></head><body><div class="main animate__animated animate__fadeInDown"><div class="nav_container animated fadeInDown"><div class=site_nav id=site_nav><ul><li><a href=https://zhurongshuo.com/>首页</a></li><li><a href=https://zhurongshuo.com/start/>开始</a></li><li><a href=https://zhurongshuo.com/advanced/>进阶rc</a></li><li><a href=https://zhurongshuo.com/posts/>归档</a></li><li><a href=https://zhurongshuo.com/tags/>标签</a></li><li><a href=https://zhurongshuo.com/about/>关于</a></li></ul></div><div class=menu_icon><a id=menu_icon><i class=ri-menu-line></i></a></div></div><div class="header animated fadeInDown"><div class=site_title_container><div class=site_title><h1><a href=https://zhurongshuo.com/><span class=web-font>祝融说。</span></a></h1></div><div class=description><p class=sub_title>法不净空，觉无性也。</p><div class=my_socials><a href=https://zhurongshuo.com/books/ title=book-open><i class=ri-book-open-line></i></a>
<a href=https://zhurongshuo.com/practices/ title=trophy><i class=ri-trophy-line></i></a>
<a href=https://zhurongshuo.com/gallery/ title=gallery><i class=ri-gallery-line></i></a>
<a href=https://zhurongshuo.com/about/ title=game><i class=ri-game-line></i></a>
<a href type=application/rss+xml title=rss target=_blank><i class=ri-rss-fill></i></a></div></div></div></div><div class=content><div class=post_page><div class="post animate__animated animate__fadeInDown"><div class="post_title post_detail_title"><h2><a href=https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-02/>第二章：数据科学核心工具链实战</a></h2><span class=date>2025.12.09</span></div><div class="post_content markdown"><p>如果说上一章我们修炼的Python内功是AI工程师的“心法”，那么本章将要锻造的，则是我们手中最锋利的“兵器”——数据科学核心工具链。在人工智能的世界里，数据是驱动一切的燃料。原始数据，如同未经提炼的矿石，驳杂而混乱；而模型的输入，则需要是规整、纯净的“金条”。从矿石到金条的这一过程，便是数据科学的“炼金术”，其核心技艺就蕴藏在Numpy、Pandas、Matplotlib和Scikit-learn这四大神器之中。</p><p>Numpy，是这套工具链的基石。它为Python带来了高性能的多维数组对象和丰富的数学函数库。更重要的是，它教会我们一种全新的思考方式——向量化思维，这是告别低效循环，迈向高性能计算的第一步。</p><p>Pandas，是数据处理与分析的瑞士军刀。它提供了<code>DataFrame</code>这一强大而直观的数据结构，让我们能够像操作Excel表格一样，轻松地对结构化数据进行清洗、转换、筛选、聚合等一系列复杂操作。</p><p>Matplotlib & Seaborn，是我们的“眼睛”。它们能将枯燥的数字转化为生动的图表，帮助我们直观地理解数据分布、发现变量间的关系、洞察隐藏的模式，并最终用“数据故事”来呈现我们的发现。</p><p>Scikit-learn，是传统机器学习的集大成者。它以其统一、简洁的API，封装了从数据预处理到模型训练、评估的全流程工具，是我们快速进行基线模型（Baseline Model）搭建与验证的利器。</p><p>对于AI工程师而言，无论你未来是专注于前沿的深度学习模型，还是复杂的LLM应用，这套工具链都是你无法绕开的必经之路。因为任何模型的成功，都始于对数据的深刻理解和精细处理。一个经过精心清洗和特征工程的数据集，其价值往往胜过一个未经调优的复杂模型。</p><p>在本章中，我们将不仅仅是罗列这些库的API。我们会以一个贯穿始终的实战项目——Kaggle经典赛题“泰坦尼克号生还者预测”——为载体，模拟一次完整的数据科学项目流程。我们将从加载原始数据开始，一步步使用Pandas进行清洗和探索性分析（EDA），借助Matplotlib和Seaborn揭示数据背后的秘密，利用Numpy进行高效的数值计算，并最终使用Scikit-learn构建、训练和评估我们的预测模型。</p><p>这不仅是一次技术的学习，更是一次思维的训练。你将学会如何像一名真正的数据科学家那样思考：如何提出问题，如何通过数据寻找答案，如何验证假设，以及如何将分析结果转化为有价值的模型。</p><p>现在，让我们装载好这些强大的工具，开启这场从原始数据中“炼金”的精彩旅程。</p><h2 id=21-numpy科学计算的基石与向量化思维>2.1 Numpy：科学计算的基石与向量化思维</h2><p>Numpy（Numerical Python）是Python科学计算生态的绝对核心。几乎所有上层的数据科学库，包括Pandas、Scikit-learn、TensorFlow和PyTorch，其底层都依赖于Numpy强大的<code>ndarray</code>对象。</p><h3 id=211-ndarray不止是python列表>2.1.1 <code>ndarray</code>：不止是Python列表</h3><p>Python自带的<code>list</code>灵活但低效。<code>list</code>可以存储不同类型的元素，这意味着在内存中，它存储的是指向各个对象的指针，这些对象散布在内存各处。当你对<code>list</code>中的数字进行计算时，Python解释器需要逐个解引用指针，并对每个元素进行类型检查，这个过程非常缓慢。</p><p>Numpy的<code>ndarray</code>（n-dimensional array）则完全不同：</p><ol><li>同质性：一个<code>ndarray</code>中的所有元素都必须是相同的数据类型（如<code>int32</code>, <code>float64</code>）。</li><li>连续内存：<code>ndarray</code>在内存中是一块连续的、紧凑的区域。</li></ol><p>这两个特性带来了巨大的性能优势。由于类型统一且内存连续，Numpy可以利用底层C语言或Fortran编写的高度优化的代码，对整个数组执行数学运算，而无需在Python层面进行循环。这种操作，我们称之为向量化（Vectorization）。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建一个大列表和一个ndarray</span>
</span></span><span class=line><span class=cl><span class=n>n</span> <span class=o>=</span> <span class=mi>10_000_000</span>
</span></span><span class=line><span class=cl><span class=n>py_list</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>np_array</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Python列表循环求平方</span>
</span></span><span class=line><span class=cl><span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>py_list_squared</span> <span class=o>=</span> <span class=p>[</span><span class=n>x2</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>py_list</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>end_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Python list comprehension time: </span><span class=si>{</span><span class=n>end_time</span> <span class=o>-</span> <span class=n>start_time</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2> s&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Numpy向量化求平方</span>
</span></span><span class=line><span class=cl><span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>np_array_squared</span> <span class=o>=</span> <span class=n>np_array</span>  <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>end_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Numpy vectorization time: </span><span class=si>{</span><span class=n>end_time</span> <span class=o>-</span> <span class=n>start_time</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2> s&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>输出（结果可能因机器而异，但数量级差异是显著的）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Python list comprehension time: 2.6512 s
</span></span><span class=line><span class=cl>Numpy vectorization time: 0.0210 s
</span></span></code></pre></div><p>性能差异高达100倍以上！这就是向量化思维的力量。在进行数值计算时，你的第一反应应该是：“我能否用一个Numpy操作来替代这个for循环？”</p><h3 id=212-核心操作创建索引与广播>2.1.2 核心操作：创建、索引与广播</h3><p>创建数组：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 从列表创建</span>
</span></span><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建特定形状和值的数组</span>
</span></span><span class=line><span class=cl><span class=n>zeros</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>      <span class=c1># 2x3的全0数组</span>
</span></span><span class=line><span class=cl><span class=n>ones</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=mi>3</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>       <span class=c1># 3x2的全1数组</span>
</span></span><span class=line><span class=cl><span class=n>full</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>full</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span> <span class=mi>7</span><span class=p>)</span>    <span class=c1># 2x2的全7数组</span>
</span></span><span class=line><span class=cl><span class=n>eye</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>              <span class=c1># 3x3的单位矩阵</span>
</span></span><span class=line><span class=cl><span class=n>rand</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># 2x3的[0,1)均匀分布随机数</span>
</span></span></code></pre></div><p>索引与切片：</p><p>Numpy的索引比Python列表更强大，支持多维索引和高级索引。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>arr</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 基础索引</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>arr</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>  <span class=c1># 输出: 2 (第0行，第1列)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 切片</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>arr</span><span class=p>[:</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>:])</span> <span class=c1># 输出: [[2, 3], [5, 6]] (前2行，从第1列到末尾)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 布尔索引 (极其重要！)</span>
</span></span><span class=line><span class=cl><span class=n>bool_idx</span> <span class=o>=</span> <span class=n>arr</span> <span class=o>&gt;</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>bool_idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># [[False False False]</span>
</span></span><span class=line><span class=cl><span class=c1>#  [False False  True]</span>
</span></span><span class=line><span class=cl><span class=c1>#  [ True  True  True]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>arr</span><span class=p>[</span><span class=n>bool_idx</span><span class=p>])</span> <span class=c1># 输出: [6 7 8 9] (所有大于5的元素)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 整数数组索引 (花式索引)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>arr</span><span class=p>[[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]])</span> <span class=c1># 输出: [2 9] (获取(0,1)和(2,2)两个位置的元素)</span>
</span></span></code></pre></div><p>布尔索引是在数据分析中进行条件筛选的核心技巧，我们将在Pandas部分看到它的身影。</p><p>广播（Broadcasting）：</p><p>广播是Numpy最强大也最容易让人困惑的特性之一。它描述了Numpy在处理不同形状的数组进行算术运算时的规则。简单来说，如果两个数组的形状不匹配，Numpy会尝试“扩展”（或“广播”）较小的数组，使其形状与较大的数组兼容。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>]])</span> <span class=c1># shape (2, 3)</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>30</span><span class=p>])</span>           <span class=c1># shape (3,)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># a的每一行都与b相加</span>
</span></span><span class=line><span class=cl><span class=n>c</span> <span class=o>=</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>c</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># [[11 22 33]</span>
</span></span><span class=line><span class=cl><span class=c1>#  [14 25 36]]</span>
</span></span></code></pre></div><p>这里，<code>b</code> (shape <code>(3,)</code>) 被广播成了 <code>[[10, 20, 30], [10, 20, 30]]</code> (shape <code>(2, 3)</code>)，然后与 <code>a</code> 进行逐元素相加。广播使得我们无需手动创建重复的行或列，代码更简洁，内存效率更高。</p><h3 id=213-在ai中的角色>2.1.3 在AI中的角色</h3><p>数据表示：图像可以表示为 <code>(height, width, channels)</code> 的3D <code>ndarray</code>，文本数据经过词嵌入后可以表示为 <code>(num_tokens, embedding_dim)</code> 的2D <code>ndarray</code>。</p><p>数学运算：所有深度学习框架的底层张量运算，都与Numpy的API和思想高度一致。掌握Numpy的矩阵乘法（<code>@</code> 或 <code>np.dot</code>）、求和（<code>np.sum</code>）、均值（<code>np.mean</code>）等，是理解模型内部计算的基础。</p><p>与库的交互：Pandas的 <code>DataFrame</code> 可以轻松地与Numpy数组相互转换（<code>.values</code> 属性和 <code>pd.DataFrame()</code> 构造函数），是连接数据处理和模型训练的桥梁。</p><h2 id=22-pandas从数据清洗到探索性数据分析eda>2.2 Pandas：从数据清洗到探索性数据分析（EDA）</h2><p>如果说Numpy是处理纯粹数字的利器，那么Pandas就是为处理现实世界中混杂、不完美的表格数据（结构化数据）而生的。</p><h3 id=221-两大核心数据结构series-和-dataframe>2.2.1 两大核心数据结构：<code>Series</code> 和 <code>DataFrame</code></h3><p><code>Series</code>：一个带标签的一维数组。可以看作是Numpy一维数组的加强版，因为它有一个与之关联的索引（index）。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=n>s</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span> <span class=n>index</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;a&#39;</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=s1>&#39;c&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>s</span><span class=p>[</span><span class=s1>&#39;b&#39;</span><span class=p>])</span> <span class=c1># 输出: 20</span>
</span></span></code></pre></div><p><code>DataFrame</code>：一个二维的、带标签的数据结构，可以看作是共享相同索引的<code>Series</code>的集合。它是Pandas中使用最广泛的数据结构，直观上就像一个Excel表格或SQL表。</p><p>每一列都是一个<code>Series</code>。有行索引（index）和列索引（columns）。</p><h3 id=222-实战载入泰坦尼克号数据集>2.2.2 实战载入：泰坦尼克号数据集</h3><p>现在，我们正式开始我们的Kaggle项目。首先，下载泰坦尼克号数据集（通常包含<code>train.csv</code>和<code>test.csv</code>），并使用Pandas加载。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 假设数据文件在 &#39;data/&#39; 目录下</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;data/train.csv&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;data/test.csv&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 初步探索数据</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;训练集形状:&#34;</span><span class=p>,</span> <span class=n>train_df</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>前5行数据:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_df</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>数据基本信息:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span><span class=o>.</span><span class=n>info</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>数值特征描述性统计:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_df</span><span class=o>.</span><span class=n>describe</span><span class=p>())</span>
</span></span></code></pre></div><ul><li><code>head()</code>、<code>info()</code>、<code>describe()</code> 是探索任何新数据集的“三板斧”。</li><li><code>head()</code> 让我们对数据长什么样有一个直观印象。</li><li><code>info()</code> 告诉我们每列的数据类型和缺失值情况，这是数据清洗的起点。</li><li><code>describe()</code> 提供了数值列的均值、标准差、分位数等统计信息，有助于我们发现异常值。</li></ul><p>从<code>info()</code>的输出中，我们立刻发现 <code>Age</code>、<code>Cabin</code> 和 <code>Embarked</code> 列存在缺失值。<code>Cabin</code> 的缺失尤其严重。</p><h3 id=223-数据清洗处理缺失值重复值与异常值>2.2.3 数据清洗：处理缺失值、重复值与异常值</h3><p>处理缺失值 (<code>NaN</code>)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 检查每列的缺失值数量</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_df</span><span class=o>.</span><span class=n>isnull</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 策略1: 填充 (Imputation)</span>
</span></span><span class=line><span class=cl><span class=c1># Age: 用年龄的中位数填充，因为年龄分布可能偏斜</span>
</span></span><span class=line><span class=cl><span class=n>age_median</span> <span class=o>=</span> <span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>median</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=n>age_median</span><span class=p>,</span> <span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Embarked: 用出现次数最多的港口填充</span>
</span></span><span class=line><span class=cl><span class=n>embarked_mode</span> <span class=o>=</span> <span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Embarked&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mode</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Embarked&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=n>embarked_mode</span><span class=p>,</span> <span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 策略2: 删除</span>
</span></span><span class=line><span class=cl><span class=c1># Cabin: 缺失值太多，直接删除该列</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s1>&#39;Cabin&#39;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 同样的操作也需要对 test_df 进行</span>
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span></code></pre></div><p><code>inplace=True</code> 表示直接在原DataFrame上修改。<code>axis=1</code> 表示操作针对列。</p><p>处理重复值</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 检查是否有完全重复的行</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;重复行数量: </span><span class=si>{</span><span class=n>train_df</span><span class=o>.</span><span class=n>duplicated</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># train_df.drop_duplicates(inplace=True) # 如果有，则删除</span>
</span></span></code></pre></div><h3 id=224-数据筛选与转换loc-iloc-与特征工程>2.2.4 数据筛选与转换：<code>.loc</code>, <code>.iloc</code> 与特征工程</h3><p>数据筛选</p><ul><li><code>.loc</code>：基于标签的索引。</li><li><code>.iloc</code>：基于整数位置的索引。</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 筛选年龄大于60岁的男性乘客</span>
</span></span><span class=line><span class=cl><span class=n>old_men</span> <span class=o>=</span> <span class=n>train_df</span><span class=o>.</span><span class=n>loc</span><span class=p>[(</span><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>60</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Sex&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;male&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 筛选第1到3行，第2到4列的数据</span>
</span></span><span class=line><span class=cl><span class=n>subset</span> <span class=o>=</span> <span class=n>train_df</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=mi>1</span><span class=p>:</span><span class=mi>4</span><span class=p>,</span> <span class=mi>2</span><span class=p>:</span><span class=mi>5</span><span class=p>]</span>
</span></span></code></pre></div><p>注意，这里的条件筛选 <code>(train_df['Age'] > 60) & (train_df['Sex'] == 'male')</code> 正是利用了类似Numpy的布尔索引。</p><p>特征工程（Feature Engineering）</p><p>这是数据科学中最具创造性的部分，即从原始数据中创建新的、对模型更有用的特征。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 创建 FamilySize 特征</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;FamilySize&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;SibSp&#39;</span><span class=p>]</span> <span class=o>+</span> <span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Parch&#39;</span><span class=p>]</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 从 Name 中提取 Title (Mr, Mrs, Miss等)</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Title&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Name&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>name</span><span class=p>:</span> <span class=n>name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;,&#39;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 将 Sex 文本特征转换为数值特征</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Sex_numeric&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Sex&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>map</span><span class=p>({</span><span class=s1>&#39;male&#39;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span> <span class=s1>&#39;female&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 对 Embarked 进行独热编码 (One-Hot Encoding)</span>
</span></span><span class=line><span class=cl><span class=n>embarked_dummies</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>train_df</span><span class=p>[</span><span class=s1>&#39;Embarked&#39;</span><span class=p>],</span> <span class=n>prefix</span><span class=o>=</span><span class=s1>&#39;Embarked&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>train_df</span><span class=p>,</span> <span class=n>embarked_dummies</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><ul><li><code>.apply()</code> 可以将一个函数应用到<code>Series</code>的每个元素上。</li><li><code>.map()</code> 用于基于一个字典进行值的替换。</li><li><code>pd.get_dummies()</code> 是进行独热编码的便捷方法。</li></ul><h3 id=225-数据聚合groupby>2.2.5 数据聚合：<code>groupby</code></h3><p><code>groupby</code> 操作是数据分析的核心，它实现了“分割-应用-合并”（Split-Apply-Combine）的模式。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 按性别计算生还率</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_df</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s1>&#39;Sex&#39;</span><span class=p>)[</span><span class=s1>&#39;Survived&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 按船票等级和性别计算生还率</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_df</span><span class=o>.</span><span class=n>groupby</span><span class=p>([</span><span class=s1>&#39;Pclass&#39;</span><span class=p>,</span> <span class=s1>&#39;Sex&#39;</span><span class=p>])[</span><span class=s1>&#39;Survived&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用 agg 进行更复杂的聚合</span>
</span></span><span class=line><span class=cl><span class=n>agg_funcs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;Survived&#39;</span><span class=p>:</span> <span class=s1>&#39;mean&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;Age&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;mean&#39;</span><span class=p>,</span> <span class=s1>&#39;max&#39;</span><span class=p>,</span> <span class=s1>&#39;min&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>train_df</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s1>&#39;Pclass&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>agg</span><span class=p>(</span><span class=n>agg_funcs</span><span class=p>))</span>
</span></span></code></pre></div><p>通过<code>groupby</code>，我们能快速地验证假设，例如“女性的生还率是否高于男性？”、“头等舱的生还率是否最高？”。</p><h2 id=23-matplotlib--seaborn数据故事的可视化表达>2.3 Matplotlib & Seaborn：数据故事的可视化表达</h2><p>数字是抽象的，而图形是直观的。可视化是探索性数据分析（EDA）的灵魂。</p><p>Matplotlib：是Python可视化的基础库，功能强大，定制性极高，但API有时略显复杂。</p><p>Seaborn：基于Matplotlib，提供了更高级的API，专注于统计图形，能用更少的代码绘制出更美观的图表。通常，我们会将两者结合使用。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置绘图风格</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>set_style</span><span class=p>(</span><span class=s1>&#39;whitegrid&#39;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=231-单变量分析理解数据分布>2.3.1 单变量分析：理解数据分布</h3><p>类别变量：计数图 (<code>countplot</code>)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>countplot</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=s1>&#39;Survived&#39;</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>train_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;生还人数分布 (0 = No, 1 = Yes)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>countplot</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=s1>&#39;Pclass&#39;</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s1>&#39;Survived&#39;</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>train_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;不同船票等级的生还情况&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p>第一张图告诉我们总体生还情况，第二张图则通过<code>hue</code>参数，清晰地展示了船票等级与生还之间的强烈关系：等级越高，生还比例越大。</p><p>连续变量：直方图 (<code>histplot</code>) 和核密度估计图 (<code>kdeplot</code>)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>histplot</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>train_df</span><span class=p>,</span> <span class=n>x</span><span class=o>=</span><span class=s1>&#39;Age&#39;</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s1>&#39;Survived&#39;</span><span class=p>,</span> <span class=n>kde</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;不同年龄的生还情况分布&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p>这张图信息量巨大：我们可以看到儿童（Age &lt; 10）的生还率非常高，而年轻人（Age 18-30）的死亡率较高。</p><h3 id=232-双变量多变量分析探索关系>2.3.2 双变量/多变量分析：探索关系</h3><p>散点图 (<code>scatterplot</code>)：连续 vs 连续</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 泰坦尼克数据集中没有两个很好的连续变量，这里仅作演示</span>
</span></span><span class=line><span class=cl><span class=c1># sns.scatterplot(x=&#39;Age&#39;, y=&#39;Fare&#39;, hue=&#39;Survived&#39;, data=train_df)</span>
</span></span></code></pre></div><p>箱形图 (<code>boxplot</code>)：类别 vs 连续</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>boxplot</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=s1>&#39;Pclass&#39;</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=s1>&#39;Age&#39;</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>train_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;不同船票等级乘客的年龄分布&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p>箱形图清晰地显示了头等舱乘客的平均年龄最高，且年龄分布更广。</p><p>热力图 (<code>heatmap</code>)：展示相关性矩阵</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 只选择数值列计算相关性</span>
</span></span><span class=line><span class=cl><span class=n>numeric_cols</span> <span class=o>=</span> <span class=n>train_df</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>corr_matrix</span> <span class=o>=</span> <span class=n>numeric_cols</span><span class=o>.</span><span class=n>corr</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>corr_matrix</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;coolwarm&#39;</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;.2f&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;特征相关性热力图&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p>热力图帮助我们快速识别特征之间的线性关系。例如，<code>Pclass</code> 和 <code>Fare</code> 之间有很强的负相关，这符合常识。</p><p>通过这一系列的可视化探索，我们对数据的理解已经非常深入，这为后续的模型构建打下了坚实的基础。</p><h2 id=24-scikit-learn传统机器学习算法的快速实现与评估>2.4 Scikit-learn：传统机器学习算法的快速实现与评估</h2><p>Scikit-learn 是将我们从数据分析带入机器学习建模阶段的桥梁。它的设计哲学是统一和简洁。</p><h3 id=241-scikit-learn的核心api设计>2.4.1 Scikit-learn的核心API设计</h3><p>Scikit-learn中的对象都遵循一致的接口：</p><p>Estimator（估计器）：任何可以从数据中学习的对象。</p><p><code>estimator.fit(X, y)</code>：用于训练模型。<code>X</code>是特征数据，<code>y</code>是标签。</p><p>Transformer（转换器）：一种特殊的Estimator，用于数据转换。</p><p><code>transformer.transform(X)</code>：转换数据。</p><p><code>transformer.fit_transform(X, y)</code>：先学习参数再转换，更高效。例如 <code>StandardScaler</code>。</p><p>Model（模型）：用于进行预测的Estimator。</p><p><code>model.predict(X)</code>：进行预测。</p><p><code>model.predict_proba(X)</code>：预测概率（分类模型）。</p><p><code>model.score(X, y)</code>：评估模型性能。</p><h3 id=242-数据准备为模型构建输入>2.4.2 数据准备：为模型构建输入</h3><p>模型不能直接处理原始的DataFrame，我们需要将其转换为纯数值的Numpy数组。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 删除不再需要的、非数值的列</span>
</span></span><span class=line><span class=cl><span class=n>train_df_final</span> <span class=o>=</span> <span class=n>train_df</span><span class=o>.</span><span class=n>drop</span><span class=p>([</span><span class=s1>&#39;PassengerId&#39;</span><span class=p>,</span> <span class=s1>&#39;Name&#39;</span><span class=p>,</span> <span class=s1>&#39;Sex&#39;</span><span class=p>,</span> <span class=s1>&#39;Ticket&#39;</span><span class=p>,</span> <span class=s1>&#39;Embarked&#39;</span><span class=p>,</span> <span class=s1>&#39;Title&#39;</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 确保测试集也经过了完全相同的处理步骤</span>
</span></span><span class=line><span class=cl><span class=c1># ... (此处省略对test_df的完整处理代码，但实际项目中至关重要)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义特征 X 和目标 y</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>train_df_final</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s1>&#39;Survived&#39;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>train_df_final</span><span class=p>[</span><span class=s1>&#39;Survived&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 划分训练集和验证集</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_val</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_val</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span></code></pre></div><p><code>train_test_split</code> 是一个至关重要的函数，它帮助我们将数据划分为训练集和验证集，以评估模型的泛化能力。<code>random_state</code> 保证了每次划分的结果都一样，便于复现。</p><h3 id=243-模型训练与评估>2.4.3 模型训练与评估</h3><p>让我们尝试几个经典的分类模型。</p><p>逻辑回归（Logistic Regression）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>LogisticRegression</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>classification_report</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 初始化模型</span>
</span></span><span class=line><span class=cl><span class=n>log_reg</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 训练模型</span>
</span></span><span class=line><span class=cl><span class=n>log_reg</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 在验证集上进行预测</span>
</span></span><span class=line><span class=cl><span class=n>y_pred_log_reg</span> <span class=o>=</span> <span class=n>log_reg</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_val</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 评估模型</span>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_val</span><span class=p>,</span> <span class=n>y_pred_log_reg</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;逻辑回归验证集准确率: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>分类报告:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_val</span><span class=p>,</span> <span class=n>y_pred_log_reg</span><span class=p>))</span>
</span></span></code></pre></div><p>随机森林（Random Forest）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 初始化模型</span>
</span></span><span class=line><span class=cl><span class=n>rf_clf</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>n_estimators</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 训练模型</span>
</span></span><span class=line><span class=cl><span class=n>rf_clf</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 预测</span>
</span></span><span class=line><span class=cl><span class=n>y_pred_rf</span> <span class=o>=</span> <span class=n>rf_clf</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_val</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 评估</span>
</span></span><span class=line><span class=cl><span class=n>accuracy_rf</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_val</span><span class=p>,</span> <span class=n>y_pred_rf</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;随机森林验证集准确率: </span><span class=si>{</span><span class=n>accuracy_rf</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>随机森林通常比逻辑回归表现更好，因为它是一种更强大的集成模型。</p><h3 id=244-模型优化交叉验证与网格搜索>2.4.4 模型优化：交叉验证与网格搜索</h3><p>一个好的模型不仅要效果好，还要参数调整得当。</p><p>交叉验证（Cross-Validation）：比单次划分验证集更稳健的评估方法。它将训练集分成K份，轮流用K-1份训练，1份验证，最后取平均分。</p><p>网格搜索（Grid Search）：自动化地在给定的参数网格中，通过交叉验证寻找最佳参数组合。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>GridSearchCV</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义参数网格</span>
</span></span><span class=line><span class=cl><span class=n>param_grid</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;n_estimators&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>100</span><span class=p>,</span> <span class=mi>200</span><span class=p>,</span> <span class=mi>300</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 初始化GridSearchCV</span>
</span></span><span class=line><span class=cl><span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>estimator</span><span class=o>=</span><span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=c1># 5折交叉验证</span>
</span></span><span class=line><span class=cl>    <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span> <span class=c1># 使用所有CPU核心</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在整个训练集上进行搜索 (X, y)</span>
</span></span><span class=line><span class=cl><span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;最佳参数: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;最佳交叉验证准确率: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>通过网格搜索，我们可以找到一组最优的超参数，从而进一步提升模型性能。</p><h2 id=25-实战项目总结kaggle竞赛数据全流程分析与建模>2.5 实战项目总结：Kaggle竞赛数据全流程分析与建模</h2><p>回顾我们本章的旅程，我们完成了一次端到端的数据科学项目，这正是工业界AI项目的一个微缩模型。</p><p>流程回顾：</p><ol><li>问题定义：预测泰坦尼克号乘客的生还情况（一个二分类问题）。</li><li>数据获取：使用 <code>Pandas</code> 的 <code>read_csv</code> 加载数据。</li><li>探索性数据分析（EDA） & 数据清洗：<ol><li>使用 <code>.info()</code>, <code>.describe()</code>, <code>.isnull().sum()</code> 快速了解数据概况。</li><li>使用 <code>Matplotlib</code> 和 <code>Seaborn</code> 进行了深入的可视化分析，发现了年龄、性别、船票等级等关键因素与生还的强相关性。</li><li>基于分析结果，对缺失值进行了合理的填充（中位数、众数），并删除了无用列。</li></ol></li><li>特征工程：<ol><li>创建了 <code>FamilySize</code>, <code>Title</code> 等新特征。</li><li>将 <code>Sex</code>, <code>Embarked</code> 等类别特征转换为模型可以理解的数值格式（数值映射、独热编码）。</li></ol></li><li>模型构建与训练：<ol><li>使用 <code>Scikit-learn</code> 的 <code>train_test_split</code> 划分数据集。</li><li>遵循 <code>fit</code>/<code>predict</code> 的统一API，快速实现了逻辑回归和随机森林两个基线模型。</li></ol></li><li>模型评估与优化：<ol><li>使用 <code>accuracy_score</code> 和 <code>classification_report</code> 评估了模型在验证集上的性能。</li><li>学习了使用 <code>GridSearchCV</code> 进行超参数调优，以寻找更优的模型配置。</li></ol></li></ol><p>最终交付：</p><p>项目的最后一步，通常是用找到的最佳模型（<code>grid_search.best_estimator_</code>）在完整的训练数据上重新训练，然后对官方提供的 <code>test.csv</code> 进行预测，生成提交文件。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用最佳模型对测试集进行预测</span>
</span></span><span class=line><span class=cl><span class=n>best_rf</span> <span class=o>=</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_estimator_</span>
</span></span><span class=line><span class=cl><span class=c1># ... (对 test_df 进行与 train_df 完全相同的预处理) ...</span>
</span></span><span class=line><span class=cl><span class=n>test_predictions</span> <span class=o>=</span> <span class=n>best_rf</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_final</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建提交文件</span>
</span></span><span class=line><span class=cl><span class=n>submission</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;PassengerId&#39;</span><span class=p>:</span> <span class=n>test_df</span><span class=p>[</span><span class=s1>&#39;PassengerId&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;Survived&#39;</span><span class=p>:</span> <span class=n>test_predictions</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=n>submission</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=s1>&#39;submission.csv&#39;</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=本章小结>本章小结</h2><p>在本章中，我们不仅学习了Numpy、Pandas、Matplotlib和Scikit-learn这四个库的API，更重要的是，我们通过一个真实的项目，将它们串联成了一套行之有效的工作流。</p><p>你现在应该深刻地理解到：</p><p>向量化思维是提升数值计算性能的关键。</p><p>数据清洗和特征工程是决定模型性能上限的核心步骤，它需要你结合业务理解和数据洞察。</p><p>可视化不是可有可无的点缀，而是驱动数据分析和假设验证的引擎。</p><p>Scikit-learn提供了一套强大而简洁的工具，能让你快速地将想法转化为可评估的模型。</p><p>这套数据科学工具链，是你作为AI工程师的“标准装备”。熟练掌握它们，你才能在面对任何数据时都胸有成竹，才能为后续更复杂的深度学习和LLM项目打下最坚实的地基。在下一章，我们将开始构建AI服务的后端基石，学习如何将我们训练好的模型，封装成一个可以对外提供服务的API。</p></div><div class=post_footer><div class=meta><div class=info><span class="field tags"><i class=ri-stack-line></i>
<a href=https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/>书稿</a></span></div></div></div></div><div class=doc_comments></div></div></div></div><a id=back_to_top href=# class=back_to_top><i class=ri-arrow-up-s-line></i></a><footer class=footer><div class=powered_by><a href=https://varkai.com>Designed by VarKai, </a><a href=http://www.gohugo.io/>Proudly published with Hugo,</a></div><div class=footer_slogan><span>法不净空，觉无性也。</span></div><div class=powered_by style=margin-top:10px;font-size:14px><a href=https://zhurongshuo.com/>Copyright © 2010-2025 祝融说 zhurongshuo.com All Rights Reserved.</a></div></footer><script defer src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><link href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.css rel=stylesheet integrity="sha256-7qiTu3a8qjjWtcX9w+f2ulVUZSUdCZFEK62eRlmLmCE=" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script defer src=https://zhurongshuo.com/js/zozo.js></script><script type=text/javascript async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-KKJ5ZEG1NB"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KKJ5ZEG1NB")</script></body></html>