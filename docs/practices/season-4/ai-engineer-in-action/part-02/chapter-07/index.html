<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=google-site-verification content="8_xpI-TS3tNV8UPug-Q6Ef3BhKTcy0WOG7dEdAcm2zk"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="祝融"><link rel=dns-prefetch href=//cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=preconnect href=https://www.googletagmanager.com crossorigin><link rel=canonical href=https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-07/><title>祝融说。 第七章：大语言模型时代：LLM技术全景解析</title><meta property="og:title" content="第七章：大语言模型时代：LLM技术全景解析"><meta property="og:url" content="https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-07/"><meta property="og:site_name" content="祝融说。"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:published_time" content="2025-12-09T00:00:00+08:00"><meta property="article:modified_time" content="2025-12-09T00:00:00+08:00"><meta property="article:tag" content="书稿"><meta name=description content="在上一章中，我们已经深入剖析了Transformer架构——那座支撑起整个现代NLP乃至AI大厦的宏伟基石。我们理解了自注意力机制如何让模型并行地捕捉长距离依赖，也亲手构建了一个简化版的Transformer。现在，我们将站在Transformer这座巨人的肩膀上，去眺望一片更加波澜壮阔的风景——大语言模型（Large Language Models, LLM）的时代。
"><meta property="og:description" content="在上一章中，我们已经深入剖析了Transformer架构——那座支撑起整个现代NLP乃至AI大厦的宏伟基石。我们理解了自注意力机制如何让模型并行地捕捉长距离依赖，也亲手构建了一个简化版的Transformer。现在，我们将站在Transformer这座巨人的肩膀上，去眺望一片更加波澜壮阔的风景——大语言模型（Large Language Models, LLM）的时代。
"><meta property="og:image" content="https://zhurongshuo.com/images/favicon.ico"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="第七章：大语言模型时代：LLM技术全景解析"><meta name=twitter:description content="在上一章中，我们已经深入剖析了Transformer架构——那座支撑起整个现代NLP乃至AI大厦的宏伟基石。我们理解了自注意力机制如何让模型并行地捕捉长距离依赖，也亲手构建了一个简化版的Transformer。现在，我们将站在Transformer这座巨人的肩膀上，去眺望一片更加波澜壮阔的风景——大语言模型（Large Language Models, LLM）的时代。
"><meta name=twitter:image content="https://zhurongshuo.com/images/favicon.ico"><meta name=keywords content="AI工程师实战：从Python基础到LLM应用与性能优化,第七章：大语言模型时代：LLM技术全景解析"><link rel="shortcut icon" href=https://zhurongshuo.com/images/favicon.ico><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/animate-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/zozo.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/remixicon-custom.css><link rel=stylesheet type=text/css media=screen href=https://zhurongshuo.com/css/highlight.css><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","headline":"第七章：大语言模型时代：LLM技术全景解析","description":"在上一章中，我们已经深入剖析了Transformer架构——那座支撑起整个现代NLP乃至AI大厦的宏伟基石。我们理解了自注意力机制如何让模型并行地捕捉长距离依赖，也亲手构建了一个简化版的Transformer。现在，我们将站在Transformer这座巨人的肩膀上，去眺望一片更加波澜壮阔的风景——大语言模型（Large Language Models, LLM）的时代。\n","datePublished":"2025-12-09T00:00:00\u002b08:00","dateModified":"2025-12-09T00:00:00\u002b08:00","author":{"@type":"Person","name":"祝融"},"publisher":{"@type":"Organization","name":"祝融说。","logo":{"@type":"ImageObject","url":"https:\/\/zhurongshuo.com\/images\/favicon.ico"}},"image":"https:\/\/zhurongshuo.com\/images\/favicon.ico","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zhurongshuo.com\/practices\/season-4\/ai-engineer-in-action\/part-02\/chapter-07\/"},"keywords":"书稿"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"首页","item":"https:\/\/zhurongshuo.com\/"},{"@type":"ListItem","position":2,"name":"practices","item":"https:\/\/zhurongshuo.com\/practices/"},{"@type":"ListItem","position":3,"name":"第七章：大语言模型时代：LLM技术全景解析","item":"https:\/\/zhurongshuo.com\/practices\/season-4\/ai-engineer-in-action\/part-02\/chapter-07\/"}]}</script></head><body><div class="main animate__animated animate__fadeInDown"><div class="nav_container animated fadeInDown"><div class=site_nav id=site_nav><ul><li><a href=https://zhurongshuo.com/>首页</a></li><li><a href=https://zhurongshuo.com/start/>开始</a></li><li><a href=https://zhurongshuo.com/advanced/>进阶rc</a></li><li><a href=https://zhurongshuo.com/posts/>归档</a></li><li><a href=https://zhurongshuo.com/tags/>标签</a></li><li><a href=https://zhurongshuo.com/about/>关于</a></li></ul></div><div class=menu_icon><a id=menu_icon><i class=ri-menu-line></i></a></div></div><div class="header animated fadeInDown"><div class=site_title_container><div class=site_title><h1><a href=https://zhurongshuo.com/><span class=web-font>祝融说。</span></a></h1></div><div class=description><p class=sub_title>法不净空，觉无性也。</p><div class=my_socials><a href=https://zhurongshuo.com/books/ title=book-open><i class=ri-book-open-line></i></a>
<a href=https://zhurongshuo.com/practices/ title=trophy><i class=ri-trophy-line></i></a>
<a href=https://zhurongshuo.com/gallery/ title=gallery><i class=ri-gallery-line></i></a>
<a href=https://zhurongshuo.com/about/ title=game><i class=ri-game-line></i></a>
<a href type=application/rss+xml title=rss target=_blank><i class=ri-rss-fill></i></a></div></div></div></div><div class=content><div class=post_page><div class="post animate__animated animate__fadeInDown"><div class="post_title post_detail_title"><h2><a href=https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-07/>第七章：大语言模型时代：LLM技术全景解析</a></h2><span class=date>2025.12.09</span></div><div class="post_content markdown"><p>在上一章中，我们已经深入剖析了Transformer架构——那座支撑起整个现代NLP乃至AI大厦的宏伟基石。我们理解了自注意力机制如何让模型并行地捕捉长距离依赖，也亲手构建了一个简化版的Transformer。现在，我们将站在Transformer这座巨人的肩膀上，去眺望一片更加波澜壮阔的风景——大语言模型（Large Language Models, LLM）的时代。</p><p>2018年以来，AI领域见证了一场由“规模定律”（Scaling Law）驱动的深刻变革。研究者们发现，当Transformer模型的参数量、训练数据量和计算量跨越某个临界点后，模型的能力会发生“相变”，展现出惊人的涌现能力（Emergent Abilities）。这些能力，如上下文学习（In-context Learning）、零样本/少样本推理（Zero/Few-shot Reasoning）、思维链（Chain-of-Thought）等，是小模型上从未出现过的。模型不再仅仅是任务的执行者，它开始表现出某种程度的“通用智能”。</p><p>从BERT的“完形填空”，到GPT-3的“文本续写”，再到ChatGPT和GPT-4的“对话式AI”，LLM的每一次迭代都在重新定义人机交互的边界。它们正在从根本上改变我们创造内容、编写代码、获取信息乃至进行科学研究的方式。一个全新的AI应用范式——生成式AI（Generative AI）——已经降临。</p><p>作为新时代的AI工程师，我们不能再仅仅满足于训练一个特定任务的模型。我们必须学会如何理解、驾驭和利用这些强大的“基础模型”（Foundation Models）。本章，就是你进入LLM世界的第一份“全景地图”。我们将一起探索：</p><ul><li>LLM的演进之路：我们将回顾从BERT到GPT系列这条波澜壮阔的技术演进路线。你将理解Encoder-only、Decoder-only和Encoder-Decoder这三大架构流派的差异，以及它们各自的适用场景。</li><li>主流开源LLM选型指南：在闭源模型（如GPT-4）之外，一个繁荣的开源LLM生态正在崛起。我们将对Llama、Gemma、Qwen等主流开源模型进行梳理和对比，为你提供在实际项目中进行技术选型时的决策依据。</li><li>Prompt Engineering：与LLM交互，就像与一个知识渊博但需要精确指令的“外星智慧”对话。我们将系统学习“提示工程”这门新兴的艺术，掌握如何通过精心设计的Prompt，来最大限度地激发和引导LLM的潜能。</li><li>LLM的局限性与挑战：能力越大，责任越大。我们也将清醒地认识到LLM并非万能的。我们将深入探讨其固有的“幻觉”（Hallucination）、偏见（Bias）和安全（Safety）等问题，并了解当前业界应对这些挑战的思路与方法。</li></ul><p>本章将为你构建一个关于LLM的宏观认知框架。它将帮助你理解“现在我们身在何处”，并为你指明“未来将往何方”。掌握了这份地图，你才能在接下来的章节中，更有方向地去学习如何对LLM进行微调、构建RAG和Agent等高级应用。现在，让我们一起，踏入这个由代码、数据和巨大算力共同铸就的智能新纪元。</p><h2 id=71-llm的演进之路从bert到gpt系列>7.1 LLM的演进之路：从BERT到GPT系列</h2><p>Transformer架构的诞生，为构建更大、更强的语言模型铺平了道路。此后的发展，主要沿着三条并行但又相互影响的技术路线展开，它们分别对应了Transformer的三种架构变体：Encoder-only, Decoder-only, 和 Encoder-Decoder。</p><h3 id=711-预训练范式的确立从elmo到bert>7.1.1 预训练范式的确立：从ELMo到BERT</h3><p>在LLM出现之前，NLP任务通常需要为每个任务单独设计模型并从头训练。2018年，一系列工作的出现，确立了“预训练-微调（Pre-training, Fine-tuning）”这一新范式，彻底改变了NLP的游戏规则。</p><p>ELMo (Embeddings from Language Models)：它使用双向LSTM在大量文本上进行预训练，但其核心贡献是提出了“上下文相关的词嵌入”。同一个词在不同句子中的嵌入是不同的，这解决了传统词向量（如Word2Vec）的“一词多义”问题。</p><p>BERT (Bidirectional Encoder Representations from Transformers)：BERT是这场变革的引爆点。它只使用了Transformer的Encoder部分。</p><p>架构：Encoder-only。</p><p>预训练任务：</p><ol><li>掩码语言模型（Masked Language Model, MLM）：这是一种“完形填空”游戏。在输入句子中，随机地将15%的词替换为一个特殊的<code>[MASK]</code>标记，然后让模型去预测这些被掩盖的原始词语。通过这个任务，模型被迫去学习深刻的双向上下文表示。</li><li>下一句预测（Next Sentence Prediction, NSP）：给定两个句子A和B，让模型判断B是否是A的下一句。这个任务旨在让模型学习句子间的关系。</li></ol><p>核心优势：由于MLM任务的存在，BERT在预训练时能够同时看到一个词的左侧和右侧上下文，从而获得了比以往任何模型都更深刻的语义理解能力。</p><p>适用场景：BERT及其变体（如RoBERTa, ALBERT）非常擅长理解型任务（NLU），如文本分类、情感分析、命名实体识别、问答（抽取式）等。它们就像一个强大的“特征提取器”，为下游任务提供高质量的句子或词语表示。</p><h3 id=712-生成能力的崛起gpt系列的decoder-only之路>7.1.2 生成能力的崛起：GPT系列的Decoder-only之路</h3><p>与BERT并行发展的，是OpenAI主导的GPT（Generative Pre-trained Transformer）系列。它们选择了另一条技术路线。</p><p>架构：Decoder-only。GPT系列只使用了Transformer的Decoder部分（但去掉了Encoder-Decoder交叉注意力层）。</p><p>预训练任务：标准的语言模型任务（Standard Language Model），即根据一个词前面所有的词，来预测这个词。这是一种“文本续写”游戏。例如，对于句子“今天天气很”，模型需要预测下一个词是“好”。</p><p>核心特点：</p><ul><li>自回归（Auto-regressive）：GPT的生成过程是一个词一个词地进行的，当前生成的词会作为下一步预测的输入。</li><li>单向上下文：在预测第 <code>t</code> 个词时，模型只能看到前 <code>t-1</code> 个词的信息，看不到未来的信息。这是通过在自注意力层中使用“掩码”（Masking）来实现的。</li></ul><p>GPT系列的演进：</p><ul><li>GPT-1 (2018)：首次证明了在多样化的无标注文本上进行生成式预训练，然后对下游任务进行微调的有效性。</li><li>GPT-2 (2019)：大幅增加了模型规模（最大15亿参数），并使用了更大、更多样化的数据集。GPT-2展现出了惊人的零样本（Zero-shot）生成能力，能够在没有明确微调的情况下，完成一些简单的任务，如文章摘要、机器翻译等。这让研究界首次窥见了“规模定律”的威力。</li><li>GPT-3 (2020)：一次巨大的飞跃。参数量达到了惊人的1750亿。GPT-3的“涌现能力”震惊了世界，特别是其强大的上下文学习（In-context Learning, ICL）能力。你只需要在Prompt中给出几个任务的示例（Few-shot），模型就能“领会”你的意图，并完成新的、类似的任务，而无需更新任何模型权重。</li><li>InstructGPT / ChatGPT (2022)：在GPT-3的基础上，引入了基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF）技术。通过让人类对模型的不同输出进行排序，训练一个奖励模型，再用强化学习来优化语言模型，使其输出更符合人类的偏好、指令和价值观。这极大地提升了模型的对齐（Alignment）能力，使其更“有用”、更“无害”，从而催生了ChatGPT这一现象级产品。</li><li>GPT-4 (2023)：更进一步的规模扩展，并引入了多模态（Multi-modality）能力，能够同时处理文本和图像输入。</li></ul><p>Decoder-only架构的适用场景：由于其强大的文本生成能力，这类模型非常适合生成型任务（NLG），如对话系统、内容创作、代码生成、摘要、翻译等。所有我们今天熟知的聊天机器人，几乎都基于此架构。</p><h3 id=713-两全其美t5与bart的encoder-decoder架构>7.1.3 两全其美：T5与BART的Encoder-Decoder架构</h3><p>第三条路线试图结合前两者的优点。</p><p>架构：完整的Encoder-Decoder。</p><p>代表模型：T5 (Text-to-Text Transfer Transformer), BART。</p><p>核心思想：将所有NLP任务都统一为“文本到文本”（Text-to-Text）的格式。例如，对于翻译任务，输入是<code>"translate English to German: That is good."</code>，模型应输出<code>"Das ist gut."</code>。对于情感分类，输入是<code>"sst2 sentence: This movie is great!"</code>，模型应输出<code>"positive"</code>。对于摘要任务，输入是<code>"summarize: {long article text}"</code>，模型应输出摘要文本。</p><p>预训练任务：通常采用一种“去噪（Denoising）”的目标。例如，T5会随机地破坏输入文本（如删除、替换一些片段），然后让模型去恢复原始的、未被破坏的文本。</p><p>适用场景：Encoder-Decoder架构在需要对源文本有深刻理解，同时又需要进行复杂生成的任务上表现出色，如摘要、翻译、问答（生成式）等。</p><p>三大架构流派总结：</p><table><thead><tr><th style=text-align:left>架构类型</th><th style=text-align:left>代表模型</th><th style=text-align:left>预训练任务</th><th style=text-align:left>核心特点</th><th style=text-align:left>擅长任务</th></tr></thead><tbody><tr><td style=text-align:left><strong>Encoder-only</strong></td><td style=text-align:left>BERT, RoBERTa</td><td style=text-align:left>掩码语言模型 (MLM)</td><td style=text-align:left>双向上下文，强大的语义理解</td><td style=text-align:left>理解型 (NLU)：分类、NER、情感分析</td></tr><tr><td style=text-align:left><strong>Decoder-only</strong></td><td style=text-align:left>GPT系列, Llama</td><td style=text-align:left>标准语言模型 (CLM)</td><td style=text-align:left>单向上下文，强大的文本生成</td><td style=text-align:left>生成型 (NLG)：对话、创作、代码生成</td></tr><tr><td style=text-align:left><strong>Encoder-Decoder</strong></td><td style=text-align:left>T5, BART</td><td style=text-align:left>文本到文本去噪</td><td style=text-align:left>结合两者，适合Seq2Seq</td><td style=text-align:left>摘要、翻译、生成式问答</td></tr></tbody></table><h2 id=72-主流开源llm选型指南llama-gemma-qwen等>7.2 主流开源LLM选型指南（Llama, Gemma, Qwen等）</h2><p>虽然像GPT-4这样的闭源模型性能强大，但它们是“黑箱”，调用成本高，且无法进行深度定制。近年来，一个繁荣的开源LLM生态正在蓬勃发展，为企业和开发者提供了更多选择。</p><p>在选择一个开源LLM时，你需要考虑以下几个关键因素：</p><ol><li>模型规模（参数量）：如7B, 13B, 70B（B代表Billion，十亿）。规模越大，通常能力越强，但对硬件（特别是GPU显存）的要求也越高。</li><li>上下文长度（Context Length）：模型能处理的输入文本的最大长度（以token计）。对于需要处理长文档的任务，这个参数至关重要。</li><li>许可证（License）：决定了你是否可以将其用于商业用途。例如，Llama 2的许可证允许商用，但有一些限制。</li><li>多语言/多模态能力：模型是否支持中文或其他语言？是否能处理图像输入？</li><li>社区生态与支持：是否有活跃的社区、丰富的微调脚本、量化版本等资源？</li></ol><h3 id=721-meta的llama系列开源社区的事实标准>7.2.1 Meta的Llama系列：开源社区的“事实标准”</h3><p>Llama (2023.02)：Meta发布的第一个系列，虽然最初未开放商用，但其高质量和高性能点燃了整个开源社区的热情。</p><p>Llama 2 (2023.07)：开源LLM发展史上的里程碑。</p><ul><li>规模：7B, 13B, 70B。</li><li>特点：相比Llama 1，使用了更大规模（2万亿token）的公开数据集进行训练，上下文长度翻倍至4096。同时发布了经过RLHF对齐的<code>Llama-2-Chat</code>版本，对话能力大幅提升。</li><li>许可证：允许商用，但对月活用户超过7亿的公司有限制。</li><li>生态：拥有最庞大、最活跃的社区。几乎所有新的微调技术、量化方法、推理框架都会第一时间支持Llama 2。它是进行学术研究和商业探索的基准模型。</li></ul><p>Llama 3 (2024.04)：最新的迭代。</p><ul><li>规模：目前发布了8B和70B版本，未来将发布更大的400B+模型。</li><li>特点：使用了高达15万亿token的超大规模数据集进行预训练，并对数据质量进行了极致的筛选。其全新的分词器（Tokenizer）对多语言支持更好。在同等规模下，Llama 3的性能全面超越了Llama 2，甚至其8B模型在某些基准上能与Llama 2 70B相媲美。上下文长度提升至8192。</li><li>选型建议：在硬件允许的情况下，Llama 3是当前开源模型的首选。</li></ul><h3 id=722-google的gemma技术先进的亲民之选>7.2.2 Google的Gemma：技术先进的“亲民”之选</h3><p>Gemma (2024.02)：由Google DeepMind发布，其技术与强大的闭源模型Gemini一脉相承。</p><ul><li>规模：2B, 7B。</li><li>特点：虽然规模不大，但其性能在同级别模型中极具竞争力，7B版本在多个基准上优于Llama 2 7B/13B。它使用了与Gemini相同的分词器和架构。</li><li>许可证：非常宽松，允许商用。</li><li>选型建议：对于资源有限、需要部署在端侧或小型服务器上的场景，Gemma 2B/7B是一个极具性价比的选择。</li></ul><h3 id=723-阿里巴巴的qwen通义千问系列中文领域的佼佼者>7.2.3 阿里巴巴的Qwen（通义千问）系列：中文领域的佼佼者</h3><p>Qwen (2023.08)：阿里巴巴达摩院推出的系列模型。</p><ul><li>规模：从1.8B, 7B, 14B到72B，覆盖范围非常广。</li><li>特点：对中文的支持是其最大优势。在中文的预训练语料上投入巨大，使其在中文的理解、生成、对齐方面表现优异。同时，也发布了支持长上下文（<code>Qwen-7B-Chat-32k</code>）、代码（<code>CodeQwen</code>）和多模态（<code>Qwen-VL</code>）的多种变体。</li><li>许可证：早期版本对商用有限制，但后续版本（如Qwen1.5）已非常开放。</li><li>选型建议：如果你的核心业务场景是面向中文的，Qwen系列是毫无疑问的首选之一。</li></ul><h3 id=724-其他值得关注的模型>7.2.4 其他值得关注的模型</h3><p>Mistral AI系列 (Mistral 7B, Mixtral 8x7B)：由前DeepMind和Meta员工创立的法国公司Mistral AI推出。</p><ul><li>Mistral 7B：以其小巧的体积和超越Llama 2 13B的性能而闻名，效率极高。</li><li>Mixtral 8x7B：一个稀疏混合专家模型（Sparse Mixture-of-Experts, SMoE）。它内部有8个“专家”（都是7B模型），在推理时，每个token只会被路由到其中2个最相关的专家进行处理。这使得它在拥有巨大等效参数量（~47B）的同时，推理成本只与一个12B模型相当，实现了性能和效率的完美结合。</li></ul><p>Yi系列 (零一万物)：由李开复创办的公司推出，以其强大的基础模型能力和长上下文支持而受到关注。</p><p>选型决策树（简化版）：</p><ol><li>主要面向中文？<ul><li>是 -> Qwen系列</li><li>否 -> 继续</li></ul></li><li>需要最强的综合性能，且有足够硬件资源（如A100/H100）？<ul><li>是 -> Llama 3 70B 或 Mixtral 8x7B</li><li>否 -> 继续</li></ul></li><li>硬件资源有限，追求最佳性价比？<ul><li>是 -> Llama 3 8B (综合首选) 或 Gemma 7B (技术新) 或 Mistral 7B (效率高)</li></ul></li><li>需要在端侧或极低资源环境下部署？<ul><li>是 -> Gemma 2B 或 Qwen 1.8B</li></ul></li></ol><h2 id=73-prompt-engineering与大模型高效对话的艺术>7.3 Prompt Engineering：与大模型高效对话的艺术</h2><p>拥有了一个强大的LLM，就像拥有了一个无所不知但有点“书呆子气”的超级大脑。你如何向它提问，将直接决定你得到答案的质量。Prompt Engineering（提示工程）就是研究如何设计和优化Prompt，以更好地引导LLM完成特定任务的一门学问。</p><h3 id=731-prompt的基本构成>7.3.1 Prompt的基本构成</h3><p>一个好的Prompt通常包含以下一个或多个元素：</p><ul><li>角色（Role）：为LLM设定一个身份。<code>"你是一位资深的软件架构师..."</code></li><li>指令（Instruction）：明确地告诉模型要做什么。<code>"请总结以下文章..."</code></li><li>上下文（Context）：提供相关的背景信息。<code>"背景信息：公司正在计划一个电商项目。问题：..."</code></li><li>示例（Examples / Shots）：给出输入/输出的范例，即上下文学习（In-context Learning）。<ul><li>Zero-shot：不给任何示例，直接提问。</li><li>Few-shot：给出少量（通常1-5个）示例。</li></ul></li><li>输出格式（Output Format）：指定你希望的输出形式。<code>"请以JSON格式返回结果，包含'title'和'summary'两个键。"</code></li></ul><h3 id=732-核心原则与技巧>7.3.2 核心原则与技巧</h3><ol><li><p>清晰明确，而非简短：不要害怕写长的Prompt。提供足够的细节和上下文，比含糊的短句效果好得多。</p><ul><li>差: <code>"总结这篇文章。"</code></li><li>好: <code>"请为以下文章撰写一段不超过100字的摘要，主要面向对AI不了解的普通读者，重点突出其核心结论和现实意义。文章：{...}"</code></li></ul></li><li><p>赋予角色：让模型扮演一个专家角色，可以有效地引导其输出的风格和深度。</p><ul><li><code>"你是一位经验丰富的旅行规划师，请为我设计一个为期7天的日本关西家庭游行程，重点考虑有老人和小孩的情况。"</code></li></ul></li><li><p>使用分隔符：使用三重引号<code>"""</code>、XML标签<code>&lt;tag></code>或Markdown的<code>###</code>等清晰的分隔符来区分指令、上下文和输入数据，避免混淆。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>### 指令 ###
</span></span><span class=line><span class=cl>根据以下提供的客户评论，提取产品名称和客户的情感（正面/负面/中性）。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>### 评论 ###
</span></span><span class=line><span class=cl>&#34;&#34;&#34;
</span></span><span class=line><span class=cl>我刚买的SuperPhone Pro，电池续航太棒了！
</span></span><span class=line><span class=cl>&#34;&#34;&#34;
</span></span></code></pre></div></li><li><p>提供示例（Few-shot Learning）：对于复杂的或新颖的任务，提供示例是引导模型最有效的方式之一。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>将句子改写为更正式的商业邮件风格。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>句子：嘿，哥们，那个报告搞定了没？
</span></span><span class=line><span class=cl>改写：您好，请问关于XX项目的报告目前进展如何？
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>句子：老板说下周三之前必须交。
</span></span><span class=line><span class=cl>改写：
</span></span></code></pre></div><p>模型会接着你的格式，输出<code>"根据XX总监的要求，请确保相关报告在下周三（X月X日）前提交。"</code></p></li><li><p>思维链（Chain-of-Thought, CoT）：这是提升LLM在复杂推理任务（如数学题、逻辑题）上性能的革命性技巧。核心是让模型在给出最终答案前，先把解题的步骤一步步地写出来。</p><ul><li>Zero-shot CoT: 只需在你的Prompt末尾加上一句神奇的话：<code>"Let's think step by step."</code> (让我们一步一步地思考)。</li><li>Few-shot CoT: 在你提供的示例中，也包含详细的思考过程。</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>问题：一个杂货店有5个苹果，他们买了2箱苹果，每箱有6个。现在他们有多少个苹果？
</span></span><span class=line><span class=cl>答案：让我们一步一步地思考。
</span></span><span class=line><span class=cl>1. 杂货店最初有5个苹果。
</span></span><span class=line><span class=cl>2. 他们买了2箱苹果，每箱6个，所以他们新买了 2 * 6 = 12 个苹果。
</span></span><span class=line><span class=cl>3. 他们现在总共有 5 + 12 = 17 个苹果。
</span></span><span class=line><span class=cl>所以，最终答案是17。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问题：Roger有5个网球。他买了2罐网球，每罐3个。他现在有多少个网球？
</span></span><span class=line><span class=cl>答案：
</span></span></code></pre></div><p>模型会模仿你的思考过程，从而更准确地解决问题。</p></li><li><p>指定输出格式：为了方便程序解析，强制模型按特定格式（如JSON, XML, Markdown表格）输出。</p><p><code>"请以一个JSON数组的形式返回结果，每个对象包含'name'和'capital'两个字段。"</code></p></li></ol><h3 id=733-迭代与优化>7.3.3 迭代与优化</h3><p>Prompt Engineering不是一蹴而就的，它是一个不断实验和迭代的过程。当效果不佳时，可以尝试：</p><p>分析模型的错误输出，思考是哪里产生了误解。</p><p>增加更明确的指令或约束。</p><p>提供更高质量或更多样化的示例。</p><p>尝试改变问题的措辞或角度。</p><h2 id=74-llm的局限性与挑战幻觉偏见与安全>7.4 LLM的局限性与挑战：幻觉、偏见与安全</h2><p>尽管LLM能力强大，但它们远非完美。作为负责任的AI工程师，我们必须清醒地认识并妥善处理其固有的局限性。</p><h3 id=741-幻觉hallucination>7.4.1 幻觉（Hallucination）</h3><p>定义：幻觉是指LLM生成了看似合理，但实际上是虚假的、与事实不符或与源文本无关的信息。这是LLM最臭名昭著的问题之一。</p><p>原因：</p><ul><li>知识截止：LLM的知识被“冻结”在其训练数据截止的那个时间点。对于之后发生的新事件，它一无所知，但可能会“编造”答案。</li><li>训练目标：LLM的训练目标是预测下一个最有可能的词，而不是“说真话”。如果一个虚假的信息在训练数据中频繁地以一种流畅的方式出现，模型就可能学会生成它。</li><li>源数据错误：训练数据本身就包含大量错误、矛盾和过时的信息。</li></ul><p>应对策略：</p><ul><li>检索增强生成（Retrieval-Augmented Generation, RAG）：这是目前对抗幻觉最有效的方法。在让LLM回答问题前，先从一个可靠的、可更新的知识库（如公司文档、数据库）中检索相关的文本片段，并将这些片段作为上下文注入到Prompt中，要求LLM基于这些提供的信息来回答。我们将在第九章详细学习RAG。</li><li>在Prompt中明确约束：<code>"请仅根据以下提供的上下文回答问题。如果上下文中没有相关信息，请直接回答'我不知道'。"</code></li><li>事实核查：对于生成的关键信息，通过搜索引擎、数据库或其他可靠信源进行交叉验证。</li></ul><h3 id=742-偏见bias>7.4.2 偏见（Bias）</h3><p>定义：LLM在海量的互联网文本上进行训练，这些文本不可避免地反映了人类社会中存在的各种偏见，如性别、种族、地域、职业等刻板印象。模型会学习并放大这些偏见。</p><p>表现：</p><p>当被要求描述“一个程序员”时，可能更倾向于使用男性代词。</p><p>对于来自不同文化背景的提问，可能给出带有文化偏见的回答。</p><p>生成有害的、歧视性的内容。</p><p>应对策略：</p><ul><li>数据清洗与去偏：在预训练阶段，对数据进行仔细的筛选和处理，以减少偏见内容。这是一个极其困难的挑战。</li><li>指令微调与RLHF：通过在指令微调和RLHF阶段，使用由多样化背景的人类标注员创建的、旨在对抗偏见的数据，来“校正”模型的行为。</li><li>在Prompt中进行引导：<code>"请以一种中立、无偏见的口吻来描述..."</code></li><li>输出审查：在将模型输出展示给用户前，通过一个内容审查模型或规则系统来过滤掉可能包含偏见和有害的内容。</li></ul><h3 id=743-安全safety>7.4.3 安全（Safety）</h3><p>定义：这涵盖了LLM被用于恶意目的的风险，以及其自身可能产生的有害输出。</p><p>恶意使用：生成钓鱼邮件、散播虚假信息、编写恶意代码等。</p><p>有害输出：生成暴力、色情、仇恨言论，或提供危险的指导（如制造武器）。</p><p>越狱（Jailbreaking）：用户通过精心设计的“越狱Prompt”，绕过模型的安全限制，诱使其生成本不该生成的内容。</p><p>应对策略：</p><ul><li>红队测试（Red Teaming）：在模型发布前，由专门的团队扮演攻击者，尝试用各种方法来“攻击”模型，找出其安全漏洞。</li><li>多层安全过滤：在输入端和输出端都设置安全过滤器。</li><li>持续的RLHF：将发现的“越狱”案例和有害输出作为新的训练数据，通过RLHF持续地加固模型的安全护栏。</li><li>使用限制与监控：通过API使用策略，限制高风险应用，并对可疑的调用模式进行监控。</li></ul><h2 id=本章小结>本章小结</h2><p>在本章中，我们绘制了一幅宏大的大语言模型全景图，正式踏入了LLM时代。</p><p>我们回顾了从BERT到GPT系列的壮阔演进史，理解了Encoder-only、Decoder-only和Encoder-Decoder这三大架构流派的设计哲学与适用场景，为我们理解所有现代LLM的“出身”提供了谱系。</p><p>我们审视了百花齐放的开源LLM生态，学习了如何在Llama、Gemma、Qwen等主流模型中，根据项目需求和资源限制，做出明智的技术选型。</p><p>我们深入学习了与LLM高效交互的艺术——Prompt Engineering。从基本构成到高级技巧如思维链（CoT），我们掌握了如何通过精心设计的提示，将LLM的潜力发挥到极致。</p><p>最后，我们以一种批判性和负责任的眼光，正视了LLM面临的严峻挑战：幻觉、偏见与安全。我们理解了这些问题的根源，并探讨了当前业界应对这些挑战的核心策略。</p><p>完成本章后，你对LLM的认知已经从零散的概念，构建成了一个系统性的框架。你不再是LLM的“门外汉”，而是一个能够理解其历史、现状与未来的“圈内人”。这份宏观的认知，将是你后续进行LLM微调、RAG和Agent开发等高级实战的坚实思想基础。在下一章，我们将从“使用”LLM，迈向“定制”LLM，学习如何通过微调技术，让通用的LLM成为解决你特定领域问题的专家。</p></div><div class=post_footer><div class=meta><div class=info><span class="field tags"><i class=ri-stack-line></i>
<a href=https://zhurongshuo.com/tags/%E4%B9%A6%E7%A8%BF/>书稿</a></span></div></div></div></div><div class=doc_comments></div></div></div></div><a id=back_to_top href=# class=back_to_top><i class=ri-arrow-up-s-line></i></a><footer class=footer><div class=powered_by><a href=https://varkai.com>Designed by VarKai, </a><a href=http://www.gohugo.io/>Proudly published with Hugo,</a></div><div class=footer_slogan><span>法不净空，觉无性也。</span></div><div class=powered_by style=margin-top:10px;font-size:14px><a href=https://zhurongshuo.com/>Copyright © 2010-2025 祝融说 zhurongshuo.com All Rights Reserved.</a></div></footer><script defer src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><link href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.css rel=stylesheet integrity="sha256-7qiTu3a8qjjWtcX9w+f2ulVUZSUdCZFEK62eRlmLmCE=" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script defer src=https://zhurongshuo.com/js/zozo.js></script><script type=text/javascript async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-KKJ5ZEG1NB"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KKJ5ZEG1NB")</script></body></html>