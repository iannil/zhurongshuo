<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>祝融说。</title><link>https://zhurongshuo.com/</link><description>Recent content on 祝融说。</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 09 Dec 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://zhurongshuo.com/index.xml" rel="self" type="application/rss+xml"/><item><title>第八章：定制你的专属大模型：高效微调技术实战</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-08/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-08/</guid><description>&lt;p&gt;在上一章中，我们已经领略了大语言模型（LLM）的宏大图景。我们知道，像Llama、Qwen这样的开源LLM，是在海量的通用文本上预训练出来的“通用大脑”，它们知识渊博，能力强大。通过精巧的Prompt Engineering，我们已经可以在许多任务上引导它们给出令人满意的结果。&lt;/p&gt;</description></item><item><title>第二章：数据科学核心工具链实战</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-02/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-02/</guid><description>&lt;p&gt;如果说上一章我们修炼的Python内功是AI工程师的“心法”，那么本章将要锻造的，则是我们手中最锋利的“兵器”——数据科学核心工具链。在人工智能的世界里，数据是驱动一切的燃料。原始数据，如同未经提炼的矿石，驳杂而混乱；而模型的输入，则需要是规整、纯净的“金条”。从矿石到金条的这一过程，便是数据科学的“炼金术”，其核心技艺就蕴藏在Numpy、Pandas、Matplotlib和Scikit-learn这四大神器之中。&lt;/p&gt;</description></item><item><title>第九章：释放LLM的潜能：构建RAG与智能体（Agent）</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-09/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-09/</guid><description>&lt;p&gt;在前面的章节中，我们已经深入探索了大语言模型（LLM）的内部世界。我们学会了如何通过Prompt Engineering引导它，通过高效微调定制它。至此，我们手中的LLM已经像一个知识渊博、训练有素的“超级大脑”。然而，这个大脑在默认状态下，是与世隔绝的。它的知识被“冻结”在训练截止的那一刻，它无法访问最新的信息，也无法与外部工具互动来执行任务。它能“说”，但不能“做”；它能“回忆”，但不能“查询”。&lt;/p&gt;</description></item><item><title>第六章：自然语言处理的核心：从词嵌入到Transformer</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-06/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-06/</guid><description>&lt;p&gt;在上一章中，我们已经掌握了深度学习的基本原理和PyTorch的实战技巧，并成功构建了一个基于LSTM的情感分类器。我们已经能够让机器“处理”语言，但我们离真正“理解”语言还有多远？&lt;/p&gt;
&lt;p&gt;人类语言，是思想的载体，其复杂、微妙与歧义性，是计算机科学领域最艰巨的挑战之一。一个词语的意义，往往取决于其上下文；一个句子的情感，可能隐藏在精巧的语法结构和微妙的语序之中。要让机器理解语言，首先必须解决一个根本问题：如何将离散、符号化的文本，转化为机器能够计算和学习的数学表示？&lt;/p&gt;</description></item><item><title>第七章：大语言模型时代：LLM技术全景解析</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-07/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-07/</guid><description>&lt;p&gt;在上一章中，我们已经深入剖析了Transformer架构——那座支撑起整个现代NLP乃至AI大厦的宏伟基石。我们理解了自注意力机制如何让模型并行地捕捉长距离依赖，也亲手构建了一个简化版的Transformer。现在，我们将站在Transformer这座巨人的肩膀上，去眺望一片更加波澜壮阔的风景——大语言模型（Large Language Models, LLM）的时代。&lt;/p&gt;</description></item><item><title>第三章：构建AI服务的后端基石</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-03/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-03/</guid><description>&lt;p&gt;在前面的章节中，我们修炼了Python的内功，并掌握了数据科学的利器。通过Kaggle实战，我们已经能够从原始数据出发，经过一系列精细的处理和分析，最终训练出一个表现不错的机器学习模型，并将其保存为一个文件（例如&lt;code&gt;.pkl&lt;/code&gt;或&lt;code&gt;.pth&lt;/code&gt;格式）。&lt;/p&gt;
&lt;p&gt;然而，一个孤立的模型文件，无论其内部多么强大，其价值都是有限的。它就像一把铸造好的绝世好剑，却被锁在剑鞘里，无法施展其锋芒。要真正释放AI模型的价值，我们必须将其部署为一个在线服务，让它能够被其他的应用程序、网站、移动端乃至物联网设备所调用，从而赋能万千场景。这个从模型文件到在线服务的过程，就是AI工程化的“最后一公里”。&lt;/p&gt;</description></item><item><title>第十二章：当LLM遇见知识图谱：构建与应用</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-12/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-12/</guid><description>&lt;p&gt;在前面的章节中，我们已经深入探索了如何构建、微调和部署强大的大语言模型（LLM）。我们知道，LLM通过在海量文本上进行预训练，学习到了丰富的世界知识和强大的语言能力。它像一个博览群书、无所不知的“通才”，能够就任何话题侃侃而谈。&lt;/p&gt;
&lt;p&gt;然而，我们也清楚地认识到LLM的固有缺陷：
知识是隐性的、非结构化的：LLM的知识存储在其数十亿个参数构成的“黑箱”之中，我们无法轻易地对其进行审查、编辑或更新。
容易产生幻觉：它的知识是统计性的，而非事实性的。当被问及它不确定或不知道的信息时，它倾向于“编造”看似合理的答案。
逻辑推理能力有限：尽管LLM展现出一定的推理能力，但它在处理复杂、多跳的逻辑关系时，仍然容易出错。&lt;/p&gt;</description></item><item><title>第十三章：迈向卓越：AI工程师的职业发展与未来展望</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-13/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-13/</guid><description>&lt;p&gt;亲爱的读者，恭喜你，走到了这本《AI工程师实战宝典》的最后一章。&lt;/p&gt;
&lt;p&gt;回首我们的旅程，我们从Python编程和数据科学的坚实地基出发，一步步攀登，跨越了机器学习的丘陵，深入了深度学习与Transformer的腹地。我们不仅学会了如何使用和微调强大的大语言模型，更掌握了构建RAG、Agent等前沿应用，甚至涉足了性能优化、集群部署和知识图谱融合等高阶领域。&lt;/p&gt;</description></item><item><title>第十一章：大规模部署：GPU集群管理与虚拟化</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-11/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-11/</guid><description>&lt;p&gt;在上一章中，我们已经将单张GPU的性能压榨到了极致。通过量化、vLLM等技术，我们学会了如何让一个LLM在单机上跑得更快、更省。这对于个人开发者或小型项目来说，或许已经足够。然而，在大型企业、云服务商或任何一个需要服务数百万用户的场景中，我们面临的挑战将呈指数级增长。&lt;/p&gt;</description></item><item><title>第十章：极致性能：LLM推理服务优化</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-10/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-03/chapter-10/</guid><description>&lt;p&gt;在本书的前两个篇章中，我们已经走过了一段漫长而充实的旅程。我们从底层构建了坚实的工程基础，深入了深度学习和Transformer的腹地，并掌握了微调、RAG和Agent等高级应用开发范式。至此，我们已经能够开发出功能强大的、定制化的LLM应用原型。&lt;/p&gt;</description></item><item><title>第四章：工程师的必修课：Linux、Docker与性能监控</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-04/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-04/</guid><description>&lt;p&gt;在前三章中，我们已经走过了一段激动人心的旅程：从精通Python编程，到驾驭数据科学工具链，再到将AI模型构建成一个功能完备的在线API服务。至此，我们似乎已经拥有了一个可以工作的“产品原型”。然而，在真实的工业环境中，一个能在你的开发机（通常是Windows或macOS图形界面）上通过&lt;code&gt;python app.py&lt;/code&gt;运行起来的应用，与一个能够在生产服务器上7x24小时稳定运行、服务成千上万用户的产品之间，还存在着巨大的鸿沟。&lt;/p&gt;</description></item><item><title>第五章：深度学习之门：从神经网络到PyTorch实战</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-05/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-02/chapter-05/</guid><description>&lt;p&gt;欢迎来到本书的第二篇章。在“基础内功篇”中，我们已经为自己锻造了一身坚实的铠甲：精通了Python编程，掌握了数据科学的利器，并具备了将应用工程化部署的能力。现在，装备齐全的我们，即将踏上一段更为激动人心的征程——深入探索驱动现代人工智能革命的核心引擎：深度学习。&lt;/p&gt;</description></item><item><title>第一章：AI工程师的Python编程精要</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-01/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/part-01/chapter-01/</guid><description>&lt;p&gt;欢迎来到本书的第一篇章。在这里，我们将暂时放下那些令人眼花缭乱的神经网络模型和复杂的数学公式，回归到一切的起点——我们手中最强大的工具：Python。&lt;/p&gt;
&lt;p&gt;对于一位AI工程师而言，Python不仅仅是一门编程语言，它更是我们的“手术刀”、“画笔”与“瑞士军刀”。无论是处理TB级的海量数据、构建精巧的算法模型，还是部署高并发的推理服务，Python都扮演着不可或缺的角色。然而，许多初学者乃至有一定经验的开发者，对Python的理解常常停留在“会用”的层面：能够写出循环、定义函数、调用库。这在进行小规模的学术实验或个人项目中或许尚可应付，但一旦踏入工业界的真实战场，这种“表层熟练”便会暴露出其脆弱性。&lt;/p&gt;</description></item><item><title>附录</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/appendix/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/appendix/</guid><description>&lt;p&gt;正文的旅程已经结束，但作为一名AI工程师的远征才刚刚开始。在未来的探索中，你将需要一个可靠的工具箱，一个随时可以查阅的资源库，以及一个能够帮你扫清障碍的指南。本附录正是为此而生。&lt;/p&gt;
&lt;p&gt;它不是正文的延续，而是你未来学习和工作中的忠实伙伴。在这里，你将找到：&lt;/p&gt;</description></item><item><title>序言：拥抱AGI时代，成为掌握未来的AI工程师</title><link>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/introduction/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/ai-engineer-in-action/introduction/</guid><description>&lt;p&gt;在人类文明的长河中，总有一些时刻，技术的光芒会划破时代的夜空，从根本上重塑我们的世界。我们曾见证蒸汽机驱动的工业革命，也曾经历互联网编织的全球信息网络。而今天，我们正站在一个更加波澜壮阔的变革奇点之上——一个由人工智能，特别是通用人工智能（AGI）曙光所照亮的全新纪元。&lt;/p&gt;</description></item><item><title>第10章 GPU集群的存储设计与实现</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-10/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-02/chapter-10/</guid><description>&lt;p&gt;在前面的章节中，我们已经为GPU集群构建了强大的计算核心（GPU服务器）、高速的内部“神经网络”（计算网络）以及灵活的虚拟“城市规划”（网络虚拟化）。现在，我们来到了构建这个“AI都市”的最后一块，也是同样至关重要的一块基石——存储。&lt;/p&gt;
&lt;p&gt;存储系统是整个GPU集群的“粮仓”和“资料库”。它承载着从操作系统、应用程序、到海量的训练数据集、中间检查点、再到最终生成的模型等所有数据。如果存储系统性能不佳，数据供给跟不上，那么再强大的GPU和再快的网络也只能“望眼欲穿”，整个集群的效率将一落千丈。正如一句行业名言所说：“在高性能计算中，你花在计算上的每一分钱，都得在I/O上花同样的钱来支撑。”&lt;/p&gt;</description></item><item><title>第11章 机器学习应用开发与运行平台的设计与实现</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-11/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-11/</guid><description>&lt;p&gt;在本书的前两个部分，我们已经投入了巨大的精力，完成了从微观到宏观的、全栈式的基础设施建设。我们拥有了顶级的GPU服务器、高速无阻塞的物理网络、灵活安全的虚拟网络、以及分层异构的高性能存储系统。我们还掌握了如何通过虚拟化和容器化技术，将底层的物理资源池化、调度和隔离。至此，我们已经建成了一座基础设施完备、交通发达、能源充足的“AI都市”。&lt;/p&gt;</description></item><item><title>第12章 基于云平台的GPU集群的管理与运营</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-12/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-03/chapter-12/</guid><description>&lt;p&gt;经过前面十一章的艰苦努力，我们已经成功地设计并构建起了一个功能完备、技术先进的大模型算力基础设施。我们拥有了由顶级GPU服务器组成的计算集群，由高速无损网络构成的通信动脉，由分层异构存储组成的强大数据底座，以及一个云原生的、基于微服务的应用开发与运行平台。我们已经建成了这座宏伟的“AI都市”。&lt;/p&gt;</description></item><item><title>第13章 服务机器学习的GPU计算平台落地案例</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-04/chapter-13/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-04/chapter-13/</guid><description>&lt;p&gt;在本书的前三个部分，我们已经系统性地、由浅入深地完成了构建一个大规模GPU计算平台所需的全栈知识体系的学习。我们如同一个学徒，从认识最基础的“砖瓦”（GPU芯片），到学会建造“房屋”（GPU服务器），再到规划整个“城市”的交通（网络）、仓储（存储）、市政（应用平台）与管理（运维运营）。我们已经掌握了所有的理论知识、设计原则和关键技术。&lt;/p&gt;</description></item><item><title>第1章：AI与大模型时代对基础架构的需求</title><link>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-01/</link><pubDate>Sun, 07 Dec 2025 00:00:00 +0800</pubDate><guid>https://zhurongshuo.com/practices/season-4/intelligent-computing-center-construction-guide/part-01/chapter-01/</guid><description>&lt;p&gt;随着信息技术的飞速发展，我们正处在一个由数据驱动、智能赋能的全新时代。人工智能（Artificial Intelligence, AI）不再是科幻小说中的遥远构想，而是已经渗透到社会生产、日常生活的方方面面，成为推动第四次工业革命的核心引擎。近年来，以GPT系列、LLaMA等为代表的大规模预训练模型（Large Language Models, LLMs）取得了突破性进展，其强大的自然语言理解、生成、推理能力，以及在多模态领域的延伸，预示着通用人工智能（AGI）的曙光，也由此开启了波澜壮阔的“大模型时代”。&lt;/p&gt;</description></item></channel></rss>